{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "<h1> Introductory Econometrics in Python"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "**Table of Content**\n",
    "- Simple Regression with Cross-sectional Data\n",
    "- Multiple Regression with cross-sectioal Data, including Inference and Hypothesis testing\n",
    "- ***Binary Dependent Variables***\n",
    "- Regression Analysis with Panel Data\n",
    "- Estimation of Treatment Effects: Difference-in-difference Analysis "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "***Binary Dependent Variables***\n",
    "1. Linear Probability Model (incl.Heteroskedasticity and robust inference)\n",
    "2. Logit and Probit (incl Partial Effects)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "<h3>A Binary Dependent Variable: The Linear Probability Model</h3>\n",
    "\n",
    "So far:\n",
    "\n",
    "- We have learned much about the properties and applicability of the multiple linear regression model.\n",
    "- We studied how, through the use of binary independent variables, we can incorporate qualitative information as explanatory variables in a multiple regression model.\n",
    "- In all of the models up until now: the dependent variable $y$ has had quantitative meaning (for example, $y$ is a dollar amount, a percentage, or the logs of these).\n",
    "\n",
    "\n",
    "What happens if we want to use multiple regression to explain a qualitative event?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "**The Linear Probability Model**\n",
    "\n",
    "- Simplest case:\n",
    "    - The event we would like to explain is a binary outcome.\n",
    "    - Often the case in practice\n",
    "- In other words: our dependent variable, $y$, takes on only two values: zero and one.\n",
    "- For example:\n",
    "    - $y$ can be defined to indicate whether an adult has a high school education;\n",
    "    - $y$ can indicate whether a college student used illegal drugs during a given school year;\n",
    "    - or $y$ can indicate whether a firm was taken over by another firm during a given year."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "**The Linear Probability Model**\n",
    "\n",
    "- In each of these examples, we can let $y=1$ denote one of the outcomes and $y=0$ the other outcome.\n",
    "- What does it mean to write down a multiple regression model, such as\n",
    "\n",
    "\\begin{equation*}\n",
    "y=\\beta_0+\\beta_1x_1+...+\\beta_kx_k+u,\n",
    "\\end{equation*}\n",
    "\n",
    "when $y$ is a binary variable?\n",
    "- Because $y$ can take on only two values, $\\beta_j$ cannot be interpreted as the change in $y$ given a one-unit increase in $x_j$, holding all other factors fixed: $y$ either changes from zero to one or from one to zero (or does not change).\n",
    "- Nevertheless, the $\\beta_j$still have useful interpretations.\n",
    "- If we assume that the zero conditional mean assumption holds, that is, $E(u|x_1,...,x_k)=0$, then we have, as always,\n",
    "\n",
    "\\begin{equation*}\n",
    "E(y|\\mathbf{x})=\\beta_0+\\beta_1x_1+...+\\beta_kx_k+u,\n",
    "\\end{equation*}\n",
    "\n",
    "where **x** is shorthand for all of the explanatory variables.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "**The Linear Probability Model**\n",
    "\n",
    "The key point is that when $y$ is a binary variable taking on the values zero and one, it is always true that: $P(y=1|\\mathbf{x})=E(y|\\mathbf{x})$: \n",
    "- the probability of \"success\" — that is, the probability that $y=1$ — is the same as the expected value of $y$.\n",
    "\n",
    "Thus, we have the important equation\n",
    "\n",
    "\\begin{equation*}\n",
    "P(y=1|\\mathbf{x})=\\beta_0+\\beta_1x_1+...+\\beta_kx_k+u,\n",
    "\\end{equation*}\n",
    "\n",
    "which says that the probability of success, say, $p(\\mathbf{x})=P(y=1|\\mathbf{x})$, is a linear function of the $x_j$.\n",
    "\n",
    "- Such a model is called **binary response model**, and $P(y=1|\\mathbf{x})$ is also called the **response probability**\n",
    "- Because probabilities must sum to one, $P(y=0|\\mathbf{x})=1-P(y=1|\\mathbf{x})$ is also a linear function of the $x_j$."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "**The Linear Probability Model**\n",
    "\n",
    "- The multiple linear regression model with a binary dependent variable is called the **linear probability model (LPM)** because the response probability is linear in the parameters $\\beta_j$.\n",
    "- In the LPM, $\\beta_j$ measures the change in the probability of success when $x_j$ changes, holding other factors fixed:\n",
    "\n",
    "\\begin{equation*}\n",
    "\\Delta P(y=1|\\mathbf{x})=\\beta_j\\Delta x_j.\n",
    "\\end{equation*}\n",
    "\n",
    "\n",
    "- With this in mind, the multiple regression model can allow us to estimate the effect of various explanatory variables on qualitative events.\n",
    "- The mechanics of OLS are the same as before.\n",
    "If we write the estimated equation as\n",
    "\n",
    "\\begin{equation*}\n",
    "\\hat{y}=\\hat{\\beta}_0+\\hat{\\beta}_1x_1+...+\\hat{\\beta}_kx_k+u,\n",
    "\\end{equation*}\n",
    "\n",
    "we must now remember that $\\hat{y}$ is the predicted probability of success.\n",
    "- Therefore, $\\hat{\\beta}_0$ is the predicted probability of success when each $x_j$ is set to zero, which may or may not be interesting.\n",
    "- The slope coefficient $\\hat{\\beta}_1$ measures the predicted change in the probability of success when $x_1$ increases by one unit."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "**Example: Married Women's Labor Force Participation**\n",
    "\n",
    "Let's study the probability that a woman is in the labor force (_inlf_) depending on socio-demographic characteristics such as husband's earnings (_nwifeinc_, in thousands of dollars), the years of education, age, experience, the number of kids younger than  6 or between 6 and 18.\n",
    "The script below estimates a linear probability model using the data set `mroz`.\n",
    "How do we interpret the coefficient of _educ_?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "scrolled": true,
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "table: \n",
      "                      b      se       t    pval\n",
      "Intercept        0.5921  0.1556  3.8051  0.0002\n",
      "C(kidslt6)[T.1] -0.2713  0.0476 -5.7009  0.0000\n",
      "C(kidslt6)[T.2] -0.5454  0.0897 -6.0789  0.0000\n",
      "C(kidslt6)[T.3] -0.5806  0.2521 -2.3032  0.0215\n",
      "nwifeinc        -0.0036  0.0015 -2.4449  0.0147\n",
      "educ             0.0382  0.0074  5.1703  0.0000\n",
      "exper            0.0395  0.0057  6.9125  0.0000\n",
      "I(exper ** 2)   -0.0006  0.0002 -3.2196  0.0013\n",
      "age             -0.0162  0.0025 -6.4737  0.0000\n",
      "kidsge6          0.0131  0.0132  0.9901  0.3225\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import wooldridge as woo\n",
    "import pandas as pd\n",
    "import statsmodels.formula.api as smf\n",
    "\n",
    "mroz = woo.dataWoo('mroz')\n",
    "\n",
    "# estimate linear probability model:\n",
    "reg_lin = smf.ols(formula='inlf ~ nwifeinc + educ + exper +'\n",
    "                          'I(exper**2) + age +C(kidslt6) + kidsge6',\n",
    "                  data=mroz)\n",
    "results_lin = reg_lin.fit()\n",
    "\n",
    "# print regression table:\n",
    "table = pd.DataFrame({'b': round(results_lin.params, 4),\n",
    "                      'se': round(results_lin.bse, 4),\n",
    "                      't': round(results_lin.tvalues, 4),\n",
    "                      'pval': round(results_lin.pvalues, 4)})\n",
    "print(f'table: \\n{table}\\n')\n",
    "\n",
    "#mroz.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "**The Linear Probability Model**\n",
    "\n",
    "- The LPM is easy to interpret\n",
    "- But: let's have a look at the fitted values:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'plt' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-2-60f8b77f27e6>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     17\u001b[0m \u001b[1;31m#display(mroz['inlf_hat'].quantile([.01, 0.05, 0.1, .25, .5, .75, .9]))\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     18\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 19\u001b[1;33m \u001b[0mplt\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mhist\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmroz\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'inlf_hat'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbins\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m25\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     20\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     21\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'plt' is not defined"
     ]
    }
   ],
   "source": [
    "import wooldridge as woo\n",
    "import pandas as pd\n",
    "import statsmodels.formula.api as smf\n",
    "\n",
    "mroz = woo.dataWoo('mroz')\n",
    "\n",
    "# estimate linear probability model:\n",
    "reg_lin = smf.ols(formula='inlf ~ nwifeinc + educ + exper +'\n",
    "                          'I(exper**2) + age + kidslt6 + kidsge6',\n",
    "                  data=mroz)\n",
    "results_lin = reg_lin.fit()\n",
    "\n",
    "mroz['inlf_hat'] = results_lin.fittedvalues\n",
    "\n",
    "#display(mroz.loc[mroz['inlf_hat']<0,'inlf_hat'].describe())\n",
    "#display(mroz.loc[mroz['inlf_hat']>1,'inlf_hat'].describe())\n",
    "#display(mroz['inlf_hat'].quantile([.01, 0.05, 0.1, .25, .5, .75, .9]))\n",
    "\n",
    "plt.hist(mroz['inlf_hat'], bins=25)\n",
    "\n",
    "\n",
    "mroz=mroz.sort_values('inlf_hat')\n",
    "\n",
    "#display(mroz.head())\n",
    "#display(mroz.tail())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "**The Linear Probability Model**\n",
    "\n",
    "- Thus, if we plug certain combinations of values for the independent variables, we can get predictions either less than zero or greater than one.\n",
    "- Since these are predicted probabilities, and probabilities must be between zero and one, this can be a little embarrassing.\n",
    "- For example, what would it mean to predict that a woman is in the labor force with a probability of –.10?\n",
    "- In fact, of the 753 women in the sample, 16 of the fitted values  are less than zero, and 17 of the fitted values are greater than one.\n",
    "- A related problem is that a probability cannot be linearly related to the independent variables for all their possible values as pribabilities are bound between 0 and 1.\n",
    "- For example, our model predicts that the effect of going from zero children to one young child reduces the probability of working by .262.\n",
    "- This is also the predicted drop if the woman goes from having one young child to two.\n",
    "- It seems more realistic that the first small child would reduce the probability by a large amount, but subsequent children would have a smaller marginal effect.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "**The Linear Probability Model**\n",
    "\n",
    "- Even with these problems, the linear probability model is useful and often applied in economics.\n",
    "- It usually works well for values of the independent variables that are near the averages in the sample.\n",
    "- In the labor force participation example, over 96% of the women have either no young children or one small child, and so we should probably restrict attention to this case when interpreting the estimated equation.\n",
    "- Predicted probabilities outside the unit interval are a little troubling when we want to make predictions.\n",
    "- Still, there are ways to use the estimated probabilities (even if some are negative or greater than one) to predict a zero-one outcome.\n",
    "- As before, let $\\hat{y}_i$ denote the fitted values — which may not be bounded between zero and one.\n",
    "- Define a predicted value as  1 if  $\\hat{y}_i>0.5$ and as 0 if $\\hat{y}_i<0.5$ \n",
    "- Now we have a set of predicted values, that are either zero or one.\n",
    "- We can use these data to obtain the frequencies with which we correctly predict $y_i=0$ and $y_i=1$ as well as the proportion of overall correct predictions.\n",
    "- The latter measure, when turned into a percentage, is a widely used goodness-of-fit measure for binary dependent variables: the **percent correctly predicted**."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "**The Linear Probability Model**\n",
    "\n",
    "- Due to the binary nature of $y$, the linear probability model does violate one of our main assumptions.\n",
    "- When $y$ is a binary variable, its variance, conditional on $x$, is\n",
    "\n",
    "\\begin{equation*}\n",
    "Var(y|\\mathbf{x})=p(\\mathbf{x})[1-p(\\mathbf{x})],\n",
    "\\end{equation*}\n",
    "\n",
    "- This means that, except in the case where the probability does not depend on any of the independent variables, there must be heteroskedasticity in a linear probability model.\n",
    "- We know that this does not cause bias in the OLS estimators of the $\\beta_j$.\n",
    "- However, homoskedasticity is crucial for justifying the usual $t$ statistics, even in large samples.\n",
    "- Because the standard errors are not generally valid, we should use them with caution.\n",
    "- We will next show how to correct the standard errors for heteroskedasticity.\n",
    "- It turns out that, in many applications, the usual OLS statistics are not far off, and it is still acceptable in applied work to present a standard OLS analysis of a linear probability model."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "<h3>Heteroskedasticity and Heteroskedasticity-Robust Inference after OLS Estimation</h3>\n",
    "\n",
    "- The homoskedasticity assumption, introduced earlier for multiple regression, states that the variance of the unobserved error, $u$, conditional on the explanatory variables, is constant.\n",
    "- Homoskedasticity fails whenever the variance of the unobserved factors changes across different segments of the population, where the segments are determined by the different values of the explanatory variables.\n",
    "- For example:\n",
    "    - in a savings equation, heteroskedasticity is present if the variance of the unobserved factors affecting savings increases with income.\n",
    "- However: homoskedasticity is needed to justify the usual t tests and confidence intervals for OLS estimation of the linear regression model, even with large sample sizes."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "**Heteroskedasticity-Robust Inference after OLS Estimation**\n",
    "\n",
    "- Fortunately, it is possible to adjust standard errors and t statistics so that they are valid in the presence of **heteroskedasticity of unknown form**.\n",
    "- This is very convenient because it means we can report new statistics that work regardless of the kind of heteroskedasticity present in the population.\n",
    "- This is known as **heteroskedasticity-robust procedures** because they are valid—at least in large samples—whether or not the errors have constant variance, and we do not need to know which is the case.\n",
    "- A careful derivation of the theory is well beyond the scope of this lecture, but the application of heteroskedasticity-robust methods is very easy now because many statistics and econometrics packages compute these statistics as an option.\n",
    "- In _Python_ we can simply use `cov_type='HC3'` in the `fit` function to get **heteroskedasticity-robust standard errors**\n",
    "- However, in empirical work, using robust standrad errors is the default, so you usually don't test and just use robust inference to get more conservative estimates.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=======================================\n",
      "               not robust     robust   \n",
      "                  (1)          (2)     \n",
      "---------------------------------------\n",
      "Intercept     0.585519***  0.585519*** \n",
      "              (0.154178)   (0.153580)  \n",
      "nwifeinc      -0.003405**  -0.003405** \n",
      "              (0.001448)   (0.001558)  \n",
      "educ          0.037995***  0.037995*** \n",
      "              (0.007376)   (0.007340)  \n",
      "exper         0.039492***  0.039492*** \n",
      "              (0.005673)   (0.005984)  \n",
      "I(exper ** 2) -0.000596*** -0.000596***\n",
      "              (0.000185)   (0.000199)  \n",
      "age           -0.016091*** -0.016091***\n",
      "              (0.002485)   (0.002415)  \n",
      "kidslt6       -0.261810*** -0.261810***\n",
      "              (0.033506)   (0.032152)  \n",
      "kidsge6       0.013012     0.013012    \n",
      "              (0.013196)   (0.013660)  \n",
      "N             753          753         \n",
      "R2            0.26         0.26        \n",
      "=======================================\n",
      "Standard errors in parentheses.\n",
      "* p<.1, ** p<.05, ***p<.01\n"
     ]
    }
   ],
   "source": [
    "import wooldridge as woo\n",
    "import pandas as pd\n",
    "import statsmodels.formula.api as smf\n",
    "from statsmodels.iolib.summary2 import summary_col\n",
    "\n",
    "mroz = woo.dataWoo('mroz')\n",
    "\n",
    "# estimate linear probability model:\n",
    "reg_lin = smf.ols(formula='inlf ~ nwifeinc + educ + exper +'\n",
    "                          'I(exper**2) + age + kidslt6 + kidsge6',\n",
    "                  data=mroz)\n",
    "results_lin = reg_lin.fit()\n",
    "\n",
    "reg_lin_rob = smf.ols(formula='inlf ~ nwifeinc + educ + exper +'\n",
    "                          'I(exper**2) + age + kidslt6 + kidsge6',\n",
    "                  data=mroz)\n",
    "results_lin_rob = reg_lin_rob.fit(cov_type='HC3')\n",
    "\n",
    "output = summary_col([results_lin, results_lin_rob],stars=True,float_format='%0.6f',\n",
    "                  model_names=['not robust\\n(1)','robust\\n(2)'],\n",
    "                  info_dict={'N':lambda x: \"{0:d}\".format(int(x.nobs)),\n",
    "                             'R2':lambda x: \"{:.2f}\".format(x.rsquared)})\n",
    "print(output)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "**Logit and Probit Models for Binary Response**\n",
    "\n",
    "- The linear probability model is simple to estimate and use, but it has the mentioned drawbacks.\n",
    "- The two most important disadvantages are that the fitted probabilities can be less than zero or greater than one and the partial effect of any explanatory variable (appearing in level form) is constant.\n",
    "- These limitations of the LPM can be overcome by using more purposeful binary response models.\n",
    "- **Probit** and **logit** regression are nonlinear regression models specifically designed for binary dependent variables.\n",
    "- Because a regression with a binary dependent variable $Y$ models the probability that $Y = 1$, it makes sense to adopt a nonlinear formulation that forces the predicted values to be between 0 and 1.\n",
    "- Because cumulative probability distribution functions (c.d.f.’s) produce probabilities between 0 and 1, they are used in logit and probit regressions.\n",
    "- Probit regression uses the standard normal c.d.f.\n",
    "- Logit regression, also called **logistic regression**, uses the logistic c.d.f."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "**Probit Regression**\n",
    "\n",
    "- The probit regression model with a single regressor $x$ is\n",
    "\n",
    "\\begin{equation*}\n",
    "Pr(y=1|x)=\\Phi(\\beta_0+\\beta_1x)\n",
    "\\end{equation*}\n",
    "\n",
    "where $\\Phi$ is the cumultive standard normal distribution function.\n",
    "\n",
    "- Assume we have $\\beta_0=-2$ and $\\beta_1=3$ and $x=0.3$: we get $\\Phi(-1.1)$\n",
    "- According to the cumulative distribution we have $\\Phi(-1.1)=Pr(Z\\neq-1.1)=13.57\\%$ (these values can be found in tables for the cumulative normal distribution).\n",
    "- Thus, when $x=0.3$ the predicted probability that $y=1$ is 13.57% in this case.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "**Cumulative normal distribution table**\n",
    "<br>  \n",
    "\n",
    "\n",
    "<center><img src=\"figs/sw_cnd.png\" width=\"500\"/> \n",
    "    \n",
    "\n",
    "<p>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "**Probit Model Illustration**  \n",
    "\n",
    "When there is just one regressor, the predicted probability can be plotted as a function of $x$. \n",
    "\n",
    "<br>  \n",
    "\n",
    "\n",
    "<center><img src=\"figs/sw_probit.png\" width=\"500\"/> \n",
    "    \n",
    "\n",
    "<p>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "**Probit Regression**\n",
    "\n",
    "- Although the effect of $x$ on the z-value is linear, its effect on the probability is nonlinear.\n",
    "- Thus in practice the easiest way to interpret the coefficients of a probit model is to compute the predicted probability,or the change in the predicted probability, for one or more values of the regressors.\n",
    "- This is the same method we used before when we analyzed non-linear effects (interaction terms, polynomials).\n",
    "- This method always works for computing predicted effects of a change in $x$, no matter how complicated the nonlinear model.\n",
    "- The probit model parameters are estimated using the Maximum Likelihood Estimation (MLE) method, which we won't cover here formally.\n",
    "- Because the MLE is normally distributed in large samples, statistical inference about the probit and logit coefficients based on the MLE proceeds in the same way as inference about the linear regression function coefficients based on the OLS estimator."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "**Logit Regression**\n",
    "\n",
    "- The logit regression model is similar to the probit regression model except that the cumulative standard normal distribution function $\\Phi$ is replaced by the cumulative standard logistic distribution function, denoted $F$\n",
    "- The logistic cumulative distribution function has a specific functional form, defined in terms of the exponential function:\n",
    "\n",
    "\\begin{equation*}\n",
    "Pr(Y=1|x_1,x_2,...,x_k)=F(\\beta_0+\\beta_1x_1+...+\\beta_kx_k)=\\frac{1}{1+e^{-(\\beta_0+\\beta_1x_1+...+\\beta_kx_k)}}\n",
    "\\end{equation*}\n",
    "\n",
    "and \n",
    "\n",
    "\\begin{equation*}\n",
    "Pr(Y=0|x_1,x_2,...,x_k)=F(\\beta_0+\\beta_1x_1+...+\\beta_kx_k)=\\frac{1}{1+e^{(\\beta_0+\\beta_1x_1+...+\\beta_kx_k)}}\n",
    "\\end{equation*}\n",
    "\n",
    "- As with probit, the logit coefficients are best interpreted by computing predicted probabilities and differences in predicted probabilities.\n",
    "- The coefficients of the logit model can also be estimated by maximum likelihood.\n",
    "- The maximum likelihood estimator is consistent and normally distributed in large samples, so t-statistics and confidence intervals for the coefficients can be constructed in the usual way.\n",
    "- The logit and probit regression functions are similar and the differences between the two functions are small."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "**Using Discrete Choice Models in Python**\n",
    "\n",
    "- In `statsmodels`, many generalized linear models can be estimated with already implemented routines working similar as `ols`.\n",
    "- Two of them that we will need are:\n",
    "     - `logit` for the logit model and\n",
    "     - `probit` for the probit model.\n",
    "- Maximum likelihood estimation (MLE) of the parameters is done automatically and the `summary` of the results contains the regression table and additional information."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "scrolled": false,
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "results_logit.summary(): \n",
      "                           Logit Regression Results                           \n",
      "==============================================================================\n",
      "Dep. Variable:                   inlf   No. Observations:                  753\n",
      "Model:                          Logit   Df Residuals:                      745\n",
      "Method:                           MLE   Df Model:                            7\n",
      "Date:                Mon, 20 Sep 2021   Pseudo R-squ.:                  0.2197\n",
      "Time:                        17:53:42   Log-Likelihood:                -401.77\n",
      "converged:                       True   LL-Null:                       -514.87\n",
      "                                        LLR p-value:                 3.159e-45\n",
      "=================================================================================\n",
      "                    coef    std err          z      P>|z|      [0.025      0.975]\n",
      "---------------------------------------------------------------------------------\n",
      "Intercept         0.4255      0.860      0.494      0.621      -1.261       2.112\n",
      "nwifeinc         -0.0213      0.008     -2.535      0.011      -0.038      -0.005\n",
      "educ              0.2212      0.043      5.091      0.000       0.136       0.306\n",
      "exper             0.2059      0.032      6.422      0.000       0.143       0.269\n",
      "I(exper ** 2)    -0.0032      0.001     -3.104      0.002      -0.005      -0.001\n",
      "age              -0.0880      0.015     -6.040      0.000      -0.117      -0.059\n",
      "kidslt6          -1.4434      0.204     -7.090      0.000      -1.842      -1.044\n",
      "kidsge6           0.0601      0.075      0.804      0.422      -0.086       0.207\n",
      "=================================================================================\n",
      "\n",
      "results_logit.prsquared: 0.21968137484058825\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import wooldridge as woo\n",
    "import statsmodels.formula.api as smf\n",
    "\n",
    "mroz = woo.dataWoo('mroz')\n",
    "\n",
    "# estimate logit model:\n",
    "reg_logit = smf.logit(formula='inlf ~ nwifeinc + educ + exper +'\n",
    "                              'I(exper**2) + age + kidslt6 + kidsge6',\n",
    "                      data=mroz)\n",
    "\n",
    "# disp = 0 avoids printing out information during the estimation:\n",
    "results_logit = reg_logit.fit(disp=0)\n",
    "print(f'results_logit.summary(): \\n{results_logit.summary()}\\n')\n",
    "\n",
    "\n",
    "# McFadden's pseudo R2:\n",
    "print(f'results_logit.prsquared: {results_logit.prsquared}\\n')\n",
    "\n",
    "\n",
    "mroz['inlf_hat_logit'] = results_logit.fittedvalues\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "scrolled": false,
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Optimization terminated successfully.\n",
      "         Current function value: 0.532938\n",
      "         Iterations 5\n",
      "results_probit.summary(): \n",
      "                          Probit Regression Results                           \n",
      "==============================================================================\n",
      "Dep. Variable:                   inlf   No. Observations:                  753\n",
      "Model:                         Probit   Df Residuals:                      745\n",
      "Method:                           MLE   Df Model:                            7\n",
      "Date:                Thu, 17 Sep 2020   Pseudo R-squ.:                  0.2206\n",
      "Time:                        02:45:26   Log-Likelihood:                -401.30\n",
      "converged:                       True   LL-Null:                       -514.87\n",
      "                                        LLR p-value:                 2.009e-45\n",
      "=================================================================================\n",
      "                    coef    std err          z      P>|z|      [0.025      0.975]\n",
      "---------------------------------------------------------------------------------\n",
      "Intercept         0.2701      0.509      0.531      0.595      -0.727       1.267\n",
      "nwifeinc         -0.0120      0.005     -2.484      0.013      -0.022      -0.003\n",
      "educ              0.1309      0.025      5.183      0.000       0.081       0.180\n",
      "exper             0.1233      0.019      6.590      0.000       0.087       0.160\n",
      "I(exper ** 2)    -0.0019      0.001     -3.145      0.002      -0.003      -0.001\n",
      "age              -0.0529      0.008     -6.235      0.000      -0.069      -0.036\n",
      "kidslt6          -0.8683      0.119     -7.326      0.000      -1.101      -0.636\n",
      "kidsge6           0.0360      0.043      0.828      0.408      -0.049       0.121\n",
      "=================================================================================\n",
      "\n",
      "results_probit.prsquared: 0.22058054372529368\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import wooldridge as woo\n",
    "import statsmodels.formula.api as smf\n",
    "\n",
    "mroz = woo.dataWoo('mroz')\n",
    "\n",
    "# estimate probit model:\n",
    "reg_probit = smf.probit(formula='inlf ~ nwifeinc + educ + exper +'\n",
    "                                'I(exper**2) + age + kidslt6 + kidsge6',\n",
    "                        data=mroz)\n",
    "results_probit = reg_probit.fit()\n",
    "print(f'results_probit.summary(): \\n{results_probit.summary()}\\n')\n",
    "\n",
    "\n",
    "# McFadden's pseudo R2:\n",
    "print(f'results_probit.prsquared: {results_probit.prsquared}\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "**Partial Effects**\n",
    "\n",
    "\n",
    "- The parameters of linear regression models have straightforward interpretations:\n",
    "    - $\\beta_j$; measures the ceteris paribus effect of $x_j$ on $E(y|\\mathbf{x})$\n",
    "- The parameters of nonlinear models like logit and probit have a less straightforward interpretation since the linear index $\\mathbf{x\\beta}$ affects $\\hat{y}$ non-linearly through its link function. \n",
    "- In other words: the partial effects differ by regressor values which makes it harder to present the results in a concise and meaningful way.\n",
    "- A useful measure of the influence is again the partial effect (APE) (or average marginal effect) which is the slope and has the same interpretation as the parameters in the linear model.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "- In Python one can use `get_margeff` to get the average partial effects.\n",
    "- APEs for the constant are not part of the methods output since they do not have a direct meaningful interpretation.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "table_auto: \n",
      "      coef_names  APE_logit  APE_probit\n",
      "0       nwifeinc    -0.0038     -0.0036\n",
      "1           educ     0.0395      0.0394\n",
      "2          exper     0.0368      0.0371\n",
      "3  I(exper ** 2)    -0.0006     -0.0006\n",
      "4            age    -0.0157     -0.0159\n",
      "5        kidslt6    -0.2578     -0.2612\n",
      "6        kidsge6     0.0107      0.0108\n",
      "\n",
      "table: \n",
      "                b_ols\n",
      "Intercept      0.5855\n",
      "nwifeinc      -0.0034\n",
      "educ           0.0380\n",
      "exper          0.0395\n",
      "I(exper ** 2) -0.0006\n",
      "age           -0.0161\n",
      "kidslt6       -0.2618\n",
      "kidsge6        0.0130\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import wooldridge as woo\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import statsmodels.formula.api as smf\n",
    "\n",
    "\n",
    "mroz = woo.dataWoo('mroz')\n",
    "\n",
    "# estimate models:\n",
    "reg_lin = smf.ols(formula='inlf ~ nwifeinc + educ + exper + I(exper**2) +'\n",
    "                          'age + kidslt6 + kidsge6', data=mroz)\n",
    "results_lin = reg_lin.fit(cov_type='HC3')\n",
    "\n",
    "reg_logit = smf.logit(formula='inlf ~ nwifeinc + educ + exper + I(exper**2) +'\n",
    "                              'age + kidslt6 + kidsge6', data=mroz)\n",
    "results_logit = reg_logit.fit(disp=0)\n",
    "\n",
    "reg_probit = smf.probit(formula='inlf ~ nwifeinc + educ + exper + I(exper**2) +'\n",
    "                                'age + kidslt6 + kidsge6', data=mroz)\n",
    "results_probit = reg_probit.fit(disp=0)\n",
    "\n",
    "# automatic average partial effects:\n",
    "coef_names = np.array(results_lin.model.exog_names)\n",
    "coef_names = np.delete(coef_names, 0)  # drop Intercept\n",
    "\n",
    "coeff_LPM = results_lin.params\n",
    "APE_logit = results_logit.get_margeff().margeff\n",
    "APE_probit = results_probit.get_margeff().margeff\n",
    "\n",
    "table_auto = pd.DataFrame({'coef_names': coef_names,\n",
    "                           'APE_logit': np.round(APE_logit, 4),\n",
    "                           'APE_probit': np.round(APE_probit, 4), })    \n",
    "                                                 \n",
    "print(f'table_auto: \\n{table_auto}\\n')\n",
    "\n",
    "# print regression table:\n",
    "table = pd.DataFrame({'b_ols': round(results_lin.params, 4)})\n",
    "print(f'table: \\n{table}\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "- If we are interested in the marginal effects of certain values or want to make predictions, we can do this as before when were interested in non-linear effects (e.g quadratic effects) \n",
    "- We just have to plug in the values for each $x$\n",
    "- In the example below we do this for two extreme cases:\n",
    "    - 1. A woman with 1000.0000 Euro from her family, 5 years of education, 20 years old, 2 kids and no work experience\n",
    "    - 2. A woman with 0 moneym 17 years education, 30 years of work experience, no kids.\n",
    "- We can again use `predict` for the predictions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "predictions_lin: \n",
      "0   -0.410458\n",
      "1    1.042808\n",
      "dtype: float64\n",
      "\n",
      "predictions_logit: \n",
      "0    0.005218\n",
      "1    0.950049\n",
      "dtype: float64\n",
      "\n",
      "predictions_probit: \n",
      "0    0.001065\n",
      "1    0.959870\n",
      "dtype: float64\n",
      "\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# predictions for two \"extreme\" women:\n",
    "X_new = pd.DataFrame(\n",
    "    {'nwifeinc': [100, 0], 'educ': [5, 17],\n",
    "     'exper': [0, 30], 'age': [20, 52],\n",
    "     'kidslt6': [2, 0], 'kidsge6': [0, 0]})\n",
    "predictions_lin = results_lin.predict(X_new)\n",
    "predictions_logit = results_logit.predict(X_new)\n",
    "predictions_probit = results_probit.predict(X_new)\n",
    "\n",
    "print(f'predictions_lin: \\n{predictions_lin}\\n')\n",
    "print(f'predictions_logit: \\n{predictions_logit}\\n')\n",
    "print(f'predictions_probit: \\n{predictions_probit}\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "The APEs for the other variables don’t differ too much between the models.\n",
    "\n",
    "Generally, if:\n",
    "- We are interested in APEs only and not in individual predictions or partial effects\n",
    "- and as longs as not too many probabilities are close to 0 or 1,\n",
    "        \n",
    "then, the linear probability model often works well enough."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "<h2>Panel Data Analysis</h2>\n",
    "\n",
    "- Multiple regression is a powerful tool for controlling for the effect of variables on which we have data.\n",
    "- If data are not available for some of the variables, however, they cannot be included in the regression\n",
    "$\\rightarrow$ the OLS estimators of the regression coefficients could have omitted variable bias!\n",
    "        \n",
    "- We have illustrated the omitting variable bias using simulated data earlier and have shown that the bias could be severe and even switch the sign of the parameters\n",
    "- Until now, we have covered multiple regression analysis using pure cross-sectional data.\n",
    "- But: data sets that have both crosssectional and time series dimensions are being used more and more often in empirical research\n",
    "- Data with cross-sectional and time series aspects allow to control for some types of omitted variables without actually observing them.\n",
    "- In fact: data with cross-sectional and time series aspects can often shed light on important policy questions\n",
    "- In this section we will learn how to analyze such data with cross-sectional and time dimension\n",
    "- Such data are called **panel data** or **longitudinal data**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "**Panel Data**\n",
    "\n",
    "- To collect panel data we follow (or attempt to follow) the same individuals, families, firms, cities, states, or whatever, across time.\n",
    "- For example, a panel data set on individual wages, hours, education, and other factors is collected by randomly selecting people from a population at a given point in time.\n",
    "- Then, these same people are reinterviewed at several subsequent points in time.\n",
    "- This gives us data on wages, hours, education, and so on, for the same group of people in different years.\n",
    "- Panel data have $T \\cdot n$ observations (in the ebst case, when no observation is missing)\n",
    "    - $T$ is the number of time periods\n",
    "    - $n$ is the number of entitities\n",
    "    \n",
    "- When describing cross-sectional data, it was useful to use a subscript to denote the entity\n",
    "- For example, $y_i$ referred to the variable $y$ for the $i^{th}$ entity.\n",
    "- When describing panel data, we need some additional notation to keep track of both the entity and the time period.\n",
    "- We do so by using two subscripts rather than one:\n",
    "    - The first, $i$, refers to the entity\n",
    "    - The second, $t$, refers to the time period of the observation.\n",
    "    - Thus $y_{it}$ denotes the variable $y$ observed for the $i^{th}$ of $n$ entities in the $t^{th}$ of $T$ periods."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "**Panel Data**\n",
    "\n",
    "- Some additional terminology associated with panel data describes whether some observations are missing.\n",
    "- A **balanced** panel has all its observations; that is, the variables are observed for each entity and each time period.\n",
    "- A panel that has some missing data for at least one time period for at least one entity is called an **unbalanced panel**.\n",
    "- Having an unbalanced panel is not a problem if the missing observations are random, otherwise we have a **selection bias**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "**Panel Data**\n",
    "\n",
    "- But before we start, let's analyze a panel data set without any further knowledge\n",
    "- Use the dataset 'fatality' on state traffic fatalities\n",
    "\n",
    "- The dataset is about:\n",
    "\n",
    "\n",
    "\n",
    "**Example: Traffic Deaths and Alcohol Taxes**:\n",
    "\n",
    "- There are approximately 40,000 highway traffic fatalities each year in the United States.\n",
    "- Approximately one-fourth of fatal crashes involve a driver who was drinking, and this fraction rises during peak drinking periods.\n",
    "- One study (Levitt and Porter,2001) estimates that\n",
    "\n",
    "    - as many as 25% of drivers on the road between 1 a.m. and 3 a.m. have been drinking\n",
    "    - and that a driver who is legally drunk is at least 13 times as likely to cause a fatal crash as a driver who has not been drinking.\n",
    "    \n",
    "- We aim to study how effective various government policies designed to discourage drunk driving actually are in reducing traffic deaths.\n",
    "- The panel data set contains variables related to traffic fatalities and alcohol, including\n",
    "\n",
    "    - the number of traffic fatalities in each state in each year,\n",
    "    - the type of drunk driving laws in each state in each year,\n",
    "    - and the tax on beer in each state.\n",
    "- The measure of traffic deaths we use is the fatality rate, which is the number of annual traffic deaths per 10,000 people in the population in the state.\n",
    "- The measure of alcohol taxes we use is the \"real\" tax on a case of beer, which is the beer tax, put into 1988 dollars by adjusting for inflation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>state</th>\n",
       "      <th>year</th>\n",
       "      <th>spircons</th>\n",
       "      <th>unrate</th>\n",
       "      <th>perinc</th>\n",
       "      <th>emppop</th>\n",
       "      <th>beertax</th>\n",
       "      <th>sobapt</th>\n",
       "      <th>mormon</th>\n",
       "      <th>mlda</th>\n",
       "      <th>...</th>\n",
       "      <th>aidall</th>\n",
       "      <th>mraidall</th>\n",
       "      <th>pop</th>\n",
       "      <th>pop1517</th>\n",
       "      <th>pop1820</th>\n",
       "      <th>pop2124</th>\n",
       "      <th>miles</th>\n",
       "      <th>unus</th>\n",
       "      <th>epopus</th>\n",
       "      <th>gspch</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>AL</td>\n",
       "      <td>1982</td>\n",
       "      <td>1.37</td>\n",
       "      <td>14.4</td>\n",
       "      <td>10544.152344</td>\n",
       "      <td>50.692039</td>\n",
       "      <td>1.539379</td>\n",
       "      <td>30.355700</td>\n",
       "      <td>0.32829</td>\n",
       "      <td>19.0</td>\n",
       "      <td>...</td>\n",
       "      <td>309.437988</td>\n",
       "      <td>0.000078</td>\n",
       "      <td>3942002.25</td>\n",
       "      <td>208999.593750</td>\n",
       "      <td>221553.437500</td>\n",
       "      <td>290000.062500</td>\n",
       "      <td>28516.0</td>\n",
       "      <td>9.7</td>\n",
       "      <td>57.799999</td>\n",
       "      <td>-0.022125</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>AL</td>\n",
       "      <td>1988</td>\n",
       "      <td>1.17</td>\n",
       "      <td>7.2</td>\n",
       "      <td>12368.624023</td>\n",
       "      <td>56.834530</td>\n",
       "      <td>1.501444</td>\n",
       "      <td>30.223301</td>\n",
       "      <td>0.43018</td>\n",
       "      <td>21.0</td>\n",
       "      <td>...</td>\n",
       "      <td>298.321991</td>\n",
       "      <td>0.000073</td>\n",
       "      <td>4101992.25</td>\n",
       "      <td>201000.125000</td>\n",
       "      <td>193000.515625</td>\n",
       "      <td>262999.781250</td>\n",
       "      <td>39684.0</td>\n",
       "      <td>5.5</td>\n",
       "      <td>62.300003</td>\n",
       "      <td>0.035392</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>AZ</td>\n",
       "      <td>1982</td>\n",
       "      <td>1.97</td>\n",
       "      <td>9.9</td>\n",
       "      <td>12309.069336</td>\n",
       "      <td>56.893295</td>\n",
       "      <td>0.214797</td>\n",
       "      <td>3.958900</td>\n",
       "      <td>4.91910</td>\n",
       "      <td>19.0</td>\n",
       "      <td>...</td>\n",
       "      <td>173.667999</td>\n",
       "      <td>0.000060</td>\n",
       "      <td>2896996.50</td>\n",
       "      <td>140999.984375</td>\n",
       "      <td>156378.703125</td>\n",
       "      <td>217999.984375</td>\n",
       "      <td>19729.0</td>\n",
       "      <td>9.7</td>\n",
       "      <td>57.799999</td>\n",
       "      <td>-0.043182</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>AZ</td>\n",
       "      <td>1988</td>\n",
       "      <td>1.68</td>\n",
       "      <td>6.3</td>\n",
       "      <td>14408.084961</td>\n",
       "      <td>60.497665</td>\n",
       "      <td>0.346487</td>\n",
       "      <td>3.564000</td>\n",
       "      <td>4.41399</td>\n",
       "      <td>21.0</td>\n",
       "      <td>...</td>\n",
       "      <td>238.233994</td>\n",
       "      <td>0.000068</td>\n",
       "      <td>3488995.00</td>\n",
       "      <td>147999.937500</td>\n",
       "      <td>157000.656250</td>\n",
       "      <td>218000.046875</td>\n",
       "      <td>34247.0</td>\n",
       "      <td>5.5</td>\n",
       "      <td>62.300003</td>\n",
       "      <td>0.026568</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>AR</td>\n",
       "      <td>1982</td>\n",
       "      <td>1.19</td>\n",
       "      <td>9.8</td>\n",
       "      <td>10267.302734</td>\n",
       "      <td>54.475857</td>\n",
       "      <td>0.650358</td>\n",
       "      <td>22.967199</td>\n",
       "      <td>0.32829</td>\n",
       "      <td>21.0</td>\n",
       "      <td>...</td>\n",
       "      <td>271.459015</td>\n",
       "      <td>0.000118</td>\n",
       "      <td>2306998.50</td>\n",
       "      <td>121999.992188</td>\n",
       "      <td>121269.500000</td>\n",
       "      <td>157000.015625</td>\n",
       "      <td>16630.0</td>\n",
       "      <td>9.7</td>\n",
       "      <td>57.799999</td>\n",
       "      <td>-0.034734</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 43 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "  state  year  spircons  unrate        perinc     emppop   beertax     sobapt  \\\n",
       "0    AL  1982      1.37    14.4  10544.152344  50.692039  1.539379  30.355700   \n",
       "1    AL  1988      1.17     7.2  12368.624023  56.834530  1.501444  30.223301   \n",
       "2    AZ  1982      1.97     9.9  12309.069336  56.893295  0.214797   3.958900   \n",
       "3    AZ  1988      1.68     6.3  14408.084961  60.497665  0.346487   3.564000   \n",
       "4    AR  1982      1.19     9.8  10267.302734  54.475857  0.650358  22.967199   \n",
       "\n",
       "    mormon  mlda    ...         aidall  mraidall         pop        pop1517  \\\n",
       "0  0.32829  19.0    ...     309.437988  0.000078  3942002.25  208999.593750   \n",
       "1  0.43018  21.0    ...     298.321991  0.000073  4101992.25  201000.125000   \n",
       "2  4.91910  19.0    ...     173.667999  0.000060  2896996.50  140999.984375   \n",
       "3  4.41399  21.0    ...     238.233994  0.000068  3488995.00  147999.937500   \n",
       "4  0.32829  21.0    ...     271.459015  0.000118  2306998.50  121999.992188   \n",
       "\n",
       "         pop1820        pop2124    miles  unus     epopus     gspch  \n",
       "0  221553.437500  290000.062500  28516.0   9.7  57.799999 -0.022125  \n",
       "1  193000.515625  262999.781250  39684.0   5.5  62.300003  0.035392  \n",
       "2  156378.703125  217999.984375  19729.0   9.7  57.799999 -0.043182  \n",
       "3  157000.656250  218000.046875  34247.0   5.5  62.300003  0.026568  \n",
       "4  121269.500000  157000.015625  16630.0   9.7  57.799999 -0.034734  \n",
       "\n",
       "[5 rows x 43 columns]"
      ]
     },
     "execution_count": 97,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import statsmodels.formula.api as smf\n",
    "\n",
    "fatality=pd.read_stata('data/fatality.dta')\n",
    "fatality.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'state': 'State ID (FIPS) Code',\n",
       " 'year': 'Year',\n",
       " 'spircons': 'Spirits Consumption',\n",
       " 'unrate': 'Unemployment Rate',\n",
       " 'perinc': 'Per Capita Personal Income',\n",
       " 'emppop': 'Employment/Population Ratio',\n",
       " 'beertax': 'Tax on Case of Beer',\n",
       " 'sobapt': '% Southern Baptist',\n",
       " 'mormon': '% Mormon',\n",
       " 'mlda': 'Minimum Legal Drinking Age',\n",
       " 'dry': '% Residing in Dry Counties',\n",
       " 'yngdrv': '% of Drivers Aged 15-24',\n",
       " 'vmiles': 'Ave. Mile per Driver',\n",
       " 'breath': 'Prelim. Breath Test Law',\n",
       " 'jaild': 'Mandatory Jail Sentence',\n",
       " 'comserd': 'Mandatory Community Service',\n",
       " 'allmort': '# of Vehicle Fatalities (#VF)',\n",
       " 'mrall': 'Vehicle Fatality Rate (VFR)',\n",
       " 'allnite': '# of Night-time VF (#NVF)',\n",
       " 'mralln': 'Night-time VFR (NFVR)',\n",
       " 'allsvn': '# of Single VF (#SVN)',\n",
       " 'a1517': '#VF, 15-17 year olds',\n",
       " 'mra1517': 'VFR, 15-17 year olds',\n",
       " 'a1517n': '#NVF, 15-17 year olds',\n",
       " 'mra1517n': 'NVFR, 15-17 year olds',\n",
       " 'a1820': '#VF, 18-20 year olds',\n",
       " 'a1820n': '#NVF, 18-20 year olds',\n",
       " 'mra1820': 'VFR, 18-20 year olds',\n",
       " 'mra1820n': 'NVFR, 18-20 year olds',\n",
       " 'a2124': '#VF, 21-24 year olds',\n",
       " 'mra2124': 'VFR, 21-24 year olds',\n",
       " 'a2124n': '#NVF, 21-24 year olds',\n",
       " 'mra2124n': 'NVFR, 21-24 year olds',\n",
       " 'aidall': '# of alcohol-involved VF',\n",
       " 'mraidall': 'Alcohol-Involved VFR',\n",
       " 'pop': 'Population',\n",
       " 'pop1517': 'Population, 15-17 year olds',\n",
       " 'pop1820': 'Population, 18-20 year olds',\n",
       " 'pop2124': 'Population, 21-24 year olds',\n",
       " 'miles': 'total vehicle miles (millions',\n",
       " 'unus': 'U.S. unemployment rate',\n",
       " 'epopus': 'U.S. Emp/Pop Ratio',\n",
       " 'gspch': 'GSP Rate of Change'}"
      ]
     },
     "execution_count": 96,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import statsmodels.formula.api as smf\n",
    "\n",
    "fatality=pd.read_stata('data/fatality.dta', iterator=True)\n",
    "fatality.variable_labels()\n",
    "#pd.io.stata.StataReader('data/fatality.dta').variable_labels()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "**Panel Data**\n",
    "\n",
    "- Analyze the data descriptively\n",
    "- Is the dataset balanced?\n",
    "- How many states are in it, how many years?\n",
    "- Regress fatalities on a tax for alcohol ('beertax') for a the year 1982 and discuss the results and plot the linear fit\n",
    "- Repeat the exercise for the year 1988 \n",
    "- Repeat the exercise for the years 1982 and 1988 jointly\n",
    "- What do you think about the findings?\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>year</th>\n",
       "      <th>spircons</th>\n",
       "      <th>unrate</th>\n",
       "      <th>perinc</th>\n",
       "      <th>emppop</th>\n",
       "      <th>beertax</th>\n",
       "      <th>sobapt</th>\n",
       "      <th>mormon</th>\n",
       "      <th>mlda</th>\n",
       "      <th>dry</th>\n",
       "      <th>...</th>\n",
       "      <th>aidall</th>\n",
       "      <th>mraidall</th>\n",
       "      <th>pop</th>\n",
       "      <th>pop1517</th>\n",
       "      <th>pop1820</th>\n",
       "      <th>pop2124</th>\n",
       "      <th>miles</th>\n",
       "      <th>unus</th>\n",
       "      <th>epopus</th>\n",
       "      <th>gspch</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>96.000000</td>\n",
       "      <td>96.000000</td>\n",
       "      <td>96.000000</td>\n",
       "      <td>96.000000</td>\n",
       "      <td>96.000000</td>\n",
       "      <td>96.000000</td>\n",
       "      <td>96.000000</td>\n",
       "      <td>96.000000</td>\n",
       "      <td>96.000000</td>\n",
       "      <td>96.00000</td>\n",
       "      <td>...</td>\n",
       "      <td>96.000000</td>\n",
       "      <td>96.000000</td>\n",
       "      <td>9.600000e+01</td>\n",
       "      <td>9.600000e+01</td>\n",
       "      <td>9.600000e+01</td>\n",
       "      <td>9.600000e+01</td>\n",
       "      <td>96.000000</td>\n",
       "      <td>96.000000</td>\n",
       "      <td>96.000000</td>\n",
       "      <td>96.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>1985.000000</td>\n",
       "      <td>1.749896</td>\n",
       "      <td>7.361459</td>\n",
       "      <td>13945.891602</td>\n",
       "      <td>60.825115</td>\n",
       "      <td>0.505044</td>\n",
       "      <td>7.159286</td>\n",
       "      <td>2.804149</td>\n",
       "      <td>20.500000</td>\n",
       "      <td>4.31191</td>\n",
       "      <td>...</td>\n",
       "      <td>300.004608</td>\n",
       "      <td>0.000068</td>\n",
       "      <td>4.932250e+06</td>\n",
       "      <td>2.318125e+05</td>\n",
       "      <td>2.449765e+05</td>\n",
       "      <td>3.369480e+05</td>\n",
       "      <td>37393.980469</td>\n",
       "      <td>7.600004</td>\n",
       "      <td>60.049969</td>\n",
       "      <td>0.006398</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>3.015748</td>\n",
       "      <td>0.687137</td>\n",
       "      <td>2.824493</td>\n",
       "      <td>2422.510742</td>\n",
       "      <td>4.944419</td>\n",
       "      <td>0.477024</td>\n",
       "      <td>9.801956</td>\n",
       "      <td>9.707438</td>\n",
       "      <td>0.909019</td>\n",
       "      <td>9.65108</td>\n",
       "      <td>...</td>\n",
       "      <td>312.300995</td>\n",
       "      <td>0.000027</td>\n",
       "      <td>5.102291e+06</td>\n",
       "      <td>2.314680e+05</td>\n",
       "      <td>2.475225e+05</td>\n",
       "      <td>3.468089e+05</td>\n",
       "      <td>38114.128906</td>\n",
       "      <td>2.111023</td>\n",
       "      <td>2.261812</td>\n",
       "      <td>0.039740</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>1982.000000</td>\n",
       "      <td>0.790000</td>\n",
       "      <td>2.400000</td>\n",
       "      <td>9553.699219</td>\n",
       "      <td>45.522900</td>\n",
       "      <td>0.043311</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.100000</td>\n",
       "      <td>18.000000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>...</td>\n",
       "      <td>27.760000</td>\n",
       "      <td>0.000023</td>\n",
       "      <td>4.789997e+05</td>\n",
       "      <td>2.100002e+04</td>\n",
       "      <td>2.099996e+04</td>\n",
       "      <td>3.000016e+04</td>\n",
       "      <td>3993.000000</td>\n",
       "      <td>5.500000</td>\n",
       "      <td>57.799999</td>\n",
       "      <td>-0.089512</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>1982.000000</td>\n",
       "      <td>1.312500</td>\n",
       "      <td>5.275000</td>\n",
       "      <td>12260.571533</td>\n",
       "      <td>57.709750</td>\n",
       "      <td>0.214797</td>\n",
       "      <td>0.608632</td>\n",
       "      <td>0.233310</td>\n",
       "      <td>20.000000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>...</td>\n",
       "      <td>94.286499</td>\n",
       "      <td>0.000051</td>\n",
       "      <td>1.545251e+06</td>\n",
       "      <td>7.225006e+04</td>\n",
       "      <td>7.560232e+04</td>\n",
       "      <td>1.012503e+05</td>\n",
       "      <td>11426.500000</td>\n",
       "      <td>5.500000</td>\n",
       "      <td>57.799999</td>\n",
       "      <td>-0.023864</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>1985.000000</td>\n",
       "      <td>1.650000</td>\n",
       "      <td>7.050000</td>\n",
       "      <td>13774.353516</td>\n",
       "      <td>61.337376</td>\n",
       "      <td>0.346487</td>\n",
       "      <td>1.758600</td>\n",
       "      <td>0.400000</td>\n",
       "      <td>21.000000</td>\n",
       "      <td>0.11074</td>\n",
       "      <td>...</td>\n",
       "      <td>219.675003</td>\n",
       "      <td>0.000064</td>\n",
       "      <td>3.385503e+06</td>\n",
       "      <td>1.690000e+05</td>\n",
       "      <td>1.709823e+05</td>\n",
       "      <td>2.435000e+05</td>\n",
       "      <td>28090.499023</td>\n",
       "      <td>7.600000</td>\n",
       "      <td>60.050001</td>\n",
       "      <td>0.008297</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>1988.000000</td>\n",
       "      <td>1.995000</td>\n",
       "      <td>9.200000</td>\n",
       "      <td>15160.900391</td>\n",
       "      <td>64.257044</td>\n",
       "      <td>0.621511</td>\n",
       "      <td>13.127125</td>\n",
       "      <td>0.642450</td>\n",
       "      <td>21.000000</td>\n",
       "      <td>2.11540</td>\n",
       "      <td>...</td>\n",
       "      <td>356.607750</td>\n",
       "      <td>0.000078</td>\n",
       "      <td>5.674987e+06</td>\n",
       "      <td>2.825001e+05</td>\n",
       "      <td>3.078614e+05</td>\n",
       "      <td>4.172502e+05</td>\n",
       "      <td>44537.250000</td>\n",
       "      <td>9.700000</td>\n",
       "      <td>62.300003</td>\n",
       "      <td>0.039652</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>1988.000000</td>\n",
       "      <td>4.900000</td>\n",
       "      <td>15.500000</td>\n",
       "      <td>22193.455078</td>\n",
       "      <td>70.838394</td>\n",
       "      <td>2.720764</td>\n",
       "      <td>30.355700</td>\n",
       "      <td>65.916496</td>\n",
       "      <td>21.000000</td>\n",
       "      <td>45.77980</td>\n",
       "      <td>...</td>\n",
       "      <td>2094.899902</td>\n",
       "      <td>0.000172</td>\n",
       "      <td>2.831403e+07</td>\n",
       "      <td>1.157002e+06</td>\n",
       "      <td>1.321004e+06</td>\n",
       "      <td>1.892998e+06</td>\n",
       "      <td>241575.015625</td>\n",
       "      <td>9.700000</td>\n",
       "      <td>62.300003</td>\n",
       "      <td>0.104920</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>8 rows × 42 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "              year   spircons     unrate        perinc     emppop    beertax  \\\n",
       "count    96.000000  96.000000  96.000000     96.000000  96.000000  96.000000   \n",
       "mean   1985.000000   1.749896   7.361459  13945.891602  60.825115   0.505044   \n",
       "std       3.015748   0.687137   2.824493   2422.510742   4.944419   0.477024   \n",
       "min    1982.000000   0.790000   2.400000   9553.699219  45.522900   0.043311   \n",
       "25%    1982.000000   1.312500   5.275000  12260.571533  57.709750   0.214797   \n",
       "50%    1985.000000   1.650000   7.050000  13774.353516  61.337376   0.346487   \n",
       "75%    1988.000000   1.995000   9.200000  15160.900391  64.257044   0.621511   \n",
       "max    1988.000000   4.900000  15.500000  22193.455078  70.838394   2.720764   \n",
       "\n",
       "          sobapt     mormon       mlda       dry    ...           aidall  \\\n",
       "count  96.000000  96.000000  96.000000  96.00000    ...        96.000000   \n",
       "mean    7.159286   2.804149  20.500000   4.31191    ...       300.004608   \n",
       "std     9.801956   9.707438   0.909019   9.65108    ...       312.300995   \n",
       "min     0.000000   0.100000  18.000000   0.00000    ...        27.760000   \n",
       "25%     0.608632   0.233310  20.000000   0.00000    ...        94.286499   \n",
       "50%     1.758600   0.400000  21.000000   0.11074    ...       219.675003   \n",
       "75%    13.127125   0.642450  21.000000   2.11540    ...       356.607750   \n",
       "max    30.355700  65.916496  21.000000  45.77980    ...      2094.899902   \n",
       "\n",
       "        mraidall           pop       pop1517       pop1820       pop2124  \\\n",
       "count  96.000000  9.600000e+01  9.600000e+01  9.600000e+01  9.600000e+01   \n",
       "mean    0.000068  4.932250e+06  2.318125e+05  2.449765e+05  3.369480e+05   \n",
       "std     0.000027  5.102291e+06  2.314680e+05  2.475225e+05  3.468089e+05   \n",
       "min     0.000023  4.789997e+05  2.100002e+04  2.099996e+04  3.000016e+04   \n",
       "25%     0.000051  1.545251e+06  7.225006e+04  7.560232e+04  1.012503e+05   \n",
       "50%     0.000064  3.385503e+06  1.690000e+05  1.709823e+05  2.435000e+05   \n",
       "75%     0.000078  5.674987e+06  2.825001e+05  3.078614e+05  4.172502e+05   \n",
       "max     0.000172  2.831403e+07  1.157002e+06  1.321004e+06  1.892998e+06   \n",
       "\n",
       "               miles       unus     epopus      gspch  \n",
       "count      96.000000  96.000000  96.000000  96.000000  \n",
       "mean    37393.980469   7.600004  60.049969   0.006398  \n",
       "std     38114.128906   2.111023   2.261812   0.039740  \n",
       "min      3993.000000   5.500000  57.799999  -0.089512  \n",
       "25%     11426.500000   5.500000  57.799999  -0.023864  \n",
       "50%     28090.499023   7.600000  60.050001   0.008297  \n",
       "75%     44537.250000   9.700000  62.300003   0.039652  \n",
       "max    241575.015625   9.700000  62.300003   0.104920  \n",
       "\n",
       "[8 rows x 42 columns]"
      ]
     },
     "execution_count": 98,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import statsmodels.formula.api as smf\n",
    "\n",
    "fatality=pd.read_stata('data/fatality.dta')\n",
    "fatality.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>year</th>\n",
       "      <th>spircons</th>\n",
       "      <th>unrate</th>\n",
       "      <th>perinc</th>\n",
       "      <th>emppop</th>\n",
       "      <th>beertax</th>\n",
       "      <th>sobapt</th>\n",
       "      <th>mormon</th>\n",
       "      <th>mlda</th>\n",
       "      <th>dry</th>\n",
       "      <th>yngdrv</th>\n",
       "      <th>vmiles</th>\n",
       "      <th>breath</th>\n",
       "      <th>jaild</th>\n",
       "      <th>comserd</th>\n",
       "      <th>allmort</th>\n",
       "      <th>mrall</th>\n",
       "      <th>allnite</th>\n",
       "      <th>mralln</th>\n",
       "      <th>allsvn</th>\n",
       "      <th>a1517</th>\n",
       "      <th>mra1517</th>\n",
       "      <th>a1517n</th>\n",
       "      <th>mra1517n</th>\n",
       "      <th>a1820</th>\n",
       "      <th>a1820n</th>\n",
       "      <th>mra1820</th>\n",
       "      <th>mra1820n</th>\n",
       "      <th>a2124</th>\n",
       "      <th>mra2124</th>\n",
       "      <th>a2124n</th>\n",
       "      <th>mra2124n</th>\n",
       "      <th>aidall</th>\n",
       "      <th>mraidall</th>\n",
       "      <th>pop</th>\n",
       "      <th>pop1517</th>\n",
       "      <th>pop1820</th>\n",
       "      <th>pop2124</th>\n",
       "      <th>miles</th>\n",
       "      <th>unus</th>\n",
       "      <th>epopus</th>\n",
       "      <th>gspch</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>96.000000</td>\n",
       "      <td>96.000000</td>\n",
       "      <td>96.000000</td>\n",
       "      <td>96.000000</td>\n",
       "      <td>96.000000</td>\n",
       "      <td>96.000000</td>\n",
       "      <td>96.000000</td>\n",
       "      <td>96.000000</td>\n",
       "      <td>96.000000</td>\n",
       "      <td>96.00000</td>\n",
       "      <td>96.000000</td>\n",
       "      <td>96.000000</td>\n",
       "      <td>96.000000</td>\n",
       "      <td>95.000000</td>\n",
       "      <td>95.000000</td>\n",
       "      <td>96.000000</td>\n",
       "      <td>96.000000</td>\n",
       "      <td>96.000000</td>\n",
       "      <td>96.000000</td>\n",
       "      <td>96.000000</td>\n",
       "      <td>96.000000</td>\n",
       "      <td>96.000000</td>\n",
       "      <td>96.000000</td>\n",
       "      <td>96.000000</td>\n",
       "      <td>96.000000</td>\n",
       "      <td>96.000000</td>\n",
       "      <td>96.000000</td>\n",
       "      <td>96.000000</td>\n",
       "      <td>96.000000</td>\n",
       "      <td>96.000000</td>\n",
       "      <td>96.000000</td>\n",
       "      <td>96.000000</td>\n",
       "      <td>96.000000</td>\n",
       "      <td>96.000000</td>\n",
       "      <td>9.600000e+01</td>\n",
       "      <td>9.600000e+01</td>\n",
       "      <td>9.600000e+01</td>\n",
       "      <td>9.600000e+01</td>\n",
       "      <td>96.000000</td>\n",
       "      <td>96.000000</td>\n",
       "      <td>96.000000</td>\n",
       "      <td>96.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>1985.000000</td>\n",
       "      <td>1.749896</td>\n",
       "      <td>7.361459</td>\n",
       "      <td>13945.891602</td>\n",
       "      <td>60.825115</td>\n",
       "      <td>0.505044</td>\n",
       "      <td>7.159286</td>\n",
       "      <td>2.804149</td>\n",
       "      <td>20.500000</td>\n",
       "      <td>4.31191</td>\n",
       "      <td>0.184874</td>\n",
       "      <td>7921.525391</td>\n",
       "      <td>0.437500</td>\n",
       "      <td>0.242105</td>\n",
       "      <td>0.157895</td>\n",
       "      <td>941.979167</td>\n",
       "      <td>2.079350</td>\n",
       "      <td>191.104167</td>\n",
       "      <td>0.000041</td>\n",
       "      <td>114.770833</td>\n",
       "      <td>62.052083</td>\n",
       "      <td>0.000306</td>\n",
       "      <td>12.822917</td>\n",
       "      <td>0.000062</td>\n",
       "      <td>111.770833</td>\n",
       "      <td>35.822917</td>\n",
       "      <td>0.000510</td>\n",
       "      <td>0.000161</td>\n",
       "      <td>126.885417</td>\n",
       "      <td>0.000410</td>\n",
       "      <td>42.875000</td>\n",
       "      <td>0.000131</td>\n",
       "      <td>300.004608</td>\n",
       "      <td>0.000068</td>\n",
       "      <td>4.932250e+06</td>\n",
       "      <td>2.318125e+05</td>\n",
       "      <td>2.449765e+05</td>\n",
       "      <td>3.369480e+05</td>\n",
       "      <td>37393.980469</td>\n",
       "      <td>7.600004</td>\n",
       "      <td>60.049969</td>\n",
       "      <td>0.006398</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>3.015748</td>\n",
       "      <td>0.687137</td>\n",
       "      <td>2.824493</td>\n",
       "      <td>2422.510742</td>\n",
       "      <td>4.944419</td>\n",
       "      <td>0.477024</td>\n",
       "      <td>9.801956</td>\n",
       "      <td>9.707438</td>\n",
       "      <td>0.909019</td>\n",
       "      <td>9.65108</td>\n",
       "      <td>0.031292</td>\n",
       "      <td>1256.812012</td>\n",
       "      <td>0.498682</td>\n",
       "      <td>0.430630</td>\n",
       "      <td>0.366577</td>\n",
       "      <td>947.803755</td>\n",
       "      <td>0.595899</td>\n",
       "      <td>199.769155</td>\n",
       "      <td>0.000012</td>\n",
       "      <td>114.674595</td>\n",
       "      <td>53.314434</td>\n",
       "      <td>0.000104</td>\n",
       "      <td>13.085142</td>\n",
       "      <td>0.000037</td>\n",
       "      <td>108.574736</td>\n",
       "      <td>35.439495</td>\n",
       "      <td>0.000164</td>\n",
       "      <td>0.000075</td>\n",
       "      <td>132.653873</td>\n",
       "      <td>0.000130</td>\n",
       "      <td>45.471391</td>\n",
       "      <td>0.000039</td>\n",
       "      <td>312.300995</td>\n",
       "      <td>0.000027</td>\n",
       "      <td>5.102291e+06</td>\n",
       "      <td>2.314680e+05</td>\n",
       "      <td>2.475225e+05</td>\n",
       "      <td>3.468089e+05</td>\n",
       "      <td>38114.128906</td>\n",
       "      <td>2.111023</td>\n",
       "      <td>2.261812</td>\n",
       "      <td>0.039740</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>1982.000000</td>\n",
       "      <td>0.790000</td>\n",
       "      <td>2.400000</td>\n",
       "      <td>9553.699219</td>\n",
       "      <td>45.522900</td>\n",
       "      <td>0.043311</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.100000</td>\n",
       "      <td>18.000000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.073137</td>\n",
       "      <td>4576.345703</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>104.000000</td>\n",
       "      <td>1.100630</td>\n",
       "      <td>18.000000</td>\n",
       "      <td>0.000017</td>\n",
       "      <td>10.000000</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>0.000141</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>12.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000274</td>\n",
       "      <td>0.000025</td>\n",
       "      <td>13.000000</td>\n",
       "      <td>0.000200</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>0.000036</td>\n",
       "      <td>27.760000</td>\n",
       "      <td>0.000023</td>\n",
       "      <td>4.789997e+05</td>\n",
       "      <td>2.100002e+04</td>\n",
       "      <td>2.099996e+04</td>\n",
       "      <td>3.000016e+04</td>\n",
       "      <td>3993.000000</td>\n",
       "      <td>5.500000</td>\n",
       "      <td>57.799999</td>\n",
       "      <td>-0.089512</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>1982.000000</td>\n",
       "      <td>1.312500</td>\n",
       "      <td>5.275000</td>\n",
       "      <td>12260.571533</td>\n",
       "      <td>57.709750</td>\n",
       "      <td>0.214797</td>\n",
       "      <td>0.608632</td>\n",
       "      <td>0.233310</td>\n",
       "      <td>20.000000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.162174</td>\n",
       "      <td>7047.493530</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>292.750000</td>\n",
       "      <td>1.623710</td>\n",
       "      <td>52.250000</td>\n",
       "      <td>0.000032</td>\n",
       "      <td>34.750000</td>\n",
       "      <td>26.750000</td>\n",
       "      <td>0.000218</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>0.000041</td>\n",
       "      <td>38.000000</td>\n",
       "      <td>12.000000</td>\n",
       "      <td>0.000398</td>\n",
       "      <td>0.000117</td>\n",
       "      <td>48.000000</td>\n",
       "      <td>0.000322</td>\n",
       "      <td>12.750000</td>\n",
       "      <td>0.000107</td>\n",
       "      <td>94.286499</td>\n",
       "      <td>0.000051</td>\n",
       "      <td>1.545251e+06</td>\n",
       "      <td>7.225006e+04</td>\n",
       "      <td>7.560232e+04</td>\n",
       "      <td>1.012503e+05</td>\n",
       "      <td>11426.500000</td>\n",
       "      <td>5.500000</td>\n",
       "      <td>57.799999</td>\n",
       "      <td>-0.023864</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>1985.000000</td>\n",
       "      <td>1.650000</td>\n",
       "      <td>7.050000</td>\n",
       "      <td>13774.353516</td>\n",
       "      <td>61.337376</td>\n",
       "      <td>0.346487</td>\n",
       "      <td>1.758600</td>\n",
       "      <td>0.400000</td>\n",
       "      <td>21.000000</td>\n",
       "      <td>0.11074</td>\n",
       "      <td>0.183364</td>\n",
       "      <td>7779.157227</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>723.000000</td>\n",
       "      <td>2.024030</td>\n",
       "      <td>138.500000</td>\n",
       "      <td>0.000038</td>\n",
       "      <td>86.000000</td>\n",
       "      <td>47.500000</td>\n",
       "      <td>0.000295</td>\n",
       "      <td>10.000000</td>\n",
       "      <td>0.000054</td>\n",
       "      <td>84.500000</td>\n",
       "      <td>24.500000</td>\n",
       "      <td>0.000497</td>\n",
       "      <td>0.000145</td>\n",
       "      <td>96.000000</td>\n",
       "      <td>0.000394</td>\n",
       "      <td>31.500000</td>\n",
       "      <td>0.000127</td>\n",
       "      <td>219.675003</td>\n",
       "      <td>0.000064</td>\n",
       "      <td>3.385503e+06</td>\n",
       "      <td>1.690000e+05</td>\n",
       "      <td>1.709823e+05</td>\n",
       "      <td>2.435000e+05</td>\n",
       "      <td>28090.499023</td>\n",
       "      <td>7.600000</td>\n",
       "      <td>60.050001</td>\n",
       "      <td>0.008297</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>1988.000000</td>\n",
       "      <td>1.995000</td>\n",
       "      <td>9.200000</td>\n",
       "      <td>15160.900391</td>\n",
       "      <td>64.257044</td>\n",
       "      <td>0.621511</td>\n",
       "      <td>13.127125</td>\n",
       "      <td>0.642450</td>\n",
       "      <td>21.000000</td>\n",
       "      <td>2.11540</td>\n",
       "      <td>0.208379</td>\n",
       "      <td>8749.439941</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1076.000000</td>\n",
       "      <td>2.453930</td>\n",
       "      <td>230.000000</td>\n",
       "      <td>0.000046</td>\n",
       "      <td>134.250000</td>\n",
       "      <td>77.500000</td>\n",
       "      <td>0.000357</td>\n",
       "      <td>16.000000</td>\n",
       "      <td>0.000075</td>\n",
       "      <td>131.250000</td>\n",
       "      <td>45.000000</td>\n",
       "      <td>0.000573</td>\n",
       "      <td>0.000187</td>\n",
       "      <td>151.500000</td>\n",
       "      <td>0.000469</td>\n",
       "      <td>50.250000</td>\n",
       "      <td>0.000147</td>\n",
       "      <td>356.607750</td>\n",
       "      <td>0.000078</td>\n",
       "      <td>5.674987e+06</td>\n",
       "      <td>2.825001e+05</td>\n",
       "      <td>3.078614e+05</td>\n",
       "      <td>4.172502e+05</td>\n",
       "      <td>44537.250000</td>\n",
       "      <td>9.700000</td>\n",
       "      <td>62.300003</td>\n",
       "      <td>0.039652</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>1988.000000</td>\n",
       "      <td>4.900000</td>\n",
       "      <td>15.500000</td>\n",
       "      <td>22193.455078</td>\n",
       "      <td>70.838394</td>\n",
       "      <td>2.720764</td>\n",
       "      <td>30.355700</td>\n",
       "      <td>65.916496</td>\n",
       "      <td>21.000000</td>\n",
       "      <td>45.77980</td>\n",
       "      <td>0.281496</td>\n",
       "      <td>11812.115234</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>5390.000000</td>\n",
       "      <td>4.217840</td>\n",
       "      <td>1049.000000</td>\n",
       "      <td>0.000086</td>\n",
       "      <td>603.000000</td>\n",
       "      <td>247.000000</td>\n",
       "      <td>0.000634</td>\n",
       "      <td>72.000000</td>\n",
       "      <td>0.000257</td>\n",
       "      <td>583.000000</td>\n",
       "      <td>196.000000</td>\n",
       "      <td>0.001095</td>\n",
       "      <td>0.000524</td>\n",
       "      <td>758.000000</td>\n",
       "      <td>0.000892</td>\n",
       "      <td>249.000000</td>\n",
       "      <td>0.000292</td>\n",
       "      <td>2094.899902</td>\n",
       "      <td>0.000172</td>\n",
       "      <td>2.831403e+07</td>\n",
       "      <td>1.157002e+06</td>\n",
       "      <td>1.321004e+06</td>\n",
       "      <td>1.892998e+06</td>\n",
       "      <td>241575.015625</td>\n",
       "      <td>9.700000</td>\n",
       "      <td>62.300003</td>\n",
       "      <td>0.104920</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              year   spircons     unrate        perinc     emppop    beertax  \\\n",
       "count    96.000000  96.000000  96.000000     96.000000  96.000000  96.000000   \n",
       "mean   1985.000000   1.749896   7.361459  13945.891602  60.825115   0.505044   \n",
       "std       3.015748   0.687137   2.824493   2422.510742   4.944419   0.477024   \n",
       "min    1982.000000   0.790000   2.400000   9553.699219  45.522900   0.043311   \n",
       "25%    1982.000000   1.312500   5.275000  12260.571533  57.709750   0.214797   \n",
       "50%    1985.000000   1.650000   7.050000  13774.353516  61.337376   0.346487   \n",
       "75%    1988.000000   1.995000   9.200000  15160.900391  64.257044   0.621511   \n",
       "max    1988.000000   4.900000  15.500000  22193.455078  70.838394   2.720764   \n",
       "\n",
       "          sobapt     mormon       mlda       dry     yngdrv        vmiles  \\\n",
       "count  96.000000  96.000000  96.000000  96.00000  96.000000     96.000000   \n",
       "mean    7.159286   2.804149  20.500000   4.31191   0.184874   7921.525391   \n",
       "std     9.801956   9.707438   0.909019   9.65108   0.031292   1256.812012   \n",
       "min     0.000000   0.100000  18.000000   0.00000   0.073137   4576.345703   \n",
       "25%     0.608632   0.233310  20.000000   0.00000   0.162174   7047.493530   \n",
       "50%     1.758600   0.400000  21.000000   0.11074   0.183364   7779.157227   \n",
       "75%    13.127125   0.642450  21.000000   2.11540   0.208379   8749.439941   \n",
       "max    30.355700  65.916496  21.000000  45.77980   0.281496  11812.115234   \n",
       "\n",
       "          breath      jaild    comserd      allmort      mrall      allnite  \\\n",
       "count  96.000000  95.000000  95.000000    96.000000  96.000000    96.000000   \n",
       "mean    0.437500   0.242105   0.157895   941.979167   2.079350   191.104167   \n",
       "std     0.498682   0.430630   0.366577   947.803755   0.595899   199.769155   \n",
       "min     0.000000   0.000000   0.000000   104.000000   1.100630    18.000000   \n",
       "25%     0.000000   0.000000   0.000000   292.750000   1.623710    52.250000   \n",
       "50%     0.000000   0.000000   0.000000   723.000000   2.024030   138.500000   \n",
       "75%     1.000000   0.000000   0.000000  1076.000000   2.453930   230.000000   \n",
       "max     1.000000   1.000000   1.000000  5390.000000   4.217840  1049.000000   \n",
       "\n",
       "          mralln      allsvn       a1517    mra1517     a1517n   mra1517n  \\\n",
       "count  96.000000   96.000000   96.000000  96.000000  96.000000  96.000000   \n",
       "mean    0.000041  114.770833   62.052083   0.000306  12.822917   0.000062   \n",
       "std     0.000012  114.674595   53.314434   0.000104  13.085142   0.000037   \n",
       "min     0.000017   10.000000    5.000000   0.000141   0.000000   0.000000   \n",
       "25%     0.000032   34.750000   26.750000   0.000218   5.000000   0.000041   \n",
       "50%     0.000038   86.000000   47.500000   0.000295  10.000000   0.000054   \n",
       "75%     0.000046  134.250000   77.500000   0.000357  16.000000   0.000075   \n",
       "max     0.000086  603.000000  247.000000   0.000634  72.000000   0.000257   \n",
       "\n",
       "            a1820      a1820n    mra1820   mra1820n       a2124    mra2124  \\\n",
       "count   96.000000   96.000000  96.000000  96.000000   96.000000  96.000000   \n",
       "mean   111.770833   35.822917   0.000510   0.000161  126.885417   0.000410   \n",
       "std    108.574736   35.439495   0.000164   0.000075  132.653873   0.000130   \n",
       "min     12.000000    1.000000   0.000274   0.000025   13.000000   0.000200   \n",
       "25%     38.000000   12.000000   0.000398   0.000117   48.000000   0.000322   \n",
       "50%     84.500000   24.500000   0.000497   0.000145   96.000000   0.000394   \n",
       "75%    131.250000   45.000000   0.000573   0.000187  151.500000   0.000469   \n",
       "max    583.000000  196.000000   0.001095   0.000524  758.000000   0.000892   \n",
       "\n",
       "           a2124n   mra2124n       aidall   mraidall           pop  \\\n",
       "count   96.000000  96.000000    96.000000  96.000000  9.600000e+01   \n",
       "mean    42.875000   0.000131   300.004608   0.000068  4.932250e+06   \n",
       "std     45.471391   0.000039   312.300995   0.000027  5.102291e+06   \n",
       "min      4.000000   0.000036    27.760000   0.000023  4.789997e+05   \n",
       "25%     12.750000   0.000107    94.286499   0.000051  1.545251e+06   \n",
       "50%     31.500000   0.000127   219.675003   0.000064  3.385503e+06   \n",
       "75%     50.250000   0.000147   356.607750   0.000078  5.674987e+06   \n",
       "max    249.000000   0.000292  2094.899902   0.000172  2.831403e+07   \n",
       "\n",
       "            pop1517       pop1820       pop2124          miles       unus  \\\n",
       "count  9.600000e+01  9.600000e+01  9.600000e+01      96.000000  96.000000   \n",
       "mean   2.318125e+05  2.449765e+05  3.369480e+05   37393.980469   7.600004   \n",
       "std    2.314680e+05  2.475225e+05  3.468089e+05   38114.128906   2.111023   \n",
       "min    2.100002e+04  2.099996e+04  3.000016e+04    3993.000000   5.500000   \n",
       "25%    7.225006e+04  7.560232e+04  1.012503e+05   11426.500000   5.500000   \n",
       "50%    1.690000e+05  1.709823e+05  2.435000e+05   28090.499023   7.600000   \n",
       "75%    2.825001e+05  3.078614e+05  4.172502e+05   44537.250000   9.700000   \n",
       "max    1.157002e+06  1.321004e+06  1.892998e+06  241575.015625   9.700000   \n",
       "\n",
       "          epopus      gspch  \n",
       "count  96.000000  96.000000  \n",
       "mean   60.049969   0.006398  \n",
       "std     2.261812   0.039740  \n",
       "min    57.799999  -0.089512  \n",
       "25%    57.799999  -0.023864  \n",
       "50%    60.050001   0.008297  \n",
       "75%    62.300003   0.039652  \n",
       "max    62.300003   0.104920  "
      ]
     },
     "execution_count": 108,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import statsmodels.formula.api as smf\n",
    "\n",
    "fatality=pd.read_stata('data/fatality.dta')\n",
    "\n",
    "pd.set_option('display.max_rows', 400)\n",
    "pd.set_option('display.max_columns', 100)\n",
    "fatality.head(400)\n",
    "fatality.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1982, 1988], dtype=int64)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "[AL, AZ, AR, CA, CO, ..., VA, WA, WV, WI, WY]\n",
       "Length: 48\n",
       "Categories (48, object): [AL < AZ < AR < CA ... WA < WV < WI < WY]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import statsmodels.formula.api as smf\n",
    "\n",
    "fatality=pd.read_stata('data/fatality.dta')\n",
    "display(fatality.year.unique())\n",
    "display(fatality.state.unique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1982], dtype=int64)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "res_fat_82.summary(): \n",
      "                            OLS Regression Results                            \n",
      "==============================================================================\n",
      "Dep. Variable:                  mrall   R-squared:                       0.013\n",
      "Model:                            OLS   Adj. R-squared:                 -0.008\n",
      "Method:                 Least Squares   F-statistic:                    0.6212\n",
      "Date:                Thu, 16 Sep 2021   Prob (F-statistic):              0.435\n",
      "Time:                        09:52:10   Log-Likelihood:                -47.899\n",
      "No. Observations:                  48   AIC:                             99.80\n",
      "Df Residuals:                      46   BIC:                             103.5\n",
      "Df Model:                           1                                         \n",
      "Covariance Type:            nonrobust                                         \n",
      "==============================================================================\n",
      "                 coef    std err          t      P>|t|      [0.025      0.975]\n",
      "------------------------------------------------------------------------------\n",
      "Intercept      2.0104      0.139     14.455      0.000       1.730       2.290\n",
      "beertax        0.1485      0.188      0.788      0.435      -0.231       0.528\n",
      "==============================================================================\n",
      "Omnibus:                       17.902   Durbin-Watson:                   2.272\n",
      "Prob(Omnibus):                  0.000   Jarque-Bera (JB):               22.354\n",
      "Skew:                           1.346   Prob(JB):                     1.40e-05\n",
      "Kurtosis:                       4.983   Cond. No.                         2.63\n",
      "==============================================================================\n",
      "\n",
      "Warnings:\n",
      "[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import statsmodels.formula.api as smf\n",
    "\n",
    "fatality=pd.read_stata('data/fatality.dta')\n",
    "\n",
    "fatality_82=fatality[fatality['year']==1982]\n",
    "display(fatality_82.year.unique())\n",
    "\n",
    "reg_82 = smf.ols(formula='mrall ~ beertax',\n",
    "                      data=fatality_82)\n",
    "res_fat_82 = reg_82.fit()\n",
    "\n",
    "print(f'res_fat_82.summary(): \\n{res_fat_82.summary()}\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1982], dtype=int64)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "Text(0.5, 0, 'beertax')"
      ]
     },
     "execution_count": 101,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAe8AAAFXCAYAAACLEMbVAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADl0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uIDMuMC4yLCBodHRwOi8vbWF0cGxvdGxpYi5vcmcvOIA7rQAAIABJREFUeJzt3X10VNXB7/FfSIgmJOIAY26rRgUiwfJYTZSKxRUiIChEXgKERBNWSR/RJUWxWpC21F6tkbLsfdQKgm15qvWlEBSxaCtXaK2VhptQ34DwpAiIiJKQiTgJhRDO/YMykjAZ5iRzZs458/2s5VrOPsmczXbkN/vl7J1gGIYhAADgGD1iXQEAAGAO4Q0AgMMQ3gAAOAzhDQCAwxDeAAA4DOENAIDDJMW6AuGqr//S1M97PKny+Vosqo370F7m0F7m0F7m0WbmuLG9vN70Tq+5tuedlJQY6yo4Cu1lDu1lDu1lHm1mTry1l2vDGwAAtyK8AQBwGMIbAACHIbwBAHAYwhsAAIchvAEAcBjCGwAAhyG8AQBwGMfssOZkdXW1qqnZLJ/voDyevsrNHaqsrOxYVwsA4FCEt8Xq6mq1fv1rgdeNjQ2B1wQ4AKArGDa3WE3N5qDlW7YELwcA4EwIb4v5fAc7KW+Mck0AAG5BeFvM4+nbSXmfKNcEAOAWhLfFcnOHBi3PyQleDgDAmbBgzWInF6Vt2bJZPl+jPJ4+yslhtTkAoOsI7yjIysomrAEAEcOwOQAADkN4AwDgMIQ3AAAOQ3gDAOAwhDcAAA5DeAMA4DCENwAADkN4AwDgMIQ3AAAOQ3gDAOAwhDcAAA5jaXgfPHhQeXl52rlzZ7vyDRs2qLCwUEVFRVq5cqWVVQAAwHUsO5iktbVVCxcu1Nlnn31aeUVFhSorK5WSkqLi4mLl5+fL6/VaVRUAAFzFsp73okWLNH36dJ133nntynfu3KnMzEz17t1bycnJys3NVXV1tVXVAADAdSzpeb/00kvq06ePrrvuOi1fvrzdNb/fr/T09MDrXr16ye/3n/E9PZ5UJSUlmqqH15t+5h9CAO1lDu1lDu1lHm1mTjy1lyXhvXr1aiUkJGjTpk3avn275s2bp6VLl8rr9SotLU3Nzc2Bn21ubm4X5p3x+VpM1cHrTVd9/Zem6x6vaC9zaC9zaC/zaDNz3Nheob6MWBLezz33XODfS0tL9cADDwTmtAcMGKA9e/aoqalJqampqq6uVnl5uRXVAADAlSxbsNbRq6++qpaWFhUVFWn+/PkqLy+XYRgqLCxURkZGtKqhurpa1dRsls93UB5PX+XmDlVWVnbU7g8AQHclGIZhxLoS4TA7HBJsCKWurlbr17922s+OHn1T3Ae4G4ecrER7mUN7mUebmePG9go1bB5Xm7TU1GwOWr5lS/ByAADsKK7C2+c72El5Y5RrAgBA18VVeHs8fTsp7xPlmgAA0HVxFd65uUODlufkBC8HAMCOorba3A5OLkrbsmWzfL5GeTx9lJPDanMAgLPEVXhLJwKcsAYAOFlcDZsDAOAGhDcAAA5DeAMA4DCENwAADkN4AwDgMIQ3AAAOQ3gDAOAwhDcAAA5DeAMA4DCENwAADkN4AwDgMIQ3AAAOQ3gDAOAwhDcAAA5DeAMA4DCENwAADkN4AwDgMIQ3AAAOQ3gDAOAwhDcAAA5DeAMA4DCENwAADkN4AwDgMIQ3AAAOQ3gDAOAwhDcAAA5DeAMA4DCENwAADkN4AwDgMIQ3AAAOk2TVG7e1telHP/qRdu3apcTERFVUVCgzMzNwfcWKFaqsrFSfPn0kST/96U/Vv39/q6oDAIBrWBbeGzdulCS9+OKLqqqqUkVFhZYuXRq4vnXrVi1atEhDhgyxqgoAALiSZeE9atQojRgxQpL06aefql+/fu2ub926VcuXL1d9fb1GjBihWbNmWVUVAABcJcEwDMPKG8ybN0/r16/X448/ruHDhwfKf/nLX6qkpERpaWmaPXu2iouLlZ+f3+n7HDvWpqSkRCurCgCAI1ge3pJUX1+vadOmad26dUpNTZVhGPL7/UpPT5ckPffcc2pqatKdd94Z4j2+NHVPrzfd9O/EM9rLHNrLHNrLPNrMHDe2l9eb3uk1y1abr1mzRsuWLZMkpaSkKCEhQYmJJ3rOfr9f48ePV3NzswzDUFVVFXPfAACEybI57xtuuEH333+/brnlFh07dkwLFizQG2+8oZaWFhUVFWnu3LkqKytTcnKyhg0bpry8PKuqAgCAq0Rl2DwSGDa3Fu1lDu1lDu1lHm1mjhvbKybD5gAAwBqENwAADkN4AwDgMIQ3AAAOQ3gDAOAwhDcAAA5DeAMA4DCENwAADkN4AwDgMIQ3AAAOQ3gDAOAwhDcAAA5DeAMA4DCWHQkK2EFdXa1qajbL5zsoj6evcnOHKisrO9bVAoBuIbzhWnV1tVq//rXA68bGhsBrAhyAkzFsDteqqdkctHzLluDlAOAUhDdcy+c72El5Y5RrAgCRRXjDtTyevp2U94lyTQAgsghvuFZu7tCg5Tk5wcsBwClYsNYFrGB2hpP/TbZs2Syfr1EeTx/l5PDfCoDzEd4msYLZWbKysvnvAsB1GDY3iRXMAIBYo+dtUixWMDNMDwA4FeFtksfTV42NDUHKrVnBzDA9AKAjhs1NivYKZobpAQAd0fM2KdormNloBADQEeHdBdFcwRztYXoAgP0xbG5zbDQCAOiInrfNsdEIAKAjwtsB2GgEAHAqhs0BAHAYwhsAAIchvAEAcBjCGwAAhyG8AQBwGMvCu62tTffff7+mT5+uW265RR9//HG76xs2bFBhYaGKioq0cuVKq6oBAIDrWBbeGzdulCS9+OKLmjNnjioqKgLXWltbVVFRod/85jd69tln9fvf/1719fVWVQUAAFexLLxHjRqlBx98UJL06aefql+/foFrO3fuVGZmpnr37q3k5GTl5uaqurraqqoAAOAqlm7SkpSUpHnz5mn9+vV6/PHHA+V+v1/p6emB17169ZLf77eyKgAAuIblO6wtWrRI9957r6ZNm6Z169YpNTVVaWlpam5uDvxMc3NzuzAPxuNJVVJSoql7e72h3xPt0V7m0F7m0F7m0WbmxFN7WRbea9as0eeff65Zs2YpJSVFCQkJSkw8Eb4DBgzQnj171NTUpNTUVFVXV6u8vDzk+/l8Labu7/Wmq77+yy7XP97QXubQXubQXubRZua4sb1CfRmxLLxvuOEG3X///brlllt07NgxLViwQG+88YZaWlpUVFSk+fPnq7y8XIZhqLCwUBkZGVZVBQAAV7EsvFNTU/XYY491ev3666/X9ddfb9XtAQBwLTZpAQDAYQhvAAAchvAGAMBhCG8AAByG8AYAwGEIbwAAHMbyHdYAhKeurlY1NZvl8x2Ux9NXublDlZWVHetqAbAhwhuwgbq6Wq1f/1rgdWNjQ+A1AQ6gI4bNARuoqdkctHzLluDlAOIb4Q3YgM93sJPyxijXBIATEN6ADXg8fTsp7xPlmgBwAsIbsIHc3KFBy3NygpcDiG8sWANs4OSitC1bNsvna5TH00c5Oaw2BxAc4Q3YRFZWNmENICwMmwMA4DD0vF2KDT8AwL1ChveaNWtC/vLEiRMjWhlEBht+AIC7hQzvqqqqkL9MeNtTqA0/CG8AcL6Q4V1RURGteiCC2PADANwtZHhff/31SkhI6PT6m2++GfEKofs8nr5qbGwIUs6GHwDgBiHD+9lnn41WPRBBublD2815n8SGHwDgDiHD+/zzz5ckHT16VH/5y1/U3NwsSWpra9Mnn3yiu+66y/oawjQ2/AAAdwvrUbF77rlHX3zxhT7++GNdddVVqqqqUk5OjtV1Qzew4QcAuFdYm7Ts2LFDzzzzjEaPHq3vfve7euGFF7Rv3z6r6wYAAIIIK7z79u2rhIQEXXLJJdqxY4cuvPBCtba2Wl03AAAQRFjD5llZWXrwwQdVXFyse++9VwcOHJBhGFbXDQAABBFWeP/kJz/Ru+++q4EDB+p73/ueNm3apEcffdTquiFMbIUKAPElrPCeOnWqXn75ZUnSyJEjNXLkSEsrhfCxFSoAxJ+w5rz79eun6upqHT161Or6wKRQW6ECANwprJ73Bx98oNLS0tPKt2/fHvEKwRy2QgWA+BNWeK9bt07r1q3ToUOHrK4PTGIrVACIP2ENm992222qra21ui7ogtzc4FueshUqALhXWD1vSXr44YetrAe6iK1QASD+hBXeo0aN0qpVq3TNNdcoMTExUP71r3/dsoohfGyFal88xgfACmGFd0tLix5++GF5PJ5AWUJCAkeCAiHwGB8Aq4QV3hs3btSmTZt09tlnW10fwDVCPcZHeAPojrDC+/zzz9cXX3wRdni3trZqwYIF2rdvn44ePao77rij3cYuK1asUGVlpfr0ObEi+qc//an69+/fherbE0OlkHiMD4B1wgrv1tZWjRs3TllZWerZs2eg/Jlnngn682vXrtW5556rxYsXy+fzadKkSe3Ce+vWrVq0aJGGDBnSzerbD0Ol9hLLL1I8xgfAKmGF9+23327qTceOHasxY8YEXp+6yE06Ed7Lly9XfX29RowYoVmzZpl6fztjqNQ+Yv1FKjd3aLv7n8RjfAC6K6zwHjrU3F82vXr1kiT5/X7NmTNHd999d7vr48aNU0lJidLS0jR79mxt3LhR+fn5Id/T40lVUlJiyJ/pyOtNN/XzkRBqqDQW9THD7vUzq7KyOmj5++/X6Nprr+72+5+pvbzeq3XOOSl6++23VV9fL6/Xq+HDh7tyxCkcbvt8RQNtZk48tVfYz3mbtX//ft15550qKSlRQUFBoNwwDM2YMUPp6ScaOS8vT9u2bTtjePt8Labu7/Wmq77+S/MV76ZQQ6WxqE+4YtVeVqqvr++0vLt/1nDbKyPjIhUWXtTh/u5q53C48fNlNdrMHDe2V6gvI2HtsGZWQ0ODZs6cqfvuu09Tpkxpd83v92v8+PFqbm6WYRiqqqpyVU+EHc/sw+Pp20k5c84AnM2SnvdTTz2lQ4cOacmSJVqyZImkE8eKHj58WEVFRZo7d67KysqUnJysYcOGKS8vz4pqxAQ7ntkHc84A3CrBMAwj1pUIh9nhEDcOoVjJre1VV1dryRcpt7aXVWgv82gzc9zYXqGGzS2b8wbsgK1jAbiRJXPeAADEg7a2Nn300T/12mt/0Cef7I3afel5wzLsNAfAaQzD0Oeff6bt27eptna7duw48c/27dvV0tJ8xt//7LMm9ehhfb+Y8IYlYr1BCgCc9MUXTaqtrdWOHdtVW3silGtrt6mh4fTHervjnnt+EJXglghvWISd5gBY5V//+pfq6v4nEMQ7dmxXXd0O7dq1K+L38nrPU3b2ZRo8eLCysy/ToEHZuvTSQerd+9yI38sMwhuW4FAOAOFqa2vT7t0fBekdb4/4vdLS0pWdPVjZ2YM1aFC2srMvU3b2ZTrvvPOUkJAQ8ftZhfCGJTiUA4hfhmHos8/2BwK4tnbbv0O5Nqx5YzN69OihQYMG64orLtcll2QFeseZmReddq6GmxDesAQbpADu0tTkU21tbSCId+yotWTeWJIuvviSf/eIv+odDxyYpbPOOqvT33Hjc96hEN6wBDvNAfZ2+PBh/fOf/9Oud1xbu117934c8XtlZPwvDRo0WNnZ2e1COT39nIjfK14Q3rAMG6QA0XNy3nj79pPD1Cfnj62bNx48+GQQn/jHafPGTkZ4x6Fgz197vd0/IhNA5BiGoerqzXrllZe1du3L2r//U8vulZiYGJgrPrGY60QoZ2ZeFLVHn2AO4R1nOnv++pxzUpSRcVGI3wTQXXv27NYrr7ykl19era1bP7D0Xpdc0l+DBg0+5RGnwRowYGDIeWM4B+EdZzp7/vrtt98+7dxpAKH5fI1at+5VrVnzkt56a2PU7pube7UmTpys6dNvifnzxogNwtvmIr3FaGfPX9fX13f5PQG3OHLkiDZufFOvvPKS1qxZrba2tqjc9+KLL9GkSYWaMKFQgwdfpoSEhJCrp0/+vfD88yvYejhOEd42ZsUWo509f+31ertWScDGDMNQTc3/05o1q7VmzUs6cODzqNw3Pf0cTZgwSRMmTNa3v32dkpIi91ctWw9DIrxtzYotRjt7/nr48OFdej8g2nbt+ujfPeOXtG3bh1G779ix4zRpUqFGjx6rtLS0qN23I7YehkR4WyJSQ91WbDHa2fPXQ4YMiasNDmAfJ+eNX355tf761z9H7b5XX/0tTZw4WePHT9DXvvb1qN23u9h6GBLhHXGRHNKyaotRnr+GlQ4fPqyXXlqlX/1qmeUrqk/Vv/8ATZgwSRMnTtHgwZdF7b7RxtbDkAjviIvkkFZ3thjlLG1EyvHjx/W73/1WP/jBXB0/fjxq9z3nnN6aOLFQEydO1rBh33b1PtVmsPUwJMI74iI5pNXVLUZZ0IIzeeedt/X978/Rzp3/jOp9BwwYqPLy2zRtWrHOOad3VO/tFmw9DInwjrhID2l1ZYibBS3xZ/fuXfrRj+bpjTf+GPV7z5lzj2bMmKkLL8zs9Gfi7dAIqzH1BcI7wuwwpMWCFufz+7/U4sWPaOnSJ6J+7/PPv0CLFj2qG264sdOf6Tgt869/tUSxhoC9xGKakvB2IRa02E9bW5seeeQhPfbYozG5/4MPVmjmzNvUs2fPbr8X0zLAV2L1/wPhHWF2GLK2Q+8/HvzhD2s1c+atMbn3zJn/qXnzfhiTL2R2+IwDdhGr/x8I7wizw5C1Exe02GF1/LZtWzVlSoEaGk4ftbBa797natWqNbriipyo39ssO3zGAbuI1f8PhHeE2WXI2kkLWqwadvrss/26/PJB3a5fV/3yl8s0bVpxzO5vlUh8xu3wZQ2IhFj9nU94RxhD1uaFO+zU2tqqyZPHq6pqU7Sq1s6dd96lBQsWqmfPnnG9erq7n3HmzOEmsfo7n/COMCcOWcfSj388X8uWLen0+ve+N9uye+fl5Wvp0l+rX79+lt3Djbr7GWfOHG4Sq7/zCW8LOGnIOtJefrlSs2bNjNn9f//7l5WfPzJm948X3fmMM2cOt4nF3/mEN0LasaNW110XuyH/mTP/U488EpvHq2ANu6wLAZyM8I4zfr9f/fvH7gSlCy64UJs2bdFZZ53VrryurpaphjjBuhCg+whvF7jggn46evRozO7/979vUf/+A7v0ux1XHY8cOZbQdjnWhQDdR3jb0IoVv9K8effE7P7/9V9PqqSk1PL7sOo4fsXzuhAgEgjvbgj3WdUPPnhPI0deF4MantCnTx/V1u4OvF669P/IMIzTfq5Hjx66/fa7o1YvVh0DQNcQ3l1w7NgxLVhwn/77v38dszrs3v2ZUlNTu/S7dlkwxKpjAOgawvvfWlpa9OGHH+i3v/21/vznDaqvPxDV+2/aVKMBA7Kici+7LBiyy5cIAHAaS8K7tbVVCxYs0L59+3T06FHdcccdGjnyq2dvN2zYoCeffFJJSUkqLCzUtGnTrKhGp3bsqNXDD/9vff75fjU0NKihoV4tLZE90vD551dp1KgxEX3PSAm2YGjEiDxlZFwU1XrY5UsEADiNJeG9du1anXvuuVq8eLF8Pp8mTZoUCO/W1lZVVFSosrJSKSkpKi4uVn5+vrxerxVVCWrbtg/1xz+uU8+ePdWvn1cDB16qfv36acOG/xv057OzB+uRRx7VtdcOD5S9+OIzQXuNffv2U1FRmWV1j5SOC4Zisd0nq44BoGssCe+xY8dqzJivep2JiYmBf9+5c6cyMzPVu3dvSVJubq6qq6t14403WlGVoCZNmqKbbipQcnKyEhISuvQe9Bojg1XHAGCeJeHdq1cvSSc2BJkzZ47uvvurFcx+v1/p6entftbv95/xPT2eVCUlJZ7x507l9aaHuBrqWjjvfbXOOSdFb7/9turr6+X1ejV8+HANGTKkW+8bS6HbCx3RXubQXubRZubEU3tZtmBt//79uvPOO1VSUqKCgoJAeVpampqbmwOvm5ub24V5Z3w+c3PS0RgGzsi4SIWF7eeJnXrSVDyfktUVtJc5tJd5tJk5bmyvUF9GLAnvhoYGzZw5UwsXLtSwYcPaXRswYID27NmjpqYmpaamqrq6WuXl5VZUI6Y4rxgAYBVLwvupp57SoUOHtGTJEi1ZcuK4x6lTp+rw4cMqKirS/PnzVV5eLsMwVFhYqIyMDCuqETPsHAYAsFKCEWyrLRsyOxwSyyEUJ65Ed+OQk5VoL3NoL/NoM3Pc2F6hhs17RLEecYOdwwAAVmKHNQtYsXMYc+gAgJPoeVsgNzf4s95dfQb85Bx6Y2ODDMMIzKHX1dV2p5oAAIei522BSO8cxulbAIBTEd5BRGKIOpI7hzGHDgA4FeHdgR0f8+L0LQDAqZjz7iDUEHWsRHoOHQDgbPS8O7DjELUVp291nBrIz4/+kaAAgK4hvDuw6xB1JOfQg00NrF69WqNH38QCOABwAMK7Azse9RnpZ7xZvQ4AzkZ4d2DFEHV3WLGAzo5TAwCA8BHeQURyiLq7rOgl23VqAAAQHlab25wVvWRWrwOAs9HztpFgc9tW9JKDTQ2MGMFqcwBwCsLbQmYWmnU2t/0f/3FF0PDubi+549SAG4/TAwC3YtjcImYPE+lsbvvTTz/R6NE3qW/ffurRo4f69u3HI10AEOfoeVvE7EKzUHPbdlpABwCIPXreFjG70Mzj6dtJOSvAAQDtEd4WMRvGrAAHAISL8LaI2TDOyspmbhsAEBbmvC3SlZ3amNsGAISD8LYQYQwAsALh7UCRPqgEAOAshLdFrApYKw4qAQA4CwvWLGB2gxYz3nnnr0HLN20KXg4AcB963t3QWe/ayvOym5uDb2Hq97O1KQDEC8K7i0INX3NeduQwvw8Ap2PYvItC9a6t3C0tLS3dVLmTWTn9AABORnh3UajetZW7pQ0bdp2pcicL9QUJAOIZw+ZdFOqc7a5s0BIuK9/bbph+AIDgCO8uys0d2m7O+6STvWsrN2iJl81fQn1BAoB4xrB5F7EXufU4rAUAgqPn3Q3x0gOOlXiaIgAAMwjvGLPzo1B2qBtfkADgdIR3DNl5q1M71w0A4p2lc97vvfeeSktLTytfsWKFxo0bp9LSUpWWluqjjz6yshq2ZedHoexcNwCId5b1vJ9++mmtXbtWKSkpp13bunWrFi1apCFDhlh1e1vpbPjZykehujvkzWNaAGBflvW8MzMz9cQTTwS9tnXrVi1fvlzFxcVatmyZVVWwhVC7hFm1E1skdiazcpc4AED3WNbzHjNmjD755JOg18aNG6eSkhKlpaVp9uzZ2rhxo/Lz80O+n8eTqqSkRFN18Hpjv2VoZWV10PL3369Rfn6eVq9efdq1ESPyulX3UPe89tqrO/29U+9pVd3chHYwh/YyjzYzJ57aK+oL1gzD0IwZM5SefqKR8/LytG3btjOGt8/XYuo+Xm+66utjf9JWfX19p+UZGRdp9OibTnsUKiPjom7VPdQ9O3vfju1lVd0iKZar4e3y+XIK2ss82swcN7ZXqC8jUQ9vv9+v8ePH67XXXlNqaqqqqqpUWFgY7WpEzZl2CbPiUahI7Uxm58e0WA0PIJ5FLbxfffVVtbS0qKioSHPnzlVZWZmSk5M1bNgw5eXlRasalgjVAzzTNqpWiMU9o83KM9MBwO4sDe8LLrhAK1eulCQVFBQEyidOnKiJEydaeWvTujoEe6YeYCx2CYuHnclYDQ8gnrFJi7o3BBtODzAWw892HvKOBA4tARDPOJhE3duQhB5gbHBoCYB4Rs9b3QtgeoCxEQ9TAwDQGcJb3QvgaCwOs8MBIXbk9qkBAOgMw+bq3hCs1ed6R2K3NACAu9DzVveHYK3sAfJIFACgI8L73+w6BMuCOABARwyb2xwHhAAAOiK8bY5HogAAHTFsbnM8EgUA6IjwdgC7zscDAGKDYXMAAByG8AYAwGEIbwAAHIbwBgDAYQhvAAAchtXmneAwEACAXRHeQZw8DOSkk4eBSCLAAQAxx7B5EKEOAwEAINYI7yA4DAQAYGeEdxAcBgIAsDPCOwgOAwEA2BkL1oLgMBAAgJ0R3p2I1mEgPJIGADCL8I4hHkkDAHQFc94xxCNpAICuILxjiEfSAABdwbB5N3R3vtrj6avGxoYg5TySBgDoHD3vLjo5X93Y2CDDMALz1XV1tWG/B4+kAQC6gp53F4Warw63980jaQCAriC8uyhS89XReiQNAOAeDJt3EVuoAgBihfDuIuarAQCxwrB5FzFfDQCIFcK7G5ivBgDEAsPmAAA4jKXh/d5776m0tPS08g0bNqiwsFBFRUVauXKllVUAAMB1LBs2f/rpp7V27VqlpKS0K29tbVVFRYUqKyuVkpKi4uJi5efny+v1WlUVAABcxbKed2Zmpp544onTynfu3KnMzEz17t1bycnJys3NVXV1tVXVAADAdSzreY8ZM0affPLJaeV+v1/p6emB17169ZLf7z/j+3k8qUpKSjRVB683/cw/hADayxzayxzayzzazJx4aq+orzZPS0tTc3Nz4HVzc3O7MO+Mz9di6j5eb7rq6780Xb94RXuZQ3uZQ3uZR5uZ48b2CvVlJOqrzQcMGKA9e/aoqalJR48eVXV1ta688spoVwMAAMeKWs/71VdfVUtLi4qKijR//nyVl5fLMAwVFhYqIyMjWtUAAMDxEgzDMGJdiXCYHQ5x4xCKlWgvc2gvc2gv82gzc9zYXqGGzR0T3gAA4AR2WAMAwGEIbwAAHIbwBgDAYQhvAAAchvAGAMBhCG8AABzG8eF9/PhxLVy4UEVFRSotLdWePXvaXV+5cqUmT56sadOmaePGjTGqpX2cqb0eeughTZ48WaWlpSotLdWXX7rrucmu4nhbczprrxUrVmjcuHGBz9dHH30Ug9rZR2trq+677z6VlJRoypQpevPNN9td5/PV3pnaK64+X4bD/elPfzLmzZtnGIZh/OMf/zBuv/32wLUDBw4Y48ePN44cOWIcOnQo8O/xLFR7GYZhTJ8+3Th48GAsqmZby5cvN8aPH29MnTq1XfnRo0eNUaNGGU1NTcaRI0eMyZMnGwcOHIhRLe230ZYqAAAF70lEQVSjs/YyDMP4/ve/b3zwwQcxqJU9VVZWGg899JBhGIbR2Nho5OXlBa7x+TpdqPYyjPj6fDm+511TU6PrrrtOknTFFVfoww8/DFx7//33deWVVyo5OVnp6enKzMxUbW1trKpqC6Ha6/jx49qzZ48WLlyo6dOnq7KyMlbVtBWOtzWns/aSpK1bt2r58uUqLi7WsmXLolwz+xk7dqzuuuuuwOvExK9OTuTzdbpQ7SXF1+cr6qeKRZrf71daWlrgdWJioo4dO6akpKQuHz/qZqHaq6WlRbfeequ+853vqK2tTWVlZRoyZIiys7NjWOPYi/Txtm7XWXtJ0rhx41RSUqK0tDTNnj1bGzduVH5+fpRraB+9evWSdOKzNGfOHN19992Ba3y+TheqvaT4+nw5vufd8YjR48ePKykpKei1cI8fdbNQ7ZWSkqKysjKlpKQoLS1N11xzTdyPVITC58scwzA0Y8YM9enTR8nJycrLy9O2bdtiXa2Y279/v8rKyjRhwgQVFBQEyvl8BddZe8Xb58vx4Z2Tk6O33npLkvTuu+/q0ksvDVy7/PLLVVNToyNHjujLL7/Uzp07212PR6Haa/fu3SopKVFbW5taW1u1ZcsWfeMb34hVVW2P423N8fv9Gj9+vJqbm2UYhqqqqjRkyJBYVyumGhoaNHPmTN13332aMmVKu2t8vk4Xqr3i7fPl+GHz0aNH629/+5umT58uwzD08MMPa8WKFcrMzNTIkSNVWlqqkpISGYahuXPn6qyzzop1lWPqTO1VUFCgadOmqWfPnpowYYKysrJiXWXb4Xhbc05tr7lz56qsrEzJyckaNmyY8vLyYl29mHrqqad06NAhLVmyREuWLJEkTZ06VYcPH+bzFcSZ2iuePl+cKgYAgMM4ftgcAIB4Q3gDAOAwhDcAAA5DeAMA4DCENwAADkN4Ay5WVVUV9ICQ7rr//vu1b9++iL8vgPAQ3gBMq6qqEk+ZArFDeAMu5/P5VF5eroKCAv3whz/U0aNH9dZbb2nKlCmaOHGiZs+eLZ/PJ+nEYT7FxcWaNGmSZs6cqb1790qSSktLNXv2bI0ZM0bLly/XgQMHdNttt8nn8+n111/XtGnTdPPNN2vs2LHasmWL/H6/rr/+em3atEmSVF5erueeey5mbQC4TmwOMwMQDX//+9+Nb37zm8auXbuM48ePG3fddZfxxBNPGDfffLPR1NRkGIZhvPDCC8aCBQuMI0eOGAUFBca+ffsMwzCMt956y5gxY4ZhGIZx6623Go8//njgffPz8429e/cabW1tRllZWeAY2VWrVhmzZs0yDMMw3nnnHeOGG24wfve73xnl5eVR/FMD7uf47VEBhHbVVVfp4osvliQVFBRo/vz5SkhIUFlZmaQTh9P07t1bu3fv1t69e3XHHXcEfvfUU6wuv/zy0967R48eevLJJ7Vhwwbt2rVLmzdvVo8eJwb0hg0bpmuuuUa/+MUv9Prrr1v4JwTiD+ENuNzJU+MkBeapc3Jy9NRTT0mSjhw5oubmZh04cEAXXHCBXnnlFUlSW1ubGhoaAr979tlnn/bezc3NmjJlim6++WZdffXVGjRoUGB43DAM7dq1SykpKdq1a5fOO+88y/6MQLxhzhtwuZqaGn366ac6fvy41qxZoxkzZujdd9/Vrl27JElLlizRz3/+c/Xv319ffPGFqqurJUmrV6/WvffeG/Q9ExMT1dbWpt27dyshIUG33367vvWtb2n9+vVqa2uTJD3//PNKTU3VkiVL9OMf/7jd8ZYAuoeeN+ByAwcO1IIFC1RfX69rrrlGd9xxhy677DLdfffdOn78uDIyMrR48WIlJyfrscce089+9jMdOXJEaWlpWrRoUdD3HDFihG677TY9/fTTGjx4sG688UYlJCRo+PDhqqmp0d69e7V06VKtWrVKX/va1zR8+HAtXrxYDzzwQHT/8IBLcaoYAAAOw7A5AAAOQ3gDAOAwhDcAAA5DeAMA4DCENwAADkN4AwDgMIQ3AAAOQ3gDAOAw/x9Z68oyIy0l6QAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<Figure size 576x396 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import statsmodels.formula.api as smf\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "fatality=pd.read_stata('data/fatality.dta')\n",
    "\n",
    "fatality_82=fatality[fatality['year']==1982]\n",
    "display(fatality_82.year.unique())\n",
    "\n",
    "reg_82 = smf.ols(formula='mrall ~ beertax',\n",
    "                      data=fatality_82)\n",
    "res_fat_82 = reg_82.fit()\n",
    "\n",
    "\n",
    "plt.style.use('seaborn')\n",
    "plt.plot('beertax', 'mrall', data=fatality_82, color='grey', marker='o', linestyle='')\n",
    "plt.plot(fatality_82['beertax'],res_fat_82.fittedvalues, color='black', linestyle='-')\n",
    "plt.ylabel('mrall')\n",
    "plt.xlabel('beertax')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1988], dtype=int64)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "res_fat_88.summary(): \n",
      "                            OLS Regression Results                            \n",
      "==============================================================================\n",
      "Dep. Variable:                  mrall   R-squared:                       0.134\n",
      "Model:                            OLS   Adj. R-squared:                  0.115\n",
      "Method:                 Least Squares   F-statistic:                     7.118\n",
      "Date:                Thu, 17 Sep 2020   Prob (F-statistic):             0.0105\n",
      "Time:                        11:29:06   Log-Likelihood:                -32.871\n",
      "No. Observations:                  48   AIC:                             69.74\n",
      "Df Residuals:                      46   BIC:                             73.49\n",
      "Df Model:                           1                                         \n",
      "Covariance Type:            nonrobust                                         \n",
      "==============================================================================\n",
      "                 coef    std err          t      P>|t|      [0.025      0.975]\n",
      "------------------------------------------------------------------------------\n",
      "Intercept      1.8591      0.106     17.540      0.000       1.646       2.072\n",
      "beertax        0.4388      0.164      2.668      0.011       0.108       0.770\n",
      "==============================================================================\n",
      "Omnibus:                        5.076   Durbin-Watson:                   2.311\n",
      "Prob(Omnibus):                  0.079   Jarque-Bera (JB):                4.414\n",
      "Skew:                           0.741   Prob(JB):                        0.110\n",
      "Kurtosis:                       3.112   Cond. No.                         2.95\n",
      "==============================================================================\n",
      "\n",
      "Warnings:\n",
      "[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import statsmodels.formula.api as smf\n",
    "\n",
    "fatality=pd.read_stata('data/fatality.dta')\n",
    "\n",
    "fatality_88=fatality[fatality['year']==1988]\n",
    "display(fatality_88.year.unique())\n",
    "\n",
    "reg_88 = smf.ols(formula='mrall ~ beertax',\n",
    "                      data=fatality_88)\n",
    "res_fat_88 = reg_88.fit()\n",
    "    \n",
    "print(f'res_fat_88.summary(): \\n{res_fat_88.summary()}\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1988], dtype=int64)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "Text(0.5, 0, 'beertax')"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 576x396 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import statsmodels.formula.api as smf\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "fatality=pd.read_stata('data/fatality.dta')\n",
    "\n",
    "fatality_88=fatality[fatality['year']==1988]\n",
    "display(fatality_88.year.unique())\n",
    "\n",
    "reg_88 = smf.ols(formula='mrall ~ beertax',\n",
    "                      data=fatality_88)\n",
    "res_fat_88 = reg_88.fit()\n",
    "\n",
    "plt.style.use('seaborn')\n",
    "plt.plot('beertax', 'mrall', data=fatality_88, color='grey', marker='o', linestyle='')\n",
    "plt.plot(fatality_88['beertax'],res_fat_88.fittedvalues, color='black', linestyle='-')\n",
    "plt.ylabel('mrall')\n",
    "plt.xlabel('beertax')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "res_fat8288.summary(): \n",
      "                            OLS Regression Results                            \n",
      "==============================================================================\n",
      "Dep. Variable:                  mrall   R-squared:                       0.046\n",
      "Model:                            OLS   Adj. R-squared:                  0.036\n",
      "Method:                 Least Squares   F-statistic:                     4.552\n",
      "Date:                Thu, 16 Sep 2021   Prob (F-statistic):             0.0355\n",
      "Time:                        06:28:23   Log-Likelihood:                -83.748\n",
      "No. Observations:                  96   AIC:                             171.5\n",
      "Df Residuals:                      94   BIC:                             176.6\n",
      "Df Model:                           1                                         \n",
      "Covariance Type:            nonrobust                                         \n",
      "==============================================================================\n",
      "                 coef    std err          t      P>|t|      [0.025      0.975]\n",
      "------------------------------------------------------------------------------\n",
      "Intercept      1.9438      0.087     22.290      0.000       1.771       2.117\n",
      "beertax        0.2685      0.126      2.134      0.035       0.019       0.518\n",
      "==============================================================================\n",
      "Omnibus:                       26.827   Durbin-Watson:                   1.353\n",
      "Prob(Omnibus):                  0.000   Jarque-Bera (JB):               41.725\n",
      "Skew:                           1.229   Prob(JB):                     8.70e-10\n",
      "Kurtosis:                       5.094   Cond. No.                         2.76\n",
      "==============================================================================\n",
      "\n",
      "Warnings:\n",
      "[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import statsmodels.formula.api as smf\n",
    "\n",
    "fatality=pd.read_stata('data/fatality.dta')\n",
    "fatality_8288=fatality[(fatality['year']==1982) | (fatality['year']==1988)]\n",
    "\n",
    "fatality_8288.head()\n",
    "\n",
    "reg_8288 = smf.ols(formula='mrall ~ beertax',\n",
    "                      data=fatality_8288)\n",
    "res_fat_8288 = reg_8288.fit()\n",
    "print(f'res_fat8288.summary(): \\n{res_fat_8288.summary()}\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1982, 1988], dtype=int64)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "Text(0.5, 0, 'beertax')"
      ]
     },
     "execution_count": 103,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 576x396 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import statsmodels.formula.api as smf\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "fatality=pd.read_stata('data/fatality.dta')\n",
    "\n",
    "fatality_8288=fatality[(fatality['year']==1982) | (fatality['year']==1988)]\n",
    "display(fatality_8288.year.unique())\n",
    "\n",
    "reg_8288 = smf.ols(formula='mrall ~ beertax',\n",
    "                      data=fatality_8288)\n",
    "res_fat_8288 = reg_8288.fit()\n",
    "\n",
    "plt.style.use('seaborn')\n",
    "plt.plot('beertax', 'mrall', data=fatality_8288, color='grey', marker='o', linestyle='')\n",
    "plt.plot(fatality_8288['beertax'],res_fat_8288.fittedvalues, color='black', linestyle='-')\n",
    "plt.ylabel('mrall')\n",
    "plt.xlabel('beertax')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "res_fat_all.summary(): \n",
      "                            OLS Regression Results                            \n",
      "==============================================================================\n",
      "Dep. Variable:                  mrall   R-squared:                       0.046\n",
      "Model:                            OLS   Adj. R-squared:                  0.036\n",
      "Method:                 Least Squares   F-statistic:                     4.552\n",
      "Date:                Thu, 17 Sep 2020   Prob (F-statistic):             0.0355\n",
      "Time:                        11:32:30   Log-Likelihood:                -83.748\n",
      "No. Observations:                  96   AIC:                             171.5\n",
      "Df Residuals:                      94   BIC:                             176.6\n",
      "Df Model:                           1                                         \n",
      "Covariance Type:            nonrobust                                         \n",
      "==============================================================================\n",
      "                 coef    std err          t      P>|t|      [0.025      0.975]\n",
      "------------------------------------------------------------------------------\n",
      "Intercept      1.9438      0.087     22.290      0.000       1.771       2.117\n",
      "beertax        0.2685      0.126      2.134      0.035       0.019       0.518\n",
      "==============================================================================\n",
      "Omnibus:                       26.827   Durbin-Watson:                   1.353\n",
      "Prob(Omnibus):                  0.000   Jarque-Bera (JB):               41.725\n",
      "Skew:                           1.229   Prob(JB):                     8.70e-10\n",
      "Kurtosis:                       5.094   Cond. No.                         2.76\n",
      "==============================================================================\n",
      "\n",
      "Warnings:\n",
      "[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import statsmodels.formula.api as smf\n",
    "\n",
    "fatality=pd.read_stata('data/fatality.dta')\n",
    "\n",
    "reg_all = smf.ols(formula='mrall ~ beertax',\n",
    "                      data=fatality)\n",
    "res_fat_all = reg_all.fit()\n",
    "\n",
    "print(f'res_fat_all.summary(): \\n{res_fat_all.summary()}\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Text(0.5, 0, 'beertax')"
      ]
     },
     "execution_count": 105,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAe8AAAFXCAYAAACLEMbVAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADl0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uIDMuMC4yLCBodHRwOi8vbWF0cGxvdGxpYi5vcmcvOIA7rQAAIABJREFUeJzt3Xt8VPWB9/HvkIgmJGIIQ7bixlaIpS2gJYrgAw1XCZcoGiEQTXhqtoIVBVwpl1pWX7WyrM9q1QoW29IXri0itF6KoBSol4qwCfWGxaWIKJeagQRhEgoxOc8fyGxCZibnzJwzM2fm8/7LnDNz5pefE77ndz0ewzAMAQAA1+gU7wIAAABrCG8AAFyG8AYAwGUIbwAAXIbwBgDAZQhvAABcJj3eBTDL5zse0ftycjJVX99oc2mSF/VlHnVlDfVlDfVlTTLWl9ebHfJc0re809PT4l0EV6G+zKOurKG+rKG+rEm1+kr68AYAINkQ3gAAuAzhDQCAyxDeAAC4DOENAIDLEN4AALgM4Q0AgMsQ3gAAuIxrdlhzu927d6mmZrvq648oJydXhYUDVVDQJ97FAgC4EOEdA7t379LGjS8Ffq6rOxz4mQAHAFhFt3kM1NRsD3p8x47gxwEACIfwjoH6+iMhjtfFuCQAgGRAeMdATk5uiOPdYlwSAEAyILxjoLBwYNDjAwYEPw4AQDhMWIuBM5PSduzYrvr6OuXkdNOAAcw2BwBEhvCOkYKCPoQ1AMAWdJsDAOAyhDcAAC5DeAMA4DKENwAALkN4AwDgMoQ3AAAuQ3gDAOAyhDcAAC5DeAMA4DKENwAALkN4AwDgMo6G95EjR1RUVKQ9e/a0Ob5582aVlpaqrKxMq1evdrIIAAAkHcceTNLU1KRFixbpvPPOa3d88eLFWrNmjTIyMjR16lQNHz5cXq/XqaIAAJBUHGt5L1myRFOmTFGPHj3aHN+zZ4/y8/PVtWtXde7cWYWFhaqurnaqGAAAJB1HWt6/+93v1K1bNw0dOlTLly9vc87v9ys7Ozvwc5cuXeT3+zu8Zk5OptLT0yIqj9eb3fGLEEB9mUddWUN9WUN9WZNK9eVIeK9du1Yej0dbt27VX//6V82bN0/Lli2T1+tVVlaWGhoaAq9taGhoE+ah1Nc3RlQWrzdbPt/xiN6biqgv86gra6gva6gva5KxvsLdjDgS3k8//XTgvysqKnTvvfcGxrR79eqlffv26ejRo8rMzFR1dbWqqqqcKAYAAEnJsQlrZ3vxxRfV2NiosrIyzZ8/X1VVVTIMQ6WlpcrLy4tVMQJ2796lmprtqq8/opycXBUWDlRBQZ+YlwMAAKs8hmEY8S6EGZF2hwTrStm9e5c2bnyp3WtHjx6X8gGejF1PTqGurKG+rKG+rEnG+grXbZ6Sm7TU1GwPenzHjuDHAQBIJCkZ3vX1R0Icr4txSQAAsC4lwzsnJzfE8W4xLgkAANalZHgXFg4MenzAgODHAQBIJDGbbZ5IzkxK27Fju+rr65ST000DBjDbHADgDikZ3tLpACesAQBulJLd5gAAuBnhDQCAyxDeAAC4DOENAIDLEN4AALgM4Q0AgMsQ3gAAuAzhDQCAyxDeAAC4DOENAIDLEN4AALgM4Q0AgMsQ3gAAuAzhDQCAyxDeAAC4DOENAIDLEN4AALgM4Q0AgMsQ3gAAuAzhDQCAyxDeAAC4DOENAIDLEN4AALgM4Q0AgMsQ3gAAuAzhDQCAyxDeAAC4DOENAIDLEN4AALgM4Q0AgMukO3Xh5uZm3XPPPdq7d6/S0tK0ePFi5efnB86vWLFCa9asUbdu3SRJ9913ny655BKnigMAQNJwLLy3bNkiSVq1apW2bdumxYsXa9myZYHzO3fu1JIlS9S3b1+nigAAQFJyLLxHjRqlYcOGSZIOHjyo7t27tzm/c+dOLV++XD6fT8OGDdP06dOdKgoAAEnFYxiG4eQHzJs3Txs3btSjjz6qIUOGBI7/7Gc/U3l5ubKysjRz5kxNnTpVw4cPD3mdL75oVnp6mpNFBQDAFRwPb0ny+XyaPHmy1q1bp8zMTBmGIb/fr+zsbEnS008/raNHj+r2228Pc43jEX2215sd8XtTEfVlHnVlDfVlDfVlTTLWl9ebHfKcY7PNn3vuOf385z+XJGVkZMjj8Sgt7XTL2e/3a8KECWpoaJBhGNq2bRtj3wAAmOTYmPc111yjBQsW6KabbtIXX3yhhQsX6pVXXlFjY6PKyso0Z84cVVZWqnPnzho8eLCKioqcKgoAAEklJt3mdqDbPDaoL/OoK2uoL2uoL2uSsb7i0m0OAACcQXgDAOAyhDcAAC5DeAMA4DKENwAALkN4AwDgMoQ3AAAuQ3gDAOAyhDcAAC5DeAMA4DKENwAALkN4AwDgMoQ3AAAu49gjQYFEsXv3LtXUbFd9/RHl5OSqsHCgCgr6xLtYABAxwhtJbffuXdq48aXAz3V1hwM/E+AA3CrlwjsZW2HJ+DvZpaZme9DjO3Zsp44AuFZKhXcytsKS8XeyU339kRDH62JcEgCwT0pNWAvXCnOrZPyd7JSTkxvieLcYlwQA7JNS4Z2MrbBk/J3sVFg4MOjxAQOCHwcAN0ipbvOcnFzV1R0Octx6KyxRxpnt/J2S0Zn/Jzt2bFd9fZ1ycrppwADmBABwt5QK78LCgW3Gh8+w2gpLpHFmu36nZFZQ0IewBpBUUiq87WqFJdIMZlqWAJB6Uiq8JXtaYfEYZw7XTU/LEgBSS8qFtx1iPc6cSN30AID4S6nZ5naJ9QxmloMBAFqj5R2BWI8zsxwMANAa4R2hWI4zsxwMANAa3eYuwEYjAIDWaHm7AMvBAACtEd4uwXIwAMAZdJsDAOAyhDcAAC5DeAMA4DKENwAALkN4AwDgMo6Fd3NzsxYsWKApU6bopptu0ieffNLm/ObNm1VaWqqysjKtXr3aqWIAAJB0HAvvLVu2SJJWrVqlO++8U4sXLw6ca2pq0uLFi/WrX/1KTz31lJ555hn5fD6nigIAQFJxbJ33qFGjNGzYMEnSwYMH1b1798C5PXv2KD8/X127dpUkFRYWqrq6WmPHjnWqOACSWLhH5gLJyNFNWtLT0zVv3jxt3LhRjz76aOC43+9XdnZ24OcuXbrI7/c7WRQASYpH5iIVOb7D2pIlS3T33Xdr8uTJWrdunTIzM5WVlaWGhobAaxoaGtqEeTA5OZlKT0+LqAxeb/hroy3qyzzqyhon6mvNmuqgx999t0ZXX32l7Z8XS3y/rEml+nIsvJ977jl99tlnmj59ujIyMuTxeJSWdjp8e/XqpX379uno0aPKzMxUdXW1qqqqwl6vvr4xonJ4vdny+Y5H9N5URH2ZR11Z41R9hZov4/P5XP3/h++XNclYX+FuRhwL72uuuUYLFizQTTfdpC+++EILFy7UK6+8osbGRpWVlWn+/PmqqqqSYRgqLS1VXl6eU0UBkMR4ZC5SkWPhnZmZqUceeSTk+REjRmjEiBFOfTyAFFFYOLDNmPcZPDIXyYynigFwNR6Zi1REeANwPR6Zi1TD9qgAALgM4Q0AgMsQ3gAAuAzhDQCAyzBhDUgQ7M8NwCzCG0gA7M8NwAq6zYEEUFOzPejxHTuCHweQ2ghvIAHU1x8JcbwuxiUB4AaEN5AAcnJyQxxnf24A7RHeQAIoLAy+Dzf7cwMIhglrQAJgf24AVhDeQIJgf24AZhHegFhjDcBdCO8kRiCZwxprAG4TNryfe+65sG+eOHGirYWBfQgk88KtsaauACSisOG9bdu2sG8mvBMXgWQea6wBuE3Y8F68eHGsypEUnOymtnptAsm8nJxc1dUdDnKcNdYAElPY8B4xYoQ8Hk/I85s2bbK9QG7lZDd1JNcmkMwrLBzYpn7PYI01gEQVNryfeuqpWJXD9Zzspo7k2gSSeayxBuA2YcO7Z8+ekqRTp07p1VdfVUNDgySpublZ+/fv16xZs5wvoUs42U0dybUJJGtYYw3ATUwtFbvrrrv0+eef65NPPtEVV1yhbdu2acCAAU6XzVWc7KaO9NoEEgAkJ1N7m3/44YdauXKlRo8erX/5l3/Rb3/7Wx04cMDpsrmKk3tTs+81ACSOhoYGrVv3ou64Y4YKCvLVo8f56tHjfI0ZM0wtLS0xKYOplndubq48Ho++9rWv6cMPP9TEiRPV1NTkdNlcxcluarrAASD2du/+H61fv04bNqxTdXXwuUet7dmzJ+wkbzuZCu+CggL9+Mc/1tSpU3X33XertrZWhmE4XTbXcbKbmi5wALDfiRMn9Nprf9KGDeu0fv0fVFdnfp5S9+5ejR07XmPHjteQIUU677zzHCxpW6bC+9/+7d/09ttvq3fv3rrjjju0detW/ed//qfTZYNFbIcKAMF99NEebdjwkjZsWKe33nrT0nuvumqwiovHq7h4rHr1KnCohNaYCu9Jkybp97//vSRp5MiRGjlypKOFgnVshwogUsly4/+Pf/xDb7zxqtavPx3SPl+t6ffm5OR8GdDjVVQ0XJmZmQ6WNHqmwrt79+6qrq5W//791blzZ6fLhAiwHSqASLjxxn/fvo/18ssvacOGl/TGG69Zem9h4RUaO3aCiovHq6Dg0piNUdvNVHi/9957qqioaHf8r3/9q+0FSiV23u2yHSqASCTqjf+pU6f05z+/rg0b1mnDhpd06NBB0+/Nzj5fxcXjVFw8XsOHj1BWVraDJY0PU+G9bt06rVu3TseOHXO6PCnD7rtdtkMFEIl43/gfOLA/MBb96qtbLL33ssu+HQjpoqJBOnzY71ApE4+p8L711lv19a9/XRdeeKHT5UkZZu52rbTM2Q4VQCRicePf1NSkt956M9CK/vTTT0y/NzMzMxDQI0aM0vnndw36Ord2f0fKVHhL0gMPPOBkOVJOR3e7Vlvmdq4FT5bJKwA6ZueN/9//fkgvv7xeGzas06ZNGy2991vf6qfi4nEaO3a8+vW7LOXC2CpT4T1q1Cg9++yzGjRokNLS0gLHaYlHrqO73UjGoexYC/7++++7bvJKouNmCInM6o1/c3Oztm9/K7B5yccf7zX9Weecc86Xk8XGaeTI0QzrRcFUeDc2NuqBBx5QTk5O4JjH4+GRoFHo6G43XuNQr7/+etDj8Z684lZunMmL1BPsxr+2tlYbN27Qhg3r9PLL6y1dr0+fb3y57GqcLr98gDp1MrUTNywwFd5btmzR1q1bY7p7TLLr6G43XhPQfD5f0OPMWo9Mos7kBSSppaVF1dX//eVY9Dr97W+7Tb/X4/GouPj07mKjRo1R9+7dHSwpzmYqvHv27KnPP//cdHg3NTVp4cKFOnDggE6dOqXbbrutzcYuK1as0Jo1a9St2+kguu+++3TJJZdEUPzEZaarNFw3d7wmoHm9XtXWtt/YgO6tyMR7Ji8gSUeOHNHGjRsCXd1Wtrfu3bsgsHlJYeEVbYZOET+mwrupqUnjx49XQUGBzjnnnMDxlStXBn39Cy+8oAsuuEAPPvig6uvrdf3117cJ7507d2rJkiXq27dvlMVPTHZ0lcbrYSRDhw7V2rVr2x1386z1WI05B/sclvAx5h8rLS0tevvtHYFlV7t2WduH45prilVcPF6jRxcrLy/PoVLCLqbCe8aMGZYuWlxcrDFjxgR+PvtObefOnVq+fLl8Pp+GDRum6dOnW7p+orOrqzQeDyPp27evjh07kTRPMIvVmHOoz+nX7/Kg4e3mmyErGPO338cf79W8eXdpyxbrc46++tWvBbq6r7zyKqWnm15whARj6v/cwIHW/qHp0qWLJMnv9+vOO+/U7Nmz25wfP368ysvLlZWVpZkzZ2rLli0aPnx42Gvm5GQqPT2y7hqvN7a764TrKo11WSJx9dVX6uqrr4x3MWyxZk110OPvvltjy+945v9nqM+prT2k0tJSvfHGG/L5fPJ6vRoyZEjS9jqdzen6T1YtLS36xS9+oe9973sRvb+4uFjXXXedSkpK1LNnT5tLl7jc8O+rXRy77Tp06JBuv/12lZeXq6SkJHDcMAxNmzZN2dmnK7moqEgffPBBh+FdX98YUTm83mz5fMcjem+kwnWVWimLme5Gu7sk41FfTgo1Ac/n80X9e7auq3Cfk5d3sUpLLz7rePLUcThO1n8yOHBgvxYu/IHWr/9DRO/Pzj5fv/710xo06Oo2Q5qtpUo9J9u/XVL4mxFHwvvw4cO65ZZbtGjRIg0ePLjNOb/frwkTJuill15SZmamtm3bptLSUieKETNnB2jPnhdF3VVqpruRLsmOxWrMmbHt4KiX0w2WNWue0ezZt6upqSmia/TuXaCHHvqZBg0a3PGLkRIcCe8nnnhCx44d09KlS7V06VJJpx8reuLECZWVlWnOnDmqrKxU586dNXjwYBUVFTlRjJgIFqB1dYfVr9/lOnhwf8TjxmbGzVmG1LFYzdpne9rgUqlePvvsMy1aNF+//337CZ9m3XbbHZo7d4GysrKSsiUJ+zgS3vfcc4/uueeekOcnTpyoiRMnOvHRjgrWRR0qQA8e3K+yssqIP8vMEiOWIXUsVrP22Z42uHitmnCKYRj6wx+e1513fl8NDZE9BCM//2I99NBj+s53htlbOKQUphqaFKqLOtT+u9EGqJnuRrokzYnVrH07PicZh0LO1IubWpJHjhzRvff+UM8885uIr3HLLd/TggU/UteuF9hYMuA0wtukUC3sTp06qbm5ud3xaAPUTHdjKnVJpgqGQmLrlVfWa9as7+vIkeC9WB3p0SNPP/3pzzRq1JiOXwzYiPA2KVQXdUtLS9Dj0Qaome5GN3RJJlMXcCwwFGK/zz8/qh//+F6tXPmriK9x002V+tGP7lO3brk2lgyIHOFtUqgu6m7dcjVgwEBHAtRMN2w8NnIxKxm7gJ3GUEjkXn11i2bN+r4OHjwQ0fu7dr1AP/3p4xo3bgKPo0TCI7xNCtdFncgBGk90AVvHUEh4fv9x/fu/36/ly5dFfI3S0sm6996fsAUoXI3wNskNXdSJhi5g6/ienfbWW29q1qzva+/ejyJ6/3nnnaef/vRxXX/9jbSikZQIbwtoYVtDF3BkUuV75vcf15w5d+j5538X8TUmTLhO99//77rwwtTZAhSQCG84iC5gSKfHoidNui6qazzyyFKVlZWrU6dONpUKcDfCG5aZnUFOF3DqOHHihObNu0urVj0d8TVGjbpGixf/P1188VftKxiQpAhvWGJ1BnmqdAGnihdffE5VVZHvHChJd901V3PnLmz3qGAA5hHeKSrS9dfMIE9+J06c0NixI/XBB+9HfI3c3FytXv28+vXrHzjmph3WgERHeKegcK1nrzf8M5aZQZ48Nm16RVOn3hjVNa64YqCef359yMdRAnAG4Z2CwrWer746fHgzg9xdTp06pRtumKDt29+K6jpPPfWMxowZa1OpAESL8HYBu7cYjab1zAzyxPTnP7+u668fH9U1vvGNb2r9+s3KzMy0qVRwCtsOg/COktN/RE5sMRpN65kZ5PHzxRdfqKKiTJs2bYzqOsuXr9DEiaU2lQqxxrbDkAjvqMTij8iJCWLRtp6ZQe6smpr/1tixI6O6xkUX/bP+9Kc3df75XW0qFRIFk0YhEd5R6eiPyI5WuRMTxGg9x19LS4uGDLlSf/vb7qiu8/DDP9NNN0W3dAvuwqRRSIR3VML9EdnVKndqghit59iwY0Z3164XaNu2v/A4Skhi0ihOI7yjEO6PyK6urWi6uJnUEhuGYWjcuFGqqfnvqK4zffrt+vGPF9tUKiQrJo1CIryjEu6P6I9/XB/0PVa7tiLt4mZSi/3ee+8djRw5NOrr1NS8r3/+53wbSoRUxLAXJMI7KuH+iGpqttvWtRVJFzeTWiJ3882T9corG6K6xqBBV+uFF6K7BhAKw14gvKMU6o+oZ8+LgoZ3rLq2mNQS3u7d/6P/83+uiPo6b75Zo969C2wokfswLAOcFo+/BcLbAbt379J7773d7ni/fpfH7B83JrWc1q/fpfrss79HdY3i4vFaufK37Y6n8l7dDMsAp8Xrb4HwdkCoLuuDB/e3O+bUHVsqTWp57713NXLkkKivs2nTG20epIHQGJYBTovX3wLh7QCzXdZO3rG5cVJLRzcyPXqcH/VnXHJJL23dukMejyfqa6UyhmWA0+L1t0B4O8Bsl7XTd2xumtRy5kbmwIEDevLJJ6O+3i9/+ZRKSq6zoWQIxo5hGcbMkQziNURJeDvAbJd1KrdeevW6SMePH4v6OocO1SstLc2GEsGKaIdlGDNHsojXECXh7QCzXdbJPqls166/6jvfuSrq61x11VUaO7bt4yhHjx7HP/JxFO2wDGPmSBbxGqIkvB1ipss6WSaV2TEWLUk//OEPdc4557Q5lpaWpubm5nav5R/5+ItmWCaVe52QfOIxREl4x5GbJpUdPHhAl1/+jaivM21alR588GFJ0qpVK4P2PLQWLLgl/pF3u2TvdQKcRnjHWTwnlQWbMNS//7X6+9+jWxd9+tqfqGvXC8K+JlTrS5Jyc7trwICBtu5Uh8SRLL1OQLwQ3ino738/pP79vx71dS6++Kv67nf/b7vjo0eP6zC4pdCtr7S0tDY9EPwjn3zc1OsEJCLCO4nZNRb97rsf6p/+6Svtjofq9jY7Hh2q9dXc3Nxu5jH/yCcfNy1lBBIN4R2leK9Vras7oj59vmbLte6991516tRJM2bMNvX6aCcdnamnzZtfDjspjX/kAaAtwjsKsVyreuml+Tp69GjU1zmzBWioVrPX6zV9LTsmHRUU9LHt8akAkCoI7yjYvVb1H//4h/Lze0RbLEnSo4/+LGxvQKgu6yFDzO8RbtekI2YeA4A1joR3U1OTFi5cqAMHDujUqVO67bbbNHLkyMD5zZs36/HHH1d6erpKS0s1efJkJ4rhuEi7jUtLr9Xrr/8p6s//9a9/o3HjJrQ5dqY34EwYhuoNCDWW3LdvX9NPyrJrPJqZxwBgjSPh/cILL+iCCy7Qgw8+qPr6el1//fWB8G5qatLixYu1Zs0aZWRkaOrUqRo+fLil7tpEEa7F2NzcrK98JceWz6mtNb+NqJXeADvGku26hsSkNAAwy5HwLi4u1pgxYwI/t957es+ePcrPz1fXrl0lSYWFhaqurm63/aUbFBYO1EMPLdHatWvbnbvjjpmWrvX448s1adKUqMvk1p2rmJQGAOY5Et5dunSRJPn9ft15552aPft/Zy/7/X5lZ2e3ea3f7+/wmjk5mUpPj+wBFF5vdscvCsMwDM2ePVuPPvpoVNeRTs/oPlteXp5mzPhe1NeWTk84q62tDXr87Hp4//339frrr8vn88nr9Wro0KHyevtGXV+phLqyhvqyhvqyJpXqy7EJa4cOHdLtt9+u8vJylZSUBI5nZWWpoaEh8HNDQ0ObMA+lvr4xonJ4vdmmx3CPHftcP/nJfVqx4hcRfdYZv/zlSpWUTGx3fNmyh2UYRrvjPp/PdBk7ctllVwQdP+7fv7DNZ5w9U762tjbQg5CXd7EtZUkkTizps/LdAvVlFfVlTTLWV7ibEUfC+/Dhw7rlllu0aNEiDR48uM25Xr16ad++fTp69KgyMzNVXV2tqqoqJ4oRkmEY2rGjWh9+uEt/+9tu7dr1gf74x1csXaNfv8u0adPrHb6udWh06tQp6HrmaGdVnx1M/fpdroMH94cdPw41Nv7GG2+otDS5wpvHTwJINo6E9xNPPKFjx45p6dKlWrp0qSRp0qRJOnHihMrKyjR//nxVVVXJMAyVlpYqLy/PiWKE9PTTK3XXXXd0+Lorr7xKv/rVU8rL+6eIPufs0Aj1kI1oZlUHC6a6usMdPjIz1Ni4z+eLuCyJisdPAkg2joT3Pffco3vuuSfk+REjRmjEiBFOfLQpI0aM0ty5C3ThhT3Vq1eBCgouVW5uru2fEyo00tLSZBiGLbOqIw2mUDPl3TjrvyNuncQHAKGk5CYtF17YU3PnLmh33O5x0VChYRiG6S1II/2MjoLJjk1a3IJNYAAkm5QM72CcGBd1IjTOvsHIzMxSQ0P7SRodfYYdm7S4BZvAAEg2hPeXnBgXtTs0gt1ghGLmM1JlbTWbwABINoT3l5wYF7U7NELdYGRlZevcc88lmMJIlRsVAKmB8P5SqC7ulpYWrVq1MuLxbztDI9QNRmNjgyor7dnkBQCQ+AjvL4Xq4pYSZ11wpGPo8X7mOADAXp3iXYBEUVDQR6NHj1NubveQr9mxI3i3dawUFgYfxw43vt36KWOGYQRuRHbv3uVUMQEADqPl3cqZLu5Q25jGe11wJGPo4SbinTnfukXu9V5pf8EBALYivINI5HXBVsfQQ42T19UdCbo07vzzM5Jyb3MASCZ0mwcRSfe003bv3qVVq1Zq2bKHtWrVStPd3jk5wXeO69Qp+P/6N954I+IyAgBig/AOovX4d6dOnZSb273DvcKdFM24dagbkZaWlqDHk3FvcwBINnSbh5BI64Kj2UAm1Dh5Tc122/c2Z1Y7AMQG4e0C0W4gE+pGxM69zXnsJgDEDuGdgM5uwXbpkiW/3/r+5eHYvbe504/dpFUPAP+L8I4BK8Fj9/7l4cRi9zc7ltfRqgeAtpiw5jCrk83C7V+eKBPoggk1q92O5XUdrVUHgFRDy9thVruT3bp/uZOP3XSyVQ8AbkR4O8xq8CTyBjHhOPnYTbfWCQA4hfB2mNXgcbIF6zSnlte5uU4AwAmEt42CTUyzGjxOtmDdijoBgLY8RrAncCSgSJYvSZLXmx3xe604e0b0GaNHj5PknuCJVX0lA+rKGurLGurLmmSsL683O+Q5Wt4WhFvy9eabrwd9z9atr6uy8nsJG9YAAPchvE3qaK1xQ0PwO75gm6vYWSY2LgGA1EN4mxTNDmKrVq20PWDZuAQAUhfhbVJHS76ysrJDtrLPzDa3M2DDddNbvXbrFrzX69Vll13BDQAAJDDC26RQS74yM7to1aqVamjwm75WJPt9n91Fblc3/dkt+NraWlrwAJDgCG+TQi35Oh2WbQPT4/GoW7dcHTkSfF/yurrgrfhQrOx3bpXTDxSxA2P7ANAWe5ubVFDQR6NHj2uzv3iXLsGn8Xfrlquyskp169Y96HnDMEJjtoxcAAAOYElEQVTubR5MqIANJisr9NKCYBJ961Gre8MDQCogvC0oKOijsrJKjRxZLMNQyK7rM8FXWBh6BzArD9UIFbDBDB481PRrJWcfKGIHHkoCAO0R3ha1bgmGcib4Cgr6yOPxBH2NlZZtqIC140ljoW4wEmXr0UTvGQCAeGDM2yIzXditg8+Oh2qEGm8fPHho1GO/Z2896vV61b9/YcKMKfNQEgBoj/C2KFwXdm5u93Zbn7rhoRqtHyiSaFsMuqH+ACDWCG+LQrUEc3O7q6ysst1xOx6q4YYZ4U7hoSQA0B7hbVEkLcGOHpXZ0VKoeI/7RrNUy45lXk49ahQA3IrwtsjulqCZbU7jOe4bzTasbOEKAM5wdLb5O++8o4qKinbHV6xYofHjx6uiokIVFRX66KOPnCyG7c4sGZsxY7YGDBiomprtWrbsYa1atdLy+mMzS6HiOSM8mqVaLPMCAGc41vJ+8skn9cILLygjI6PduZ07d2rJkiXq27evUx8fEx21LFt3GWdmZsnjkRoa/G26j810iUfa2rejyzqaLvt4d/cDQLJyLLzz8/P12GOP6Qc/+EG7czt37tTy5cvl8/k0bNgwTZ8+3aliOKqjlmXrYG+9oUvrkDfbJW513NeuLutouuxZ5gUAznAsvMeMGaP9+/cHPTd+/HiVl5crKytLM2fO1JYtWzR8+PCw18vJyVR6elpEZfF6rW0Zala4luU771R3+P53363R8OFFWrt2bbtzw4YVRVXuNWuCf/6779bo6quvDPve1p8bTfmc+t0SSbL8HrFCfVlDfVmTSvUV8wlrhmFo2rRpys4+XclFRUX64IMPOgzv+vrGiD7PyXXL4VqWPp+vw/f7fD7l5V2s0aPHtesSz8u7OKpyh/p8n88X9rpn11c05XPqd2stng8tSbQ18YmO+rKG+rImGesr3M1IzMPb7/drwoQJeumll5SZmalt27aptLQ01sWwRbhlYzU12zt8+lfrbVTtDhw7u6yjKZ+Ty7yYzQ4gVcVsb/MXX3xRzzzzjLKzszVnzhxVVlaqvLxcvXv3VlFRUayKYavWTxrzeDxKS0uTx+NRTc129ex5UYfvd3K2eKLvWW4HZrMDSFWOtrwvuugirV69WpJUUlISOD5x4kRNnDjRyY+OSCRdsGfOb9z4kpqbmyWdbgHW1R1Wv36X6+DB/aqvr1NmZhdJUmNjg6nZ4tF2B6fCzmTMZgeQqtik5UvRdMGGagEePLg/6JapTpaltWTfmYzZ7ABSFY8E/VI0XbB2twDpDjYnFYYGACAYWt5fiiaA7W4B0h1sTioMDQBAMIT3l6IJYLsfWxmqLB6PR8uWPRzzJVGJLNmHBgAgGLrNdXqM+dSpk0HPmQng1rPOO3XqpNzc7ho9elzEoRKqO7i5uVmGYQTGwK3uow4ASA4p3/I+e3LYGVlZ2Ro8eKjpALazBXh2d7DH4wnMZG8tFZ7nDQBoL+XDO9TksHPPPTeuwdj6ZmDZsoeDvoYxcABITSnfbe6GyWE5ObkhjrMkCgBSUcqHtxuCkSVRAIDWUj683RCMdk+IAwC4W8qPebtlrTBLogAAZ6R8eEsEIwDAXVK+2xwAALeh5d2B1k/3yszMkscjNTT42eUMABA3hHcYZ2/g0tBwPPDfkT7pCwCAaNFtHkaoDVxa40lfAIBYo+UdRqgNXNq+puPNXFp3vdPdDgCIFuEdRpcuWfL7j4d9TUebuZzd9U53OwAgWnSbh2EYHb+mo81cQnW9090OAIgULe8wGhv9Ic/l5nY3tZmLG/ZOBwC4C+EdRk5OrurqDrc7npvbXWVllVFdI5H2TgcAuAvd5mHYse+5G/ZOBwC4Cy3vMOzY99wte6cDANyD8O6AHfued3QNlpIBAKwgvOOMpWQAAKsY844zlpIBAKwivOOMpWQAAKvoNo9StOPVLCUDAFhFyzsKZ8ar6+oOyzCMwHj17t27TF+DpWQAAKtoeUch3Hi12dY3S8kAAFYR3lGwa7zajuVoAIDUQbd5FHJyckMcZ7waAOAcwjsKjFcDAOKBbvMoMF4NAIgHwjtKjFcDAGKNbnMAAFzG0fB+5513VFFR0e745s2bVVpaqrKyMq1evdrJIgAAkHQc6zZ/8skn9cILLygjI6PN8aamJi1evFhr1qxRRkaGpk6dquHDh8vr9TpVFAAAkopjLe/8/Hw99thj7Y7v2bNH+fn56tq1qzp37qzCwkJVV1c7VQwAAJKOYy3vMWPGaP/+/e2O+/1+ZWdnB37u0qWL/H5/h9fLyclUenpaRGXxerM7fhECqC/zqCtrqC9rqC9rUqm+Yj7bPCsrSw0NDYGfGxoa2oR5KPX1jRF9ntebLZ/veETvTUXUl3nUlTXUlzXUlzXJWF/hbkZiPtu8V69e2rdvn44ePapTp06purpa3/72t2NdDAAAXCtmLe8XX3xRjY2NKisr0/z581VVVSXDMFRaWqq8vLxYFQMAANfzGIZhxLsQZkTaHZKMXSlOor7Mo66sob6sob6sScb6Ctdt7prwBgAAp7HDGgAALkN4AwDgMoQ3AAAuQ3gDAOAyhDcAAC5DeAMA4DJJEd4tLS1atGiRysrKVFFRoX379rU5v3r1at1www2aPHmytmzZEqdSJo6O6uv+++/XDTfcoIqKClVUVOj48eRaOxkpHnFrXqi6WrFihcaPHx/4bn300UdxKF3iaGpq0ty5c1VeXq4bb7xRmzZtanOe71ZbHdVXSn2/jCTw8ssvG/PmzTMMwzD+8pe/GDNmzAicq62tNSZMmGCcPHnSOHbsWOC/U1m4+jIMw5gyZYpx5MiReBQtYS1fvtyYMGGCMWnSpDbHT506ZYwaNco4evSocfLkSeOGG24wamtr41TKxBCqrgzDMP71X//VeO+99+JQqsS0Zs0a4/777zcMwzDq6uqMoqKiwDm+W+2Fqy/DSK3vV1K0vGtqajR06FBJ0uWXX673338/cO7dd9/Vt7/9bXXu3FnZ2dnKz8/Xrl274lXUhBCuvlpaWrRv3z4tWrRIU6ZM0Zo1a+JVzITCI27NC1VXkrRz504tX75cU6dO1c9//vMYlyzxFBcXa9asWYGf09L+98mJfLfaC1dfUmp9v2L+VDEn+P1+ZWVlBX5OS0vTF198ofT09IgfQZrMwtVXY2Ojbr75Zn33u99Vc3OzKisr1bdvX/Xp0yeOJY4/ux9xm8xC1ZUkjR8/XuXl5crKytLMmTO1ZcsWDR8+PMYlTBxdunSRdPp7dOedd2r27NmBc3y32gtXX1Jqfb+SouV99mNGW1palJ6eHvSc2UeQJrNw9ZWRkaHKykplZGQoKytLgwYNSvmeinD4fplnGIamTZumbt26qXPnzioqKtIHH3wQ72LF3aFDh1RZWanrrrtOJSUlgeN8t4ILVV+p9v1KivAeMGCAXnvtNUnS22+/rUsvvTRwrn///qqpqdHJkyd1/Phx7dmzp835VBSuvj7++GOVl5erublZTU1N2rFjh771rW/Fq6gJj0fcmuf3+zVhwgQ1NDTIMAxt27ZNffv2jXex4urw4cO65ZZbNHfuXN14441tzvHdai9cfaXa9yspus1Hjx6tP//5z5oyZYoMw9ADDzygFStWKD8/XyNHjlRFRYXKy8tlGIbmzJmjc889N95FjquO6qukpESTJ0/WOeeco+uuu04FBQXxLnLC4RG35rWuqzlz5qiyslKdO3fW4MGDVVRUFO/ixdUTTzyhY8eOaenSpVq6dKkkadKkSTpx4gTfrSA6qq9U+n7xVDEAAFwmKbrNAQBIJYQ3AAAuQ3gDAOAyhDcAAC5DeAMA4DKEN5DEtm3bFvQBIdFasGCBDhw4YPt1AZhDeAOwbNu2bWKVKRA/hDeQ5Orr61VVVaWSkhL98Ic/1KlTp/Taa6/pxhtv1MSJEzVz5kzV19dLOv0gn6lTp+r666/XLbfcok8//VSSVFFRoZkzZ2rMmDFavny5amtrdeutt6q+vl7r16/X5MmTde2116q4uFg7duyQ3+/XiBEjtHXrVklSVVWVnn766bjVAZB04vMwMwCx8NZbbxmXXXaZsXfvXqOlpcWYNWuW8dhjjxnXXnutcfToUcMwDOO3v/2tsXDhQuPkyZNGSUmJceDAAcMwDOO1114zpk2bZhiGYdx8883Go48+Grju8OHDjU8//dRobm42KisrA4+QffbZZ43p06cbhmEYb775pnHNNdcY//Vf/2VUVVXF8LcGkl9SbI8KILQrrrhCX/3qVyVJJSUlmj9/vjwejyorKyWdfjBN165d9fHHH+vTTz/VbbfdFnhv66dY9e/fv921O3XqpMcff1ybN2/W3r17tX37dnXqdLpDb/DgwRo0aJAeeughrV+/3sHfEEg9hDeQ5M48MU5SYJx6wIABeuKJJyRJJ0+eVENDg2pra3XRRRfp+eeflyQ1Nzfr8OHDgfeed9557a7d0NCgG2+8Uddee62uvPJKff3rXw90jxuGob179yojI0N79+5Vjx49HPsdgVTDmDeQ5GpqanTw4EG1tLToueee07Rp0/T2229r7969kqSlS5fqP/7jP3TJJZfo888/V3V1tSRp7dq1uvvuu4NeMy0tTc3Nzfr444/l8Xg0Y8YMXXXVVdq4caOam5slSb/5zW+UmZmppUuX6kc/+lGbx1sCiA4tbyDJ9e7dWwsXLpTP59OgQYN022236Zvf/KZmz56tlpYW5eXl6cEHH1Tnzp31yCOP6Cc/+YlOnjyprKwsLVmyJOg1hw0bpltvvVVPPvmkvvGNb2js2LHyeDwaMmSIampq9Omnn2rZsmV69tln9ZWvfEVDhgzRgw8+qHvvvTe2vzyQpHiqGAAALkO3OQAALkN4AwDgMoQ3AAAuQ3gDAOAyhDcAAC5DeAMA4DKENwAALkN4AwDgMv8fDb94mKNWAC0AAAAASUVORK5CYII=\n",
      "text/plain": [
       "<Figure size 576x396 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import statsmodels.formula.api as smf\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "fatality=pd.read_stata('data/fatality.dta')\n",
    "\n",
    "reg_all = smf.ols(formula='mrall ~ beertax',\n",
    "                      data=fatality)\n",
    "res_fat_all = reg_all.fit()\n",
    "\n",
    "plt.style.use('seaborn')\n",
    "plt.plot('beertax', 'mrall', data=fatality, color='grey', marker='o', linestyle='')\n",
    "plt.plot(fatality['beertax'],res_fat_all.fittedvalues, color='black', linestyle='-')\n",
    "plt.ylabel('mrall')\n",
    "plt.xlabel('beertax')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=========================================================\n",
      "              y82         y88        y8288        yall   \n",
      "              (1)         (2)         (3)         (4)    \n",
      "---------------------------------------------------------\n",
      "Intercept 2.010381*** 1.859073*** 1.943759*** 1.943759***\n",
      "          (0.139078)  (0.105989)  (0.087204)  (0.087204) \n",
      "beertax   0.148460    0.438755**  0.268473**  0.268473** \n",
      "          (0.188368)  (0.164454)  (0.125835)  (0.125835) \n",
      "N         48          48          96          96         \n",
      "R2        0.01        0.13        0.05        0.05       \n",
      "=========================================================\n",
      "Standard errors in parentheses.\n",
      "* p<.1, ** p<.05, ***p<.01\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import statsmodels.formula.api as smf\n",
    "from statsmodels.iolib.summary2 import summary_col\n",
    "\n",
    "fatality=pd.read_stata('data/fatality.dta')\n",
    "\n",
    "fatality_82=fatality[fatality['year']==1982]\n",
    "reg_82 = smf.ols(formula='mrall ~ beertax',\n",
    "                      data=fatality_82)\n",
    "\n",
    "fatality_88=fatality[fatality['year']==1988]\n",
    "reg_88 = smf.ols(formula='mrall ~ beertax',\n",
    "                      data=fatality_88)\n",
    "\n",
    "fatality_8288=fatality[(fatality['year']==1982) | (fatality['year']==1988)]\n",
    "reg_8288 = smf.ols(formula='mrall ~ beertax',\n",
    "                      data=fatality_8288)\n",
    "\n",
    "res_fat_8288 = reg_8288.fit()\n",
    "reg_all = smf.ols(formula='mrall ~ beertax',\n",
    "                      data=fatality)\n",
    "res_fat_all = reg_all.fit()\n",
    "\n",
    "\n",
    "output = summary_col([res_fat_82, res_fat_88, res_fat_8288, res_fat_all],stars=True,float_format='%0.6f',\n",
    "                  model_names=['y82\\n(1)','y88\\n(2)','y8288\\n(3)','yall\\n(4)'],\n",
    "                  info_dict={'N':lambda x: \"{0:d}\".format(int(x.nobs)),\n",
    "                             'R2':lambda x: \"{:.2f}\".format(x.rsquared)})\n",
    "print(output)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "**Panel Data**\n",
    "\n",
    "- Should we conclude that an increase in the tax on beer leads to more traffic deaths?\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "**Panel Data**\n",
    "\n",
    "- Should we conclude that an increase in the tax on beer leads to more traffic deaths?\n",
    "- Not necessarily, because these regressions could have substantial omitted variable bias.\n",
    "- Many factors affect the fatality rate:\n",
    "    - the quality of the automobiles driven in the state,\n",
    "    - whether the state highways are in good repair,\n",
    "    - whether most driving is rural or urban,\n",
    "    - the density of cars on the road,\n",
    "    - and whether it is socially acceptable to drink and drive."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "**Panel Data**\n",
    "\n",
    "- Any of these factors may be correlated with alcohol taxes, and if so, this will lead to omitted variable bias.\n",
    "- One approach to these potential sources of omitted variable bias would be to collect data on all these variables and add them to the annual cross-sectional regressions.\n",
    "- Unfortunately, some of these variables, such as the cultural acceptance of drinking and driving, might be very hard or even impossible to measure.\n",
    "- But: If these factors remain constant over time in a given state, however, then another route is available.\n",
    "- Because we have panel data, we can, in effect, hold these factors constant even though we cannot measure them.\n",
    "- To do so, we use OLS regression with **fixed effects**."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "**Panel Data with Two Time Periods: \"Before and After\" Comparisons**\n",
    "\n",
    "- When data for each state are obtained for $T = 2$ time periods, it is possible to compare values of the dependent variable in the second period to values in the first period.\n",
    "- By focusing on changes in the dependent variable, this \"before and after\" or \"differences\" comparison, in effect, holds constant the unobserved factors that differ from one state to the next but do not change over time within the state.\n",
    "- Let $Z_i$ be a variable that determines the fatality rate in the $i^th$ state but does not change over time (so the $t$ subscript is omitted).\n",
    "- For example, $Z_i$ might be the local cultural attitude toward drinking and driving, which changes slowly and thus could be considered to be constant between 1982 and 1988.\n",
    "- What else could be $Z_i$?\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "**Panel Data with Two Time Periods: \"Before and After\" Comparisons**\n",
    "    \n",
    "- Accordingly, the population linear regression relating $Z_i$ and the real beer tax to the fatality rate is\n",
    "\n",
    "\\begin{equation*}\n",
    "FatalityRate_{it}=\\beta_0+\\beta_1BeerTax_{it}+\\beta_2z_i+u_{it}\n",
    "\\end{equation*}\n",
    "\n",
    "where $u_{it}$ is the error term, $i = 1,..,n$, and $t = 1,...,T$.\n",
    "\n",
    "- Because $z_i$ does not change over time, in the regression model in it will not produce any change in the fatality rate between 1982 and 1988.\n",
    "- Thus, in this regression model, the influence of $z_i$ can be eliminated by analyzing the change in the fatality rate between the two periods.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "**Panel Data with Two Time Periods: \"Before and After\" Comparisons**\n",
    "\n",
    "- To see this mathematically, consider the equation below for each of the two years 1982 and 1988:\n",
    "\n",
    "\\begin{equation*}\n",
    "FatalityRate_{i1982}=\\beta_0+\\beta_1BeerTax_{i1982}+\\beta_2z_i+u_{i1982}\n",
    "\\end{equation*}\n",
    "\n",
    "\\begin{equation*}\n",
    "FatalityRate_{i1988}=\\beta_0+\\beta_1BeerTax_{i1988}+\\beta_2z_i+u_{i1988}\n",
    "\\end{equation*}\n",
    "\n",
    "Subtracting the second from the first equation eliminates the effect of $Z_i$:\n",
    "\n",
    "\\begin{equation*}\n",
    "FatalityRate_{i1988}- FatalityRate_{i1982} =\\beta_1(BeerTax_{i1988}-BeerTax_{i1982}+u_{i1988}-u_{i1982}\n",
    "\\end{equation*}\n",
    "\n",
    "- This specification has an intuitive interpretation.\n",
    "- Cultural attitudes toward drinking and driving affect the level of drunk driving and thus the traffic fatality rate in a state.\n",
    "- If, however, they did not change between 1982 and 1988, then they did not produce any change in fatalities in the state.\n",
    "- Rather: any changes in traffic fatalities over time must have arisen from other sources.\n",
    "- In our model these are changes in the tax on beer and changes in the error term (which captures changes in other factors that determine traffic deaths)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "**Panel Data with Two Time Periods: \"Before and After\" Comparisons**\n",
    "\n",
    "\n",
    "- Specifying the regression in changes in the above equation eliminates the effect of the unobserved variables $z_i$ that are constant over time.\n",
    "- In other words: analyzing changes in $y$ and $x$ has the effect of controlling for variables that are constant over time, thereby eliminating this source of omitted variable bias.\n",
    "- Let's now estimate this first differenced estimator in Python.\n",
    "- Before we can use the method `diff` to calculate first differences of the dependent variable **FatalityRate** (_mrall_) and the independent variable **BeerTax**, we have to make sure with `groupby ('id')` that these calculations are performed per individual.\n",
    "- The FD estimator can now be calculated by simply applying OLS to these differenced values.\n",
    "- The observations for the first year with missing information are automatically dropped from the estimation sample.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fatality_8288[var_selection].head(): \n",
      "  state  year    t    mrall   beertax  mrall_diff1  beertax_diff1\n",
      "0    AL  1982  0.0  2.12836  1.539379          NaN            NaN\n",
      "1    AL  1988  1.0  2.49391  1.501444      0.36555      -0.037936\n",
      "2    AZ  1982  0.0  2.49914  0.214797          NaN            NaN\n",
      "3    AZ  1988  1.0  2.70565  0.346487      0.20651       0.131690\n",
      "4    AR  1982  0.0  2.38405  0.650358          NaN            NaN\n",
      "\n",
      "table_sm: \n",
      "                      b      se       t    pval\n",
      "Intercept     -0.072037  0.0606 -1.1879  0.2410\n",
      "beertax_diff1 -1.040973  0.4172 -2.4950  0.0162\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import statsmodels.formula.api as smf\n",
    "#remove a false positive warning\n",
    "pd.options.mode.chained_assignment = None  # default='warn'\n",
    "\n",
    "fatality=pd.read_stata('data/fatality.dta')\n",
    "\n",
    "fatality_8288=fatality[(fatality['year']==1982) | (fatality['year']==1988)]\n",
    "\n",
    "fatality_8288['t']=(fatality_8288['year']-1982)/6\n",
    "\n",
    "# manually calculate first differences per entity for mrall and beertax\n",
    "fatality_8288['mrall_diff1'] = \\\n",
    "    fatality_8288.sort_values(['state', 'year']).groupby('state')['mrall'].diff()\n",
    "fatality_8288['beertax_diff1'] = \\\n",
    "    fatality_8288.sort_values(['state', 'year']).groupby('state')['beertax'].diff()\n",
    "var_selection = ['state', 'year','t', 'mrall', 'beertax', 'mrall_diff1', 'beertax_diff1']\n",
    "print(f'fatality_8288[var_selection].head(): \\n{fatality_8288[var_selection].head()}\\n')\n",
    "\n",
    "# estimate FD model with statmodels on differenced data:\n",
    "reg_sm = smf.ols(formula='mrall_diff1 ~beertax_diff1', data=fatality_8288)\n",
    "results_sm = reg_sm.fit()\n",
    "\n",
    "# print results:\n",
    "table_sm = pd.DataFrame({'b': round(results_sm.params, 8),\n",
    "                         'se': round(results_sm.bse, 4),\n",
    "                         't': round(results_sm.tvalues, 4),\n",
    "                         'pval': round(results_sm.pvalues, 4)})\n",
    "print(f'table_sm: \\n{table_sm}\\n')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "**Panel Data with Two Time Periods: \"Before and After\" Comparisons**\n",
    "\n",
    "- Including an intercept allows for the possibility that the mean change in the fatality rate, in the absence of a change in the real beer tax, is nonzero.\n",
    "- Any ideas why the sign could be negative?\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "**Panel Data with Two Time Periods: \"Before and After\" Comparisons**\n",
    "\n",
    "- Including an intercept allows for the possibility that the mean change in the fatality rate, in the absence of a change in the real beer tax, is nonzero.\n",
    "- For example, the negative intercept found could reflect improvements in auto safety between 1982 and 1988 that reduced the average fatality rate.\n",
    "- Generating the differenced values and using OLS on them is actually unnecessary.\n",
    "- The command `FirstDifferenceOLs` shows that many lines of code can be saved by using the canned routine in `linearmodels`.\n",
    "- As the output shows, the parameter estimates are therefore exactly the same as our manual calculations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "table_plm: \n",
      "                b      se       t    pval\n",
      "t       -0.016068  0.0263 -0.6106  0.5444\n",
      "beertax -0.405223  0.1810 -2.2384  0.0301\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import statsmodels.formula.api as smf\n",
    "import linearmodels as plm\n",
    "import matplotlib.pyplot as plt\n",
    "#remove a false positive warning\n",
    "pd.options.mode.chained_assignment = None  # default='warn'\n",
    "\n",
    "fatality=pd.read_stata('data/fatality.dta')\n",
    "\n",
    "fatality_8288=fatality[(fatality['year']==1982) | (fatality['year']==1988)]\n",
    "\n",
    "fatality_8288['t']=(fatality_8288['year']-1982)/6\n",
    "\n",
    "# estimate FD model with linearmodels:\n",
    "fatality_8288 = fatality_8288.set_index(['state', 'year'])\n",
    "reg_plm = plm.FirstDifferenceOLS.from_formula(formula='mrall ~t+beertax',\n",
    "                                              data=fatality_8288)\n",
    "results_plm = reg_plm.fit()\n",
    "\n",
    "# print results:\n",
    "table_plm = pd.DataFrame({'b': round(results_plm.params, 8),\n",
    "                          'se': round(results_plm.std_errors, 4),\n",
    "                          't': round(results_plm.tstats, 4),\n",
    "                          'pval': round(results_plm.pvalues, 4)})\n",
    "print(f'table_plm: \\n{table_plm}\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "**Panel Data with Two Time Periods: \"Before and After\" Comparisons**\n",
    "\n",
    "- In contrast to the cross-sectional regression results, the estimated effect of a change in the real beer tax is negative, as predicted by common sense.\n",
    "- The hypothesis that the population slope coefficient is 0 is rejected at the 5% significance level.\n",
    "- According to this estimated coefficient, an increase in the real beer tax by \\\\$1 per case reduces the traffic fatality rate by 1.04 deaths per 10,000 people.\n",
    "- This estimated effect is very large: The average fatality rate is approximately 2 in these data (that is, 2 fatalities per year\n",
    "per 10,000 members of the population), so the estimate suggests that traffic fatalities can be cut in half merely by increasing the real tax on beer by $1 per case.\n",
    "- Let's just check out of curiosity if a log specification of beer tax shows the same"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "**Panel Data with Two Time Periods: \"Before and After\" Comparisons**\n",
    "\n",
    "- By examining changes in the fatality rate over time, the regression  controls for fixed factors such as cultural attitudes toward drinking and driving.\n",
    "- But there are many factors that influence traffic safety, and if they change over time and are correlated with the real beer tax, then their omission will produce omitted variable bias.\n",
    "- Later, we undertake a more careful analysis that controls for several such factors, so for now it is best to refrain from drawing any substantive conclusions about the effect of real beer taxes on traffic fatalities.\n",
    "- This “before and after” or “differences” analysis works when the data are observed in two different years.\n",
    "- Our data set, however, contains observations for seven different years, and it seems foolish to discard those potentially useful additional data.\n",
    "- But the “before and after” method does not apply directly when $T>2$.\n",
    "- To analyze all the observations in our panel data set, we use the method of **fixed effects regression**."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "**Fixed Effects Regression**\n",
    "\n",
    "- Fixed effects regression is a method for controlling for omitted variables in panel data when the omitted variables vary across entities (states) but do not change over time.\n",
    "- Unlike the “before and after” comparisons, fixed effects regression can be used when there are two or more time observations for each entity.\n",
    "- The fixed effects regression model has n different intercepts, one for each entity.\n",
    "- These intercepts can be represented by a set of binary (or indicator) variables.\n",
    "- These binary variables absorb the influences of all omitted variables that differ from one entity to the next but are constant over time."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "**The Fixed Effects Regression Model**\n",
    "\n",
    "- Consider a regression model with the dependent variable (FatalityRate) and observed regressor (BeerTax) denoted as $y_{it}$ and $X_{it}$, respectively:\n",
    "\n",
    "\\begin{equation*}\n",
    "y_{it}=\\beta_0+\\beta_1x_{it}+\\beta_2z_i+u_{it}\n",
    "\\end{equation*}\n",
    "\n",
    "- $z_i$ is an unobserved variable that varies from one state to the next but does not change over time (for example, $z_i$ represents cultural attitudes toward drinking and driving).\n",
    "- We want to estimate $\\beta_1$, the effect on $y$ of $x$, holding constant the unobserved state characteristics $z$.\n",
    "- Because $z_i$ varies from one state to the next but is constant over time, the population regression model above can be interpreted as having $n$ intercepts, one for each state.\n",
    "- Specifically, let $\\alpha_i = \\beta_0 + \\beta_2z_i$.\n",
    "- Then the equation becomes\n",
    "\n",
    "\\begin{equation*}\n",
    "y_{it}=\\beta_1x_{it}+\\alpha_i+u_{it}\n",
    "\\end{equation*}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "**The Fixed Effects Regression Model**\n",
    "\n",
    "- The above equation is the fixed effects regression model, in which $\\alpha_1,...,\\alpha_n$ are treated as unknown intercepts to be estimated, one for each state.\n",
    "- The interpretation of $\\alpha_i$ as a state-specific intercept comes from considering the population regression line for the $i^{th}$ state; this population regression line is $\\alpha_i + \\beta_1x_{it}$.\n",
    "- The slope coefficient of the population regression line, $\\beta_1$, is the same for all states, but the intercept of the population regression line varies from one state to the next.\n",
    "- Because the intercept $\\alpha_i$ i can be thought of as the “effect” of being in entity $i$ (in the current application, entities are states), the terms $\\alpha_1,...,\\alpha_n$ are known as **entity fixed effects**.\n",
    "- The variation in the entity fixed effects comes from omitted variables that, like $z_i$, vary across entities but not over time."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "**The Fixed Effects Regression Model**\n",
    "\n",
    "- The state-specific intercepts in the fixed effects regression model also can be expressed using binary variables to denote the individual states:\n",
    "\n",
    "\n",
    "\\begin{equation*}\n",
    "y_{it}=\\beta_0+\\beta_1x_{it}+\\gamma_2D2_i+\\gamma_3D3_i+...+\\gamma_nDn_i+u_{it}\n",
    "\\end{equation*}\n",
    "\n",
    "where $\\beta_0, \\beta_1,\\gamma_2,\\gamma_3,...,\\gamma_n$ are unknown coefficients to be estimated. \n",
    "- Note that the we left out one entitity due to collinearity (remember the dummy variable trap from the men and women case).\n",
    "- Now let's estimate the fixed effects models with dummies on the full data set on road fatalities and plot the corresponding graph."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {
    "scrolled": false,
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "res_dummies.summary(): \n",
      "                            OLS Regression Results                            \n",
      "==============================================================================\n",
      "Dep. Variable:                  mrall   R-squared:                       0.891\n",
      "Model:                            OLS   Adj. R-squared:                  0.779\n",
      "Method:                 Least Squares   F-statistic:                     7.996\n",
      "Date:                Thu, 17 Sep 2020   Prob (F-statistic):           2.24e-11\n",
      "Time:                        14:23:58   Log-Likelihood:                 20.325\n",
      "No. Observations:                  96   AIC:                             57.35\n",
      "Df Residuals:                      47   BIC:                             183.0\n",
      "Df Model:                          48                                         \n",
      "Covariance Type:            nonrobust                                         \n",
      "==================================================================================\n",
      "                     coef    std err          t      P>|t|      [0.025      0.975]\n",
      "----------------------------------------------------------------------------------\n",
      "Intercept          3.6323      0.629      5.771      0.000       2.366       4.898\n",
      "C(state)[T.AZ]    -0.7860      0.562     -1.399      0.168      -1.916       0.344\n",
      "C(state)[T.AR]    -0.6563      0.461     -1.423      0.161      -1.584       0.272\n",
      "C(state)[T.CA]    -1.6652      0.625     -2.662      0.011      -2.923      -0.407\n",
      "C(state)[T.CO]    -1.6236      0.592     -2.744      0.009      -2.814      -0.433\n",
      "C(state)[T.CT]    -1.8684      0.582     -3.208      0.002      -3.040      -0.697\n",
      "C(state)[T.DE]    -1.2677      0.605     -2.096      0.041      -2.484      -0.051\n",
      "C(state)[T.FL]    -0.2004      0.334     -0.600      0.551      -0.872       0.471\n",
      "C(state)[T.GA]     0.8938      0.463      1.932      0.059      -0.037       1.824\n",
      "C(state)[T.ID]    -0.7262      0.534     -1.361      0.180      -1.800       0.348\n",
      "C(state)[T.IL]    -1.9742      0.600     -3.291      0.002      -3.181      -0.767\n",
      "C(state)[T.IN]    -1.5225      0.562     -2.707      0.009      -2.654      -0.391\n",
      "C(state)[T.IA]    -1.4500      0.512     -2.834      0.007      -2.479      -0.421\n",
      "C(state)[T.KS]    -1.2504      0.509     -2.454      0.018      -2.275      -0.226\n",
      "C(state)[T.KY]    -1.2259      0.591     -2.073      0.044      -2.415      -0.036\n",
      "C(state)[T.LA]    -0.6585      0.403     -1.634      0.109      -1.469       0.152\n",
      "C(state)[T.ME]    -1.1643      0.403     -2.888      0.006      -1.975      -0.353\n",
      "C(state)[T.MD]    -1.8482      0.583     -3.168      0.003      -3.022      -0.675\n",
      "C(state)[T.MA]    -2.2186      0.569     -3.897      0.000      -3.364      -1.073\n",
      "C(state)[T.MI]    -1.5185      0.491     -3.091      0.003      -2.507      -0.530\n",
      "C(state)[T.MN]    -1.9412      0.544     -3.569      0.001      -3.035      -0.847\n",
      "C(state)[T.MS]     0.0669      0.339      0.198      0.844      -0.614       0.748\n",
      "C(state)[T.MO]    -1.3870      0.551     -2.518      0.015      -2.495      -0.279\n",
      "C(state)[T.MT]    -0.5340      0.544     -0.982      0.331      -1.627       0.559\n",
      "C(state)[T.NE]    -1.6172      0.509     -3.174      0.003      -2.642      -0.592\n",
      "C(state)[T.NV]    -0.5263      0.597     -0.881      0.383      -1.728       0.675\n",
      "C(state)[T.NH]    -1.4626      0.468     -3.127      0.003      -2.404      -0.521\n",
      "C(state)[T.NJ]    -2.1674      0.631     -3.434      0.001      -3.437      -0.898\n",
      "C(state)[T.NM]     0.3668      0.550      0.667      0.508      -0.740       1.473\n",
      "C(state)[T.NY]    -2.2844      0.618     -3.698      0.001      -3.527      -1.042\n",
      "C(state)[T.NC]    -0.2133      0.294     -0.726      0.471      -0.804       0.378\n",
      "C(state)[T.ND]    -1.4143      0.526     -2.690      0.010      -2.472      -0.357\n",
      "C(state)[T.OH]    -1.7372      0.526     -3.305      0.002      -2.795      -0.680\n",
      "C(state)[T.OK]    -0.2675      0.379     -0.706      0.484      -1.030       0.495\n",
      "C(state)[T.OR]    -1.2618      0.588     -2.144      0.037      -2.445      -0.078\n",
      "C(state)[T.PA]    -1.8373      0.569     -3.227      0.002      -2.983      -0.692\n",
      "C(state)[T.RI]    -2.3158      0.604     -3.832      0.000      -3.532      -1.100\n",
      "C(state)[T.SC]     0.6075      0.310      1.957      0.056      -0.017       1.232\n",
      "C(state)[T.SD]    -0.9652      0.440     -2.193      0.033      -1.851      -0.080\n",
      "C(state)[T.TN]    -0.9430      0.553     -1.704      0.095      -2.056       0.170\n",
      "C(state)[T.TX]    -0.8844      0.513     -1.724      0.091      -1.916       0.148\n",
      "C(state)[T.UT]    -1.3179      0.469     -2.810      0.007      -2.261      -0.374\n",
      "C(state)[T.VT]    -0.8870      0.444     -1.997      0.052      -1.781       0.007\n",
      "C(state)[T.VA]    -1.3438      0.431     -3.116      0.003      -2.211      -0.476\n",
      "C(state)[T.WA]    -1.7360      0.585     -2.967      0.005      -2.913      -0.559\n",
      "C(state)[T.WV]    -0.8850      0.512     -1.729      0.090      -1.914       0.144\n",
      "C(state)[T.WI]    -1.8541      0.605     -3.066      0.004      -3.071      -0.638\n",
      "C(state)[T.WY]    -0.0016      0.643     -0.002      0.998      -1.294       1.291\n",
      "beertax           -0.8689      0.393     -2.211      0.032      -1.660      -0.078\n",
      "==============================================================================\n",
      "Omnibus:                        6.048   Durbin-Watson:                   2.756\n",
      "Prob(Omnibus):                  0.049   Jarque-Bera (JB):                9.853\n",
      "Skew:                           0.000   Prob(JB):                      0.00725\n",
      "Kurtosis:                       4.569   Cond. No.                         136.\n",
      "==============================================================================\n",
      "\n",
      "Warnings:\n",
      "[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import statsmodels.formula.api as smf\n",
    "\n",
    "\n",
    "fatality=pd.read_stata('data/fatality.dta')\n",
    "\n",
    "reg_dummies = smf.ols(formula='mrall ~ beertax + C(state)',\n",
    "                      data=fatality)\n",
    "res_dummies = reg_dummies.fit()\n",
    "\n",
    "# print results:\n",
    "table_dummies = pd.DataFrame({'b': round(res_dummies.params, 8),\n",
    "                          'se': round(res_dummies.bse, 4),\n",
    "                          't': round(res_dummies.tvalues, 4),\n",
    "                          'pval': round(res_dummies.pvalues, 4)})\n",
    "#print(f'table_dummies: \\n{table_dummies}\\n')\n",
    "\n",
    "print(f'res_dummies.summary(): \\n{res_dummies.summary()}\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Text(0.5, 0, 'beertax')"
      ]
     },
     "execution_count": 112,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 576x396 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import statsmodels.formula.api as smf\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "fatality=pd.read_stata('data/fatality.dta')\n",
    "\n",
    "reg_dummies = smf.ols(formula='mrall ~ beertax + C(state)',\n",
    "                      data=fatality)\n",
    "res_dummies = reg_dummies.fit()\n",
    "\n",
    "plt.style.use('seaborn')\n",
    "plt.plot(fatality.beertax, res_dummies.params[0] + res_dummies.params[1] * fatality.beertax, 'r')\n",
    "plt.plot(fatality.beertax, fatality.mrall ,'b', marker='o', linestyle='')\n",
    "plt.ylabel('mrall')\n",
    "plt.xlabel('beertax')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "**The Fixed Effects Regression Model**\n",
    "\n",
    "- Sometimes you have a really large number of entities and estimating a parameter may be very time-consuming.\n",
    "- Regression software typically computes the OLS fixed effects estimator in two steps:\n",
    "\n",
    "    - In the first step, the entity-specific average is subtracted from each variable.\n",
    "    - In the second step, the regression is estimated using “entity-demeaned” variables.\n",
    "    \n",
    "    \n",
    "- \"Entitiy-demeaned\" variables means that for each variable you subtract its mean per entity from the original value (e.g. $y_{it}-\\bar{y_i}$ and  $x_{it}-\\bar{x_i}$).\n",
    "- Running an OLS regression on the entitiy demeaned variables produces the same results as the dummy variable approach but it's faster as it doesn't require estimating all parameters.\n",
    "- This is called the **within transformation** of the data and allows to get rid of the unobserved individual effecct $\\alpha_i$:\n",
    "\n",
    "\\begin{equation*}\n",
    "y_{it}=\\beta_1x_{it}+\\alpha_i+u_{it}\n",
    "\\end{equation*}\n",
    "\n",
    "\\begin{equation*}\n",
    "\\bar{y}_{i}=\\beta_1\\bar{x}_{i}+\\alpha_i+\\bar{u}_{i}\n",
    "\\end{equation*}\n",
    "\n",
    "\\begin{equation*}\n",
    "\\tilde{y}_{it}=y_{it}-\\bar{y}_{i}=\\beta_1\\tilde{x}_{it}+\\tilde{u}_{it}\n",
    "\\end{equation*}\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "**The Fixed Effects Regression Model**\n",
    "\n",
    "- In Python we can simply use `PanelOLS` in the module `linearmodels`.\n",
    "- Demeaning is considered by adding the word `EntityEffects` to the formula.\n",
    "- You have to define the panel data structure before running the fixed effects regression by setting entity and time dimension of the panel data (`fatality.set_index(['state', 'year']` in this case)\n",
    "- When you ue fixed effects, variables that do not vary over time are dropped (for instance a state law)\n",
    "- You can either remove such variables manually or use `drop_absorbed=True`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "table: \n",
      "              b     se       t    pval\n",
      "beertax -0.8689  0.393 -2.2111  0.0319\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import wooldridge as woo\n",
    "import pandas as pd\n",
    "import linearmodels as plm\n",
    "\n",
    "fatality=pd.read_stata('data/fatality.dta')\n",
    "fatality = fatality.set_index(['state', 'year'], drop=False)\n",
    "\n",
    "# FE model estimation:\n",
    "reg = plm.PanelOLS.from_formula(\n",
    "    formula='mrall ~ beertax + EntityEffects',\n",
    "    data=fatality, drop_absorbed=True)\n",
    "results = reg.fit()\n",
    "\n",
    "# print regression table:\n",
    "table = pd.DataFrame({'b': round(results.params, 4),\n",
    "                      'se': round(results.std_errors, 4),\n",
    "                      't': round(results.tstats, 4),\n",
    "                      'pval': round(results.pvalues, 4)})\n",
    "print(f'table: \\n{table}\\n')\n",
    "\n",
    "#print(results)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "**Regression with Time Fixed Effects**\n",
    "\n",
    "- Including state fixed effects in the fatality rate regression lets us avoid omitted variables bias arising from omitted factors, such as cultural attitudes toward drinking and driving, that vary across statesbut are constant over time within a state.\n",
    "- What are such potentially time-varying factors?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "**Regression with Time Fixed Effects**\n",
    "\n",
    "- Still, a skeptic might suspect that other factors could lead to omitted variables bias.\n",
    "- For example:\n",
    "    - over this period cars were getting safer,\n",
    "    - occupants were increasingly wearing seat belts;\n",
    "    - if the real tax on beer rose, on average, during the mid-1980s, then BeerTax could be picking up the effect of overall automobile safety improvements.\n",
    "- If, however, safety improvements evolved over time but were the same for all states, then we can eliminate their influence by including **time fixed effects**."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "**Regression with Time Fixed Effects**\n",
    "\n",
    "- Just as fixed effects for each entity can control for variables that are constant over time but differ across entities\n",
    "- So time fixed effects can control for variables that are **constant across entities but evolve over time**.\n",
    "- Because safety improvements in new cars are introduced nationally, they serve to reduce traffic fatalities in all states.\n",
    "- So it is plausible to think of automobile safety as an omitted variable that changes over time but has the same value for all states.\n",
    "- The population regression can be modified to make explicit the effect of automobile safety, which we will denote $s_t$:\n",
    "\n",
    "\\begin{equation*}\n",
    "y_{it} = \\beta_0 + \\beta_1x_{it} + \\beta_2z_i + \\beta_3s_t + u_{it}, \\end{equation*}\n",
    "\n",
    "where $s_t$ is unobserved and where the single $t$ subscript emphasizes that safety changes over time but is constant across states.\n",
    "- Because $\\beta_3s_t$ represents variables that determine $y_{it}$ if $s_t$ is correlated with $x_{it}$, then omitting $s_t$ from the regression leads to omitted variable bias."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "**Regression with Time Fixed Effects**\n",
    "\n",
    "- Our objective is to estimate $\\beta_1$, controlling for $s_t$.\n",
    "- Although $S_t$ is unobserved, its influence can be eliminated because it varies over time but not across states, just as it is possible to eliminate the effect of $z_i$, which varies across states but not over time.\n",
    "- In the entity fixed effects model, the presence of $z_i$ leads to the fixed effects regression model, in which each state has its own intercept (or fixed effect).\n",
    "- Similarly, because $s_t$ varies over time but not over states, the presence of $s_t$ leads to a regression model in which each time period has its own intercept.\n",
    "- The **time fixed effects regression model** with a single $x$ regressor is\n",
    "\n",
    "\\begin{equation*}\n",
    "y_{it} = \\beta_0 + \\beta_1x_{it} + \\lambda_t + u_{it}, \\end{equation*}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "**Regression with Time Fixed Effects**\n",
    "\n",
    "- This model has a different intercept, $\\lambda_t$, for each time period.\n",
    "- The intercept $\\lambda_t$ can be thought of as the “effect” on $y$ of year $t$ (or, more generally,time period t), so the terms $\\lambda_1,...,\\lambda_T$, are known as **time fixed effects**.\n",
    "- The variation in the time fixed effects comes from omitted variables that, like $s_t$, vary over time but not across entities.\n",
    "- Just as the entity fixed effects regression model can be represented using $n - 1$ binary indicators, so, too, can the time fixed effects regression model be represented using $T - 1$ binary indicators:\n",
    "\n",
    "\\begin{equation*}\n",
    "y_{it} = \\beta_0 + \\beta_1x_{it} + \\gamma_2B2_t+...+\\gamma_TBT_t + u_{it},\n",
    "\\end{equation*}\n",
    "\n",
    "where $\\gamma_2,...,\\gamma_T$ are unknown coefficients and where $B2_t = 1$ if $t$ = 2 and $B2_t = 0$ otherwise, and so forth.\n",
    "- Let's estimate the fatality model with both, time and entitiy fixed effects now."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "table: \n",
      "              b     se       t    pval\n",
      "beertax -0.4052  0.181 -2.2384  0.0301\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import wooldridge as woo\n",
    "import pandas as pd\n",
    "import linearmodels as plm\n",
    "\n",
    "fatality=pd.read_stata('data/fatality.dta')\n",
    "fatality = fatality.set_index(['state', 'year'], drop=False)\n",
    "\n",
    "# FE model estimation with time fixed effects:\n",
    "reg = plm.PanelOLS.from_formula(\n",
    "    formula='np.log(mrall) ~ beertax + EntityEffects + TimeEffects',\n",
    "    data=fatality, drop_absorbed=True)\n",
    "results = reg.fit()\n",
    "\n",
    "# print regression table:\n",
    "table = pd.DataFrame({'b': round(results.params, 4),\n",
    "                      'se': round(results.std_errors, 4),\n",
    "                      't': round(results.tstats, 4),\n",
    "                      'pval': round(results.pvalues, 4)})\n",
    "print(f'table: \\n{table}\\n')\n",
    "\n",
    "#print(results)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "**The Fixed Effects Regression Assumptions and Standard Errors for Fixed Effects Regression**\n",
    "\n",
    "- In panel data, the regression error can be correlated over time within an entity.\n",
    "- Like heteroskedasticity, this correlation does not introduce bias into the fixed effects estimator, but it affects the variance of the fixed effects estimator, and therefore it affects how one computes standard errors.\n",
    "- What are the consequences if standard errors not computed correctly?\n",
    "- The standard errors for fixed effects regressions reported now are so-called clustered standard errors, which are robust both to heteroskedasticity and to correlation over time within an entity. \n",
    "- We begin with the fixed effects regression assumptions, which extend the least squares regression assumptions for causal inference to panel data\n",
    "- Under these assumptions, the fixed effects estimator is consistent and asymptotically normally distributed when $n$ is large."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "**The Fixed Effects Regression Assumptions and Standard Errors for Fixed Effects Regression**\n",
    "\n",
    "- The fixed effects assumption for causal inference, are similar to those for cross-sectional data\n",
    "- However, the conditional mean assumption for the errors term $u_{it}$ is now:\n",
    "\n",
    "\\begin{equation*}\n",
    "E(u_{it}|x_{i1},x_{i2},...,x_{iT},\\alpha_i)=0\n",
    "\\end{equation*}\n",
    "\n",
    "- In other words, the assumption is that the error term has conditional mean 0 given all $T$ values of $x$ for that entity\n",
    "- This implies that there is no omitted variable bias\n",
    "- The requirement that the conditional mean of $u_{it}$ not depend on any of the values of $x$ for that entity — past, present, or future — adds an important subtlety beyond the least squares assumption for cross-sectional data.\n",
    "- This assumption is violated if current $u_{it}$ is correlated with past, present, or future values of $x$.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "**The Fixed Effects Regression Assumptions and Standard Errors for Fixed Effects Regression**\n",
    "\n",
    "- Another assumption for cross-sectional data was that the sample is produced by random sampling from the population\n",
    "- This can ertainly not hold for fixed effects models as we need to sample the variables per entity\n",
    "- Thus, the assumption is reduced to random sampling of entities\n",
    "- This means: the random sampling assumption for fixed effects models allows $x_{it}$ to be correlated over time within an entitity\n",
    "- If $x_{it}$ is correlated with $x_{is}$ for different values of $s$ and $t$ — that is, if $x_{it}$ is correlated over time for a given entity — then $x_{it}$ is said to be **autocorrelated** (correlated with itself, at different dates) or **serially correlated**.\n",
    "- Autocorrelation is a pervasive feature of time series data: What happens one year tends to be correlated with what happens the next year.\n",
    "- In the traffic fatality example, $x_{it}$, do you think the beer tax in state $i$ in year $t$, is autocorrelated? \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "**The Fixed Effects Regression Assumptions and Standard Errors for Fixed Effects Regression**\n",
    "\n",
    "- Yes, in the traffic fatality example, $x_{it}$, the beer tax in state $i$ in year $t$, is autocorrelated:\n",
    "    - Most of the time the legislature does not change the beer tax, so if it is high one year relative to its mean value for state i, it will tend to be high the next year, too.\n",
    "- Similarly, it is possible to think of reasons why $u_{it}$ would be autocorrelated.\n",
    "- Recall that $u_{it}$ consists of time-varying factors that are determinants of $y_{it}$ but are not included as regressors, and some of these omitted factors might be autocorrelated.\n",
    "- Can you think of examples that make $u_{it}$ autocorrelated?\n",
    "- Think about local factors that affect $y_{it}$ for more than one period but are not captured in the model\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "**The Fixed Effects Regression Assumptions and Standard Errors for Fixed Effects Regression**\n",
    "\n",
    "- For example, a downturn in the local economy might produce layoffs and diminish commuting traffic, thus reducing traffic fatalities for 2 or more years.\n",
    "- Similarly, a major road improvement project might reduce traffic accidents not only in the year of completion but also in future years.\n",
    "- Such omitted factors, which persist over multiple years, produce autocorrelated regression errors.\n",
    "- Not all omitted factors will produce autocorrelation in $u_{it}$\n",
    "- Can you think of an example that affects $y_{it}$ but does not produce autocorrelated error terms?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "**The Fixed Effects Regression Assumptions and Standard Errors for Fixed Effects Regression**\n",
    "\n",
    "\n",
    "- For example, severe winter driving conditions plausibly affect fatalities, but if winter weather conditions for a given state are independently distributed from one year to the next, then this component of the error term would be serially uncorrelated.\n",
    "- In general, though, as long as some omitted factors are autocorrelated, then $u_{it}$ will be autocorrelated."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "**Standard Errors for Fixed Effects Regression**\n",
    "\n",
    "\n",
    "- If the regression errors are autocorrelated, then the usual heteroskedasticity-robust standard error formula for cross-section regression is not valid.\n",
    "- One way to see this is to draw an analogy to heteroskedasticity.\n",
    "- In a regression with cross-sectional data, if the errors are heteroskedastic, then the homoskedasticity-only standard errors are not valid because they were derived under the false assumption of homoskedasticity.\n",
    "- Similarly, if the errors are autocorrelated, then the usual standard errors will not be valid because they were derived under the false assumption of no serial correlation.\n",
    "- Standard errors that are valid if $u_{it}$ is potentially heteroskedastic and potentially correlated over time within an entity are referred to as **heteroskedasticity-and autocorrelation-robust (HAR) standard errors**.\n",
    "- The HAR standard errors most commonly used are so called **clustered standard errors**."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "**Standard Errors for Fixed Effects Regression**\n",
    "\n",
    "- The term clustered arises because these standard errors allow the regression errors to have an arbitrary correlation within a cluster, or grouping, but assume that the regression errors are uncorrelated across clusters. In the context of panel data, each cluster consists of an entity.\n",
    "- Thus clustered standard errors allow for heteroskedasticity and for arbitrary autocorrelation within an entity but treat the errors as uncorrelated across entities.\n",
    "- That is, clustered standard errors allow for heteroskedasticity and autocorrelation in a way that is consistent with the fixed effects assumption of only having random sampling of entitities.\n",
    "- Like heteroskedasticity-robust standard errors in regression with cross-sectional data, clustered standard errors are valid whether or not there is heteroskedasticity, autocorrelation, or both.\n",
    "- If the number of entities $n$ is large, inference using clustered standard errors can proceed using the usual large-sample normal critical values for t-statistics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "table: \n",
      "             b  se_noclust  se_clust  pval_noclust  pval_clust\n",
      "beertax -1.041      0.4172    0.5021        0.0162      0.0438\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import wooldridge as woo\n",
    "import pandas as pd\n",
    "import linearmodels as plm\n",
    "\n",
    "fatality=pd.read_stata('data/fatality.dta')\n",
    "fatality = fatality.set_index(['state', 'year'], drop=False)\n",
    "\n",
    "# FE model estimation with and without clustering:\n",
    "reg = plm.PanelOLS.from_formula(\n",
    "    formula='mrall ~ beertax  +  EntityEffects+TimeEffects',\n",
    "    data=fatality, drop_absorbed=True)\n",
    "\n",
    "\n",
    "results_noclust = reg.fit()\n",
    "results_clust = reg.fit(cov_type='clustered',cluster_entity=True)\n",
    "\n",
    "# print regression table:\n",
    "table = pd.DataFrame({'b': round(results_noclust.params, 4),\n",
    "                      'se_noclust': round(results_noclust.std_errors, 4),\n",
    "                      'se_clust': round(results_clust.std_errors, 4),\n",
    "                      'pval_noclust': round(results_noclust.pvalues, 4),\n",
    "                      'pval_clust': round(results_clust.pvalues, 4)})\n",
    "print(f'table: \\n{table}\\n')\n",
    "\n",
    "#print(results)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "<h2>Instrumental Variable Regression</h2>\n",
    "\n",
    "- We have discussed the problem of omitting an important variable, which results ina violation of the zero conditional mean assumption (i.e. violates  $E(u_i|x_i)=0)$\n",
    "- We explained how fixed effects estimation or first differencing can be used with panel data to estimate the effects of time-varying independent variables in the presence of _time-constant_ omitted variables.\n",
    "- Although such methods are very useful, we do not always have access to panel data.\n",
    "- And even if we can have panel data, we still may have problems.\n",
    "- In which cases does it not help to use a fixed effects estimation?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "**Instrumental Variable Regression**\n",
    "\n",
    "- We may be interested in the effect of a variable that does not change over time: first differencing or fixed effects estimation eliminates time-constant explanatory variables.\n",
    "- Also: the panel data methods that we have studied so far do not solve the problem of time-varying omitted variables that are correlated with the explanatory variables.\n",
    "- If a direct solution to these problems is either infeasible or unavailable, a new method is required."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "**Instrumental Variable Regression**\n",
    "\n",
    "- **Instrumental variables (IV) regression** is a general way to obtain a consistent estimator of the unknown causal coefficients when the regressor, $x$, is correlated with the error term, $u$.\n",
    "- To understand how IV regression works, think of the variation in $x$ as having two parts:\n",
    "    - one part that, for whatever reason, is correlated with $u$ (this is the part that causes the problems) and\n",
    "    - a second part that is uncorrelated with $u$.\n",
    "- If you had information that allowed you to isolate the second part, you could focus on those variations in $x$ that are uncorrelated with $u$ and disregard the variations in $x$ that bias the OLS estimates.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "**Instrumental Variable Regression**\n",
    "\n",
    "\n",
    "- This is, in fact, what IV regression does.\n",
    "- The information about the movements in $x$ that are uncorrelated with $u$ is gleaned from one or more additional variables, called **instrumental variables** or simply **instruments**.\n",
    "- Instrumental variables regression uses these additional variables as tools or \"instruments\" to isolate the movements in $x$ that are uncorrelated with $u$\n",
    "- This permits consistent estimation of the regression coefficients.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "**Instrumental Variable Regression**\n",
    "\n",
    "- We start with the case of a single regressor, $x$, which might be correlated with the error, $u$.\n",
    "- If $x$ and $u$ are correlated, the OLS estimator is inconsistent; that is, it may not be close to the true value of the causal coefficient even when the sample is very large.\n",
    "- This correlation between $x$  and $u$ can stem from omitted variables but not only.\n",
    "- Another reason could be **simultaneous causality** (when causality runs “backward” from $y$ to $x$ as well as “forward” from $x$ to $y$).\n",
    "- Whatever the source of the correlation between $x$ and $u$, if there is a valid instrumental variable, $z$, the effect on $y$ of a unit change in $x$ can be estimated using the **instrumental variables estimator**."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "**Instrumental Variable Regression**\n",
    "\n",
    "**Endogeneity and exogeneity**\n",
    "\n",
    "- Instrumental variables regression has some specialized terminology to distinguish variables that are correlated with the population error term $u$ from ones that are not:\n",
    "    - variables correlated with the error term are called **endogenous variables**, while \n",
    "    - variables uncorrelated with the error term are called **exogenous variables**."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "**Instrumental Variable Regression**\n",
    "\n",
    "- To illustrate endogeneity and exogeneity consider a model\n",
    "\n",
    "\\begin{equation*}\n",
    "y=\\beta_0+\\beta_1x_i+u_i\n",
    "\\end{equation*}\n",
    "\n",
    "- We can use OLS to get consistent estimates if\n",
    "\n",
    "<img src=\"figs\\ols_unbiased.png\" width=\"300\"/>\n",
    "\n",
    "- We can't use OLS if\n",
    "\n",
    "<center> <img src=\"figs\\ols_biased_1.png\" alt=\"drawing\" width=\"300\"/> or <img src=\"figs\\ols_biased_2.png\" alt=\"drawing\" width=\"300\"/> </center>\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "**Refreshing the Omitted Variable Bias Problem**\n",
    "\n",
    "- We have had the example of the effect of eduction on wages\n",
    "- The problem is, that both education and wages, are also affected by a persons ability, intelligence and effort.\n",
    "- However, ability, intelligence and effort are usually not observed and thus cannot be included in the regression model.\n",
    "- The effect we measure for education is thus not isolated: it's a combination of education and all the things that effect both, education and wages\n",
    "- Thus, we only measure a correlation between wages and education but not the causal effect of wages on education\n",
    "- Let's show how this causes a bias again in the simulation, we've had before\n",
    "- We will build up on this simulation also to show how instrument variables solve this problem after that."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "**Simulating Omitted Variable Bias**\n",
    "\n",
    "- Consider a model $y=\\beta_0+\\beta_{1}x_1+\\beta_{2}x_2+u$ \n",
    "- Assume there is a common component $a$ affecting $x_1$ and $x_2$ \n",
    "- Assume $\\beta_0$ = 1, $\\beta_1$=-0.3 and $\\beta_2$=0.7\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Y</th>\n",
       "      <th>X1</th>\n",
       "      <th>X2</th>\n",
       "      <th>e</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-2.954861</td>\n",
       "      <td>3.248691</td>\n",
       "      <td>-1.498129</td>\n",
       "      <td>-1.931564</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>-1.161883</td>\n",
       "      <td>-1.223513</td>\n",
       "      <td>-3.383587</td>\n",
       "      <td>-0.160426</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>-2.231650</td>\n",
       "      <td>-1.056344</td>\n",
       "      <td>-3.880477</td>\n",
       "      <td>-0.832220</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>-1.994796</td>\n",
       "      <td>-2.145937</td>\n",
       "      <td>-4.903522</td>\n",
       "      <td>-0.206112</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>-0.169967</td>\n",
       "      <td>1.730815</td>\n",
       "      <td>-2.395682</td>\n",
       "      <td>1.026255</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          Y        X1        X2         e\n",
       "0 -2.954861  3.248691 -1.498129 -1.931564\n",
       "1 -1.161883 -1.223513 -3.383587 -0.160426\n",
       "2 -2.231650 -1.056344 -3.880477 -0.832220\n",
       "3 -1.994796 -2.145937 -4.903522 -0.206112\n",
       "4 -0.169967  1.730815 -2.395682  1.026255"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# generate some random variables with the above characteristics\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from numpy.random import seed\n",
    "from numpy.random import rand\n",
    "from numpy.random import randn\n",
    "\n",
    "# generate a random common component for x1 and x2\n",
    "# seed random number generator\n",
    "seed(1)\n",
    "a = randn(10000)\n",
    "\n",
    "# generate x1 and x2\n",
    "seed(1)\n",
    "x1 = randn(10000)+a\n",
    "x2 = randn(10000)-3+a\n",
    "\n",
    "# generate random error\n",
    "e = randn(10000)\n",
    "\n",
    "# generate y\n",
    "y = 1 - 0.3*x1 + 0.7*x2 + e\n",
    "\n",
    "# generate dataframe\n",
    "df = pd.DataFrame({'Y' : y, 'X1': x1, 'X2':x2,'e':e})\n",
    "df.head()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "We first estimate the unbiased model $\\hat{y}=\\hat{\\beta}_0+\\hat{\\beta}_1x_1+\\hat{\\beta}_2x_2+\\hat{u}$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                            OLS Regression Results                            \n",
      "==============================================================================\n",
      "Dep. Variable:                      y   R-squared:                       0.339\n",
      "Model:                            OLS   Adj. R-squared:                  0.339\n",
      "Method:                 Least Squares   F-statistic:                     2569.\n",
      "Date:                Thu, 16 Sep 2021   Prob (F-statistic):               0.00\n",
      "Time:                        13:48:36   Log-Likelihood:                -14149.\n",
      "No. Observations:               10000   AIC:                         2.830e+04\n",
      "Df Residuals:                    9997   BIC:                         2.832e+04\n",
      "Df Model:                           2                                         \n",
      "Covariance Type:            nonrobust                                         \n",
      "==============================================================================\n",
      "                 coef    std err          t      P>|t|      [0.025      0.975]\n",
      "------------------------------------------------------------------------------\n",
      "Intercept      0.9960      0.031     31.740      0.000       0.935       1.058\n",
      "x1            -0.2988      0.007    -42.091      0.000      -0.313      -0.285\n",
      "x2             0.7036      0.010     70.710      0.000       0.684       0.723\n",
      "==============================================================================\n",
      "Omnibus:                        2.137   Durbin-Watson:                   1.981\n",
      "Prob(Omnibus):                  0.344   Jarque-Bera (JB):                2.102\n",
      "Skew:                           0.028   Prob(JB):                        0.350\n",
      "Kurtosis:                       3.044   Cond. No.                         11.6\n",
      "==============================================================================\n",
      "\n",
      "Warnings:\n",
      "[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.\n"
     ]
    }
   ],
   "source": [
    "# estimate unbiased OLS model\n",
    "import statsmodels.formula.api as smf    \n",
    "import statsmodels.api as sm\n",
    "\n",
    "formula = \"y ~ x1 + x2 \"\n",
    "results = smf.ols(formula, df).fit()\n",
    "print(results.summary())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "Now we assume we don't observe $x_2$ and instead estimate\n",
    "\n",
    "\\begin{equation*}\n",
    "\\tilde{y}=\\tilde{\\beta}_0+\\tilde{\\beta}_1x_1\n",
    "\\end{equation*}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                            OLS Regression Results                            \n",
      "==============================================================================\n",
      "Dep. Variable:                      y   R-squared:                       0.009\n",
      "Model:                            OLS   Adj. R-squared:                  0.009\n",
      "Method:                 Least Squares   F-statistic:                     91.77\n",
      "Date:                Thu, 16 Sep 2021   Prob (F-statistic):           1.21e-21\n",
      "Time:                        13:48:39   Log-Likelihood:                -16176.\n",
      "No. Observations:               10000   AIC:                         3.236e+04\n",
      "Df Residuals:                    9998   BIC:                         3.237e+04\n",
      "Df Model:                           1                                         \n",
      "Covariance Type:            nonrobust                                         \n",
      "==============================================================================\n",
      "                 coef    std err          t      P>|t|      [0.025      0.975]\n",
      "------------------------------------------------------------------------------\n",
      "Intercept     -1.1082      0.012    -90.834      0.000      -1.132      -1.084\n",
      "x1             0.0585      0.006      9.580      0.000       0.047       0.070\n",
      "==============================================================================\n",
      "Omnibus:                        4.283   Durbin-Watson:                   2.006\n",
      "Prob(Omnibus):                  0.117   Jarque-Bera (JB):                4.463\n",
      "Skew:                           0.021   Prob(JB):                        0.107\n",
      "Kurtosis:                       3.094   Cond. No.                         2.00\n",
      "==============================================================================\n",
      "\n",
      "Warnings:\n",
      "[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.\n"
     ]
    }
   ],
   "source": [
    "#estimate biased OLS model\n",
    "\n",
    "formula = \"y ~ x1\"\n",
    "results = smf.ols(formula, df).fit()\n",
    "print(results.summary())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "Let's now compare the two regression\n",
    "  - the one where omitted variable $x_2$ that is correlated with our variable of interested and the dependent variable and\n",
    "  - the other one where $x_2$ is also included"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "===========================\n",
      "             y        y    \n",
      "            (1)      (2)   \n",
      "---------------------------\n",
      "Intercept 1.00***  -1.11***\n",
      "          (0.03)   (0.01)  \n",
      "x1        -0.30*** 0.06*** \n",
      "          (0.01)   (0.01)  \n",
      "x2        0.70***          \n",
      "          (0.01)           \n",
      "N         10000    10000   \n",
      "R2        0.34     0.01    \n",
      "===========================\n",
      "Standard errors in\n",
      "parentheses.\n",
      "* p<.1, ** p<.05, ***p<.01\n"
     ]
    }
   ],
   "source": [
    "#compare the two \n",
    "import statsmodels.api as sm\n",
    "from statsmodels.iolib.summary2 import summary_col\n",
    "\n",
    "formula = \"y ~ x1 + x2\"\n",
    "reg1 = smf.ols(formula, df).fit()\n",
    "formula = \"y ~ x1\"\n",
    "reg2 = smf.ols(formula, df).fit()\n",
    "\n",
    "dfoutput = summary_col([reg1,reg2],stars=True,float_format='%0.2f',\n",
    "                  model_names=['y\\n(1)','y\\n(2)'],\n",
    "                  info_dict={'N':lambda x: \"{0:d}\".format(int(x.nobs)),\n",
    "                             'R2':lambda x: \"{:.2f}\".format(x.rsquared)})\n",
    "print(dfoutput)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "**Note:** The bias of the parameter of interest is not introduced because a variable that affects $y$ is omitted in the regression model!\n",
    "\n",
    "The bias results because the missing (unobserved) variable is correlated with one of the $x$ variables!\n",
    "\n",
    "- Now consider a model $y=\\beta_0+\\beta_{1}x_1+\\beta_{2}x_2+\\beta_{3}x_3+u$ \n",
    "- Assume $\\beta_1$ = 1, $\\beta_1$=-0.3 and $\\beta_2$=0.7 AND $\\beta_3$=0.5\n",
    "- Again assume that $x_1$ and $x_2$ are correlated but uncorrelated with $x_3$\n",
    "- Though $x_3$ affects $y$ omitting it does not introduce a bias\n",
    "- Not necessarily important to put everything into the model that affects $y$, that's not the issue"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "# generate x3 which is uncorrelated to x1 and x2\n",
    "seed(1)\n",
    "x1 = randn(10000)+a\n",
    "x2 = randn(10000)-3+a\n",
    "x3 = randn(10000)\n",
    "e = randn(10000)\n",
    "\n",
    "# adjust y\n",
    "y = 1 - 0.3*x1 + 0.7*x2 - 0.4*x3 + e\n",
    "\n",
    "# generate dataframe\n",
    "df = pd.DataFrame({'y' : y, 'x1': x1, 'x2':x2,'x3':x3,'e':e})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {
    "scrolled": false,
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=============================================\n",
      "             y        y        y        y    \n",
      "            (0)      (1)      (2)      (3)   \n",
      "---------------------------------------------\n",
      "Intercept -1.07*** -1.08*** 1.01***  1.01*** \n",
      "          (0.01)   (0.01)   (0.03)   (0.03)  \n",
      "x1        0.05***  0.05***  -0.30*** -0.30***\n",
      "          (0.01)   (0.01)   (0.01)   (0.01)  \n",
      "x2                          0.70***  0.70*** \n",
      "                            (0.01)   (0.01)  \n",
      "x3                 -0.39*** -0.39***         \n",
      "                   (0.01)   (0.01)           \n",
      "N         10000    10000    10000    10000   \n",
      "R2        0.01     0.10     0.39     0.30    \n",
      "=============================================\n",
      "Standard errors in parentheses.\n",
      "* p<.1, ** p<.05, ***p<.01\n"
     ]
    }
   ],
   "source": [
    "import statsmodels.api as sm\n",
    "from statsmodels.iolib.summary2 import summary_col\n",
    "\n",
    "formula = \"y ~ x1\"\n",
    "reg1 = smf.ols(formula, df).fit()\n",
    "formula = \"y ~ x1 + x3\"\n",
    "reg2 = smf.ols(formula, df).fit()\n",
    "formula = \"y ~ x1 + x2 + x3\"\n",
    "reg3 = smf.ols(formula, df).fit()\n",
    "formula = \"y ~ x1 + x2\"\n",
    "reg4 = smf.ols(formula, df).fit()\n",
    "\n",
    "dfoutput = summary_col([reg1,reg2,reg3,reg4],stars=True,float_format='%0.2f',\n",
    "                  model_names=['y\\n(0)','y\\n(1)','y\\n(2)','y\\n(3)'],\n",
    "                  info_dict={'N':lambda x: \"{0:d}\".format(int(x.nobs)),\n",
    "                             'R2':lambda x: \"{:.2f}\".format(x.rsquared)})\n",
    "print(dfoutput)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "**Instrumental Variable Regression**\n",
    "\n",
    "\n",
    "\n",
    "- Again consider a model $y=\\beta_0+\\beta_{1}x_1+\\beta_{2}x_2+u$ \n",
    "- Again assume that $x_1$ and $x_2$ are correlated (maybe because a component $a$ affects both, $x_1$ and $x_2$)\n",
    "- In addition assume that there is a further component $z$ that affects $x_1$ but is uncorrelated to $x_2$ such that\n",
    "\n",
    "\\begin{equation*}\n",
    " x_1=\\gamma_0+\\gamma_{1}a+\\gamma_{2}z+e\n",
    " \\end{equation*}\n",
    "\n",
    "- If $\\gamma_2$ is sufficiently large we can isolate this **exogenous variation** in $x_{1}$ to identify $\\beta_{1}$\n",
    "- We then say $z$ is an **instrument** for $x_{1}$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "**Instrumental Variable Regression: Requirements for an Instrument**\n",
    "\n",
    "There ae two conditions for an instrument to work:\n",
    "\n",
    "- **Relevance:** Instrument has to be sufficiently strong correlated with the endogenous regressor (must not be a _weak_ instrument) in order to cause enough variation in the endogenous variable to identify it\n",
    "\n",
    "<center>$Cov(z,x_1)\\neq 0$</center>\n",
    "\n",
    "- **Exogeneity**: Instrument has to be uncorrelated with the error term\n",
    "\n",
    "<center>$Cov(z_i,u_i)= 0$</center>\n",
    "\n",
    "<p>\n",
    "\n",
    "<center> <img src=\"figs\\instr_req.png\" width=\"400\"/> </center>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "**Instrumental Variable Regression: Two Stage Least Squares Estimation**\n",
    "\n",
    "- If the instrument $z$ satisfies the conditions of instrument relevance and exogeneity, the coefficient $\\beta_1$ can be estimated using an IV estimator called **two stage least squares (TSLS)**.\n",
    "- As the name suggests, the two stage least squares estimator is calculated in two stages:\n",
    "    - The first stage decomposes $x_1$ into two components: a problematic component that may be correlated with the regression error and another, problem-free component that is uncorrelated with the error.\n",
    "    - The second stage uses the problem-free component to estimate $\\beta_1$.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "**Instrumental Variable Regression: Two Stage Least Squares Estimation**\n",
    "\n",
    "- First stage: Estimate $x_{1}=\\gamma_0 + \\gamma_1z$ (ALL coviariates that are used in the main estimation have to be included in this step!)\n",
    "- Save $\\hat{x}_{1}$, the first stage estimate of $x_{1} $\n",
    "- Regress $y=\\beta_0+\\beta_{1}\\hat{x}_{1}+u$ \n",
    "- Note $z$ only appears in the first stage, not in the second stage\n",
    "- This is called the **exclusion restriction**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "**Deriving the IV estimator**\n",
    "\n",
    "Recall the OLS estimator is\n",
    "\n",
    "<p>\n",
    "    \n",
    "$\\hat{\\beta}_{OLS}=\\frac{\\sum{(Y_i-\\bar{Y})(X_i-\\bar{X})}}{\\sum{({X_i}-\\bar{X})^2}}$\n",
    "\n",
    "Hence\n",
    "    \n",
    "<p>\n",
    "    \n",
    "$\\hat{\\beta}_{2SLS}=\\frac{\\sum{(Y_i-\\bar{Y})(\\hat{X_i}-\\bar{\\hat{X}})}}{\\sum{(\\hat{X_i}-\\bar{\\hat{X}})^2}}$\n",
    "\n",
    "<p>\n",
    "    \n",
    "If we substitute\n",
    "    \n",
    "<p>\n",
    "    \n",
    "$\\hat{X_i}-\\bar{\\hat{X}}=(\\hat{\\gamma}_{0}+\\hat{\\gamma}_{1}Z_i)-(\\hat{\\gamma}_{0}+\\hat{\\gamma}_{1}\\bar{Z})=\\hat{\\gamma}_{1}(Z_i-\\bar{Z})$\n",
    "    \n",
    "<p>\n",
    "    \n",
    "we get\n",
    "\n",
    "<p>\n",
    "    \n",
    "$\\frac{\\sum{(Y_i-\\bar{Y})\\hat{\\gamma}_{1}(Z_i-\\bar{Z})}}{\\sum{\\hat{\\gamma}_{1}^2({Z_i}-\\bar{Z})^2}}=\\frac{1}{\\hat{\\gamma}_{1}}\\times \\frac{\\sum{(Y_i-\\bar{Y})(Z_i-\\bar{Z})}}{\\sum{({Z_i}-\\bar{Z})^2}}$\n",
    "\n",
    "<p>\n",
    "    \n",
    "Since $\\hat{\\gamma}_{1}$ is the first stage OLS estimator\n",
    "\n",
    "<p>\n",
    "    \n",
    "$\\hat{\\beta}_{2SLS}=\\frac{\\sum{({Z_i}-\\bar{Z})^2}}{\\sum{(X_i-\\bar{X})(Z_i-\\bar{Z})}}\\times\\frac{\\sum{(Y_i-\\bar{Y})(Z_i-\\bar{Z})}}{\\sum{({Z_i}-\\bar{Z})^2}}$\n",
    "\n",
    "<p>\n",
    "    \n",
    "Which gives the instrumental variable estimator\n",
    "\n",
    "<p>\n",
    "$\\hat{\\beta}_{IV}=\\frac{\\sum{(Y_i-\\bar{Y})(Z_i-\\bar{Z})}}{\\sum{({X_i}-\\bar{X})({Z_i}-\\bar{Z})}}$\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "**Consistence of the IV estimator**\n",
    "\n",
    "$\\hat{\\beta}_{IV}=\\frac{\\sum{(Y_i-\\bar{Y})(Z_i-\\bar{Z})}}{\\sum{({X_i}-\\bar{X})({Z_i}-\\bar{Z})}}$\n",
    "\n",
    "<p>\n",
    "    \n",
    "In large samples the IV estimator converges to\n",
    "\n",
    "<p>\n",
    "    \n",
    "$plim(\\hat{\\beta}_{IV})=\\frac{Cov(Y_i,Z_i)}{Cov(X_i,Z_i)}=\\frac{Cov(\\beta_0+\\beta_1X_i+u_i,Z_i)}{Cov(X_i,Z_i)}=\\beta_1+\\frac{Cov(u_i,Z_i)}{Cov(X_i, Z_i)}$\n",
    "\n",
    "<p>\n",
    "    \n",
    "and if the two IV assumptions\n",
    "<p>\n",
    "$Cov(Z_i,X_i)\\neq 0$\n",
    "<p>\n",
    "and\n",
    "<p>\n",
    "$Cov(Z_i,u_i)= 0$\n",
    "<p>\n",
    "hold, we get:\n",
    "\n",
    "<p>\n",
    "    \n",
    "$plim(\\hat{\\beta}_{IV})=\\beta_1$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "**Bias of the IV estimator**\n",
    "\n",
    "$E[\\hat{\\beta}_{IV}]=E[\\frac{\\sum{(Y_i-\\bar{Y})(Z_i-\\bar{Z})}}{\\sum{(X_i-\\bar{X})(Z_i-\\bar{Z})}}]$\n",
    "\n",
    "<p>\n",
    "\n",
    "$=E[\\frac{\\sum{((\\beta_0+\\beta_1X_i+u_i)-(\\beta_0+\\beta_1\\bar{X}+\\bar{u}))(Z_i-\\bar{Z})}}{\\sum{(X_i-\\bar{X})(Z_i-\\bar{Z})}}]$\n",
    "\n",
    "<p>\n",
    "\n",
    "$=E[\\frac{\\beta_1\\sum{(X_i-\\bar{X})(Z_i-\\bar{Z})+\\sum{(u_i-\\bar{u})(Z_i-}\\bar{Z})}}{\\sum{(X_i-\\bar{X})(Z_i-\\bar{Z})}}]$\n",
    "\n",
    "<p>\n",
    "          \n",
    "=$\\beta_1+E[\\frac{\\sum{(u_i-\\bar{u})(Z_i-\\bar{Z})}}{\\sum{(X_i-\\bar{X})(Z_i-\\bar{Z})}}]$=$\\beta_1+E[\\frac{\\sum{u_i(Z_i-\\bar{Z})}}{\\sum{(X_i-\\bar{X})(Z_i-\\bar{Z})}}]$\n",
    "\n",
    "<p>\n",
    "          \n",
    "=$\\beta_1+E_{X,Z}[\\frac{\\sum{E[u_i|Z_i,X_i](Z_i-\\bar{Z})}}{\\sum{(X_i-\\bar{X})(Z_i-\\bar{Z})}}$\n",
    "\n",
    "<p>\n",
    "                  \n",
    "$\\neq \\beta_1$ \n",
    "\n",
    "<p>\n",
    "                  \n",
    "Instrument exogeneity implies $E[u_i|Z_i]=0$ but not $E[u_i|Z_i,X_i]= 0$ (this would mean that $E[u_i|X_i]=0$ and we wouldn't need an instrument!)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "**IV by hand**\n",
    "\n",
    "- Assume we don't observe $x_{2}$ but we observe the instrument $z$\n",
    "- Estimate $\\hat{\\beta}_1$ by 2SLS and compare with results from the true relationship and from the estimation suffering from endogeneity\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Y</th>\n",
       "      <th>X1</th>\n",
       "      <th>X2</th>\n",
       "      <th>e</th>\n",
       "      <th>Z</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-3.424977</td>\n",
       "      <td>2.542691</td>\n",
       "      <td>-2.472294</td>\n",
       "      <td>-1.931564</td>\n",
       "      <td>-0.893885</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>-1.656629</td>\n",
       "      <td>-2.265136</td>\n",
       "      <td>-4.536777</td>\n",
       "      <td>-0.160426</td>\n",
       "      <td>-0.371890</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>-1.086400</td>\n",
       "      <td>1.704233</td>\n",
       "      <td>-1.061301</td>\n",
       "      <td>-0.832220</td>\n",
       "      <td>0.195330</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>-1.148969</td>\n",
       "      <td>0.628252</td>\n",
       "      <td>-2.506260</td>\n",
       "      <td>-0.206112</td>\n",
       "      <td>-1.256424</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>-0.251322</td>\n",
       "      <td>1.626178</td>\n",
       "      <td>-2.556748</td>\n",
       "      <td>1.026255</td>\n",
       "      <td>-0.188097</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          Y        X1        X2         e         Z\n",
       "0 -3.424977  2.542691 -2.472294 -1.931564 -0.893885\n",
       "1 -1.656629 -2.265136 -4.536777 -0.160426 -0.371890\n",
       "2 -1.086400  1.704233 -1.061301 -0.832220  0.195330\n",
       "3 -1.148969  0.628252 -2.506260 -0.206112 -1.256424\n",
       "4 -0.251322  1.626178 -2.556748  1.026255 -0.188097"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# generate a random component for x1 and x2\n",
    "a = randn(10000)\n",
    "\n",
    "# generate a component that only affects x1 (the instrument)\n",
    "z = randn(10000)\n",
    "\n",
    "# generate x1 and x1\n",
    "seed(1)\n",
    "x1 = randn(10000) + a - 0.3*z\n",
    "x2 = randn(10000) - 3 + a\n",
    "\n",
    "# generate random error\n",
    "e = randn(10000)\n",
    "\n",
    "# generate y\n",
    "y = 1 - 0.3*x1 + 0.7*x2 + e\n",
    "\n",
    "# generate dataframe\n",
    "df = pd.DataFrame({'Y' : y, 'X1': x1, 'X2':x2,'e':e, 'Z':z})\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                            OLS Regression Results                            \n",
      "==============================================================================\n",
      "Dep. Variable:                     x1   R-squared:                       0.051\n",
      "Model:                            OLS   Adj. R-squared:                  0.051\n",
      "Method:                 Least Squares   F-statistic:                     539.0\n",
      "Date:                Thu, 16 Sep 2021   Prob (F-statistic):          3.60e-116\n",
      "Time:                        13:48:59   Log-Likelihood:                -17717.\n",
      "No. Observations:               10000   AIC:                         3.544e+04\n",
      "Df Residuals:                    9998   BIC:                         3.545e+04\n",
      "Df Model:                           1                                         \n",
      "Covariance Type:            nonrobust                                         \n",
      "==============================================================================\n",
      "                 coef    std err          t      P>|t|      [0.025      0.975]\n",
      "------------------------------------------------------------------------------\n",
      "Intercept      0.0084      0.014      0.593      0.553      -0.019       0.036\n",
      "z             -0.3288      0.014    -23.216      0.000      -0.357      -0.301\n",
      "==============================================================================\n",
      "Omnibus:                        2.347   Durbin-Watson:                   2.004\n",
      "Prob(Omnibus):                  0.309   Jarque-Bera (JB):                2.364\n",
      "Skew:                           0.037   Prob(JB):                        0.307\n",
      "Kurtosis:                       2.986   Cond. No.                         1.01\n",
      "==============================================================================\n",
      "\n",
      "Warnings:\n",
      "[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.\n"
     ]
    }
   ],
   "source": [
    "#first stage regression\n",
    "reg1 = smf.ols(formula='x1 ~ z', data=df).fit()\n",
    "df['x1_hat'] = reg1.fittedvalues\n",
    "print(reg1.summary())\n",
    "#df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "====================================\n",
      "             y        y        y    \n",
      "           (real)  (endog)    (iv)  \n",
      "------------------------------------\n",
      "Intercept 1.00***  -1.11*** -1.11***\n",
      "          (0.03)   (0.01)   (0.01)  \n",
      "x1        -0.30*** 0.04***          \n",
      "          (0.01)   (0.01)           \n",
      "x1_hat                      -0.29***\n",
      "                            (0.04)  \n",
      "x2        0.70***                   \n",
      "          (0.01)                    \n",
      "====================================\n",
      "Standard errors in parentheses.\n",
      "* p<.1, ** p<.05, ***p<.01\n"
     ]
    }
   ],
   "source": [
    "reg_iv = smf.ols(formula='y ~ x1_hat', data=df).fit()\n",
    "\n",
    "reg_real = smf.ols(formula='y ~ x1+x2', data=df).fit()\n",
    "\n",
    "reg_endog = smf.ols(formula='y ~ x1', data=df).fit()\n",
    "\n",
    "dfoutput = summary_col([reg_real,reg_endog,reg_iv],stars=True,float_format='%0.2f',\n",
    "                  model_names=['y\\n(real)','y\\n(endog)','y\\n(iv)'])\n",
    "print(dfoutput)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "reg1 = smf.ols(formula = 'x1 ~ z', data = df).fit()\n",
    "exog = df['exog'] = reg1.fittedvalues\n",
    "\n",
    "reg2 = smf.ols(formula = 'x1 ~ a', data = df).fit()\n",
    "endog = df['endog'] = reg2.fittedvalues\n",
    "\n",
    "#df.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.collections.PathCollection at 0x2399779ef60>"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 576x396 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "plt.scatter(y,endog, c = 'blue', s = 0.1)\n",
    "plt.scatter(y,exog, c = 'red', s = 0.1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "**IV in Python**\n",
    "\n",
    "- To implement IV regression in _Python_, the module `linearmodels` offers the command `IV2SLS` including the convenient formula syntax we know from `statsmodels`.\n",
    "- When working with IV regression in `linearmodels`, our first line of code is:\n",
    "\n",
    "```python\n",
    "import linearmodels.iv as iv\n",
    "```\n",
    "- In the formula specification, the endogenous regressor(s) $x_{end}$ and instruments $z$ are provided in the following way:\n",
    "\n",
    "```python\n",
    "y ~ 1 + [ x_end ~ z ]\n",
    "```\n",
    "\n",
    "- Also remember that constants in `linearmodels` must be explicitly included by adding \"1\" to the formula."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "table_iv: \n",
      "            b_man  se_man    t_man  b_auto  se_auto   t_auto\n",
      "Intercept -1.1091  0.0131 -84.4016 -1.1091    0.014 -78.9810\n",
      "x1            NaN     NaN      NaN -0.2935    0.043  -6.8318\n",
      "x1_hat    -0.2935  0.0398  -7.3799     NaN      NaN      NaN\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import wooldridge as woo\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import linearmodels.iv as iv\n",
    "import statsmodels.formula.api as smf\n",
    "\n",
    "#Iv manually (from before)\n",
    "reg_iv_manually = smf.ols(formula='y ~ x1_hat',\n",
    "                          data=df)\n",
    "results_iv_manually=reg_iv_manually.fit()\n",
    "\n",
    "# IV automatically:\n",
    "reg_iv = iv.IV2SLS.from_formula(formula='y ~ 1 + [x1 ~ z]',\n",
    "                                data=df)\n",
    "results_iv = reg_iv.fit()\n",
    "\n",
    "# print regression table:\n",
    "table_iv = pd.DataFrame({'b_man': round(results_iv_manually.params, 4),\n",
    "                         'se_man': round(results_iv_manually.bse, 4),\n",
    "                         't_man': round(results_iv_manually.tvalues, 4),\n",
    "                         'b_auto': round(results_iv.params, 4),\n",
    "                         'se_auto': round(results_iv.std_errors, 4),\n",
    "                         't_auto': round(results_iv.tstats, 4)})\n",
    "print(f'table_iv: \\n{table_iv}\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "**Standard Errors of 2SLS Estimation**\n",
    "\n",
    "- Standard errors are too small when we estimate 2SLS by hand (wrong inference, overestimate significance)\n",
    "- What is the cause?\n",
    "- Problem: We did not correct for the fact that $\\hat{x}_1$ is an estimate, i.e. there is additional uncertainty in the second stage\n",
    "- Procedure to correct standard errors is complicated but some packages like `linearmodels.iv` do the job\n",
    "- Practical 'quick and dirty' way to get asymptotically correct standard errors if we do IV by hand is to **bootstrap** standard errors, i.e. use the empirical distribution of the s.e. to get an estimate of the population's distribution s.e.\n",
    "\n",
    "> <ol> <li> draw random samples with replacement repeatedly from the sample dataset </li>\n",
    "> <li> estimate the standard errors corresponding to these bootstrap samples, which forms the sampling distribution of the s.e. </li>\n",
    "> <li> calculate the sample standard deviation of the sampling distribution </li></ol>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "**Relevant Instruments**\n",
    "\n",
    "- Recall: One requirement for IV is to have a relevant instrument, so that $Cov(Z_i,X_i)\\neq 0$\n",
    "\n",
    "- If the instrument is _weak_ this means its correlation with the endogenous variable may be to low to get useful estimates of the endogenous variable\n",
    "- The IV estimator can be severaly biased then.\n",
    "- As an exercise estimate 2SLS models where the instrument's relevance varies  using the model characteristics from before.\n",
    "\n",
    "- Estimate IV for different $\\gamma_2$ = 0.01, 0.05, 0.1, 0.3 and 0.6"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "#Estimate IV models instruments of different strengths\n",
    "\n",
    "#instrument with gamma=0.01\n",
    "x1 = randn(10000) + a - 0.01*z\n",
    "y = 1 - 0.3*x1 + 0.7*x2 + e\n",
    "reg_iv_001  = iv.IV2SLS.from_formula (formula='y ~ 1 + [x1 ~ z]', data=df).fit()\n",
    "\n",
    "#instrument with gamma=0.05\n",
    "x1 = randn(10000) + a - 0.05*z\n",
    "y = 1 - 0.3*x1 + 0.7*x2 + e\n",
    "reg_iv_005  = iv.IV2SLS.from_formula (formula='y ~ 1 + [x1 ~ z]', data=df).fit()\n",
    "\n",
    "#instrument with gamma=0.1\n",
    "x1 = randn(10000) + a - 0.1*z\n",
    "y = 1 - 0.3*x1 + 0.7*x2 + e\n",
    "reg_iv_01   = iv.IV2SLS.from_formula (formula='y ~ 1 + [x1 ~ z]',  data=df).fit()\n",
    "\n",
    "#instrument with gamma=0.3\n",
    "x1 = randn(10000) + a - 0.3*z\n",
    "y = 1 - 0.3*x1 + 0.7*x2 + e\n",
    "reg_iv_03   = iv.IV2SLS.from_formula (formula='y ~ 1 + [x1 ~ z]',  data=df).fit()\n",
    "\n",
    "#instrument with gamma=0.6\n",
    "x1 = randn(10000) + a - 0.6*z\n",
    "y = 1 - 0.3*x1 + 0.7*x2 + e\n",
    "reg_iv_06   = iv.IV2SLS.from_formula (formula='y ~ 1 + [x1 ~ z]',  data=df).fit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "table_iv_weak: \n",
      "           b_real_model  se_real_model  b_endog_model  se_endog_model  b_iv_1  \\\n",
      "Intercept        0.9998         0.0264        -1.1110          0.0132 -1.1108   \n",
      "x1              -0.2957         0.0079         0.0418          0.0090 -0.1838   \n",
      "x2               0.7048         0.0082            NaN             NaN     NaN   \n",
      "\n",
      "           se_iv_1  b_iv_2  se_iv_2  b_iv_3  se_iv_3  b_iv_4  se_iv_4  b_iv_5  \\\n",
      "Intercept   0.0172 -1.1090   0.0138 -1.1091   0.0141 -1.1090   0.0141 -1.1091   \n",
      "x1          0.7409 -0.2656   0.2224 -0.3024   0.0159 -0.2928   0.0476 -0.2965   \n",
      "x2             NaN     NaN      NaN     NaN      NaN     NaN      NaN     NaN   \n",
      "\n",
      "           se_iv_5  \n",
      "Intercept   0.0141  \n",
      "x1          0.0233  \n",
      "x2             NaN  \n",
      "\n"
     ]
    }
   ],
   "source": [
    "# print regression table:\n",
    "table_weak_iv = pd.DataFrame({'b_real_model': round(reg_real.params, 4),\n",
    "                         'se_real_model': round(reg_real.bse, 4),\n",
    "                         'b_endog_model': round(reg_endog.params, 4),\n",
    "                         'se_endog_model': round(reg_endog.bse, 4),\n",
    "                         'b_iv_1': round(reg_iv_001.params, 4),\n",
    "                         'se_iv_1': round(reg_iv_001.std_errors, 4),\n",
    "                         'b_iv_2': round(reg_iv_005.params, 4),\n",
    "                         'se_iv_2': round(reg_iv_005.std_errors, 4),\n",
    "                         'b_iv_3': round(reg_iv_01.params, 4),\n",
    "                         'se_iv_3': round(reg_iv_01.std_errors, 4),\n",
    "                         'b_iv_4': round(reg_iv_03.params, 4),\n",
    "                         'se_iv_4': round(reg_iv_03.std_errors, 4),\n",
    "                         'b_iv_5': round(reg_iv_06.params, 4),\n",
    "                         'se_iv_5': round(reg_iv_06.std_errors, 4)})\n",
    "\n",
    "print(f'table_iv_weak: \\n{table_weak_iv}\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "**Weak Instruments**\n",
    "\n",
    "- Fortunately, you can test for weak instruments\n",
    "- The most common test is the first-stage f-test of the instrument(s)\n",
    "- By rule of thumb one can say that the instrument is sufficiently strong/relevant to identify the endogenous variable if the first-stage f-statistic is larger than 10 \n",
    "- The (partial) first stage f-statistic can be computed (among some other first-stage statistics) in _Python_ with the post-estimation command \n",
    "\n",
    "```python\n",
    "regression_name.first_stage\n",
    "```\n",
    "\n",
    "Let's check the first-stage statistics for the our simulations where our instrument was only weakly correlated with $x_1$ and where it was sufficiently strong."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    First Stage Estimation Results    \n",
      "======================================\n",
      "                                    x1\n",
      "--------------------------------------\n",
      "R-squared                       0.0062\n",
      "Partial R-squared               0.0062\n",
      "Shea's R-squared                0.0062\n",
      "Partial F-statistic             62.567\n",
      "P-value (Partial F-stat)     2.554e-15\n",
      "Partial F-stat Distn           chi2(1)\n",
      "========================== ===========\n",
      "Intercept                       0.0278\n",
      "                              (1.9827)\n",
      "z                              -0.1106\n",
      "                             (-7.9099)\n",
      "--------------------------------------\n",
      "\n",
      "T-stats reported in parentheses\n",
      "T-stats use same covariance type as original model\n"
     ]
    }
   ],
   "source": [
    "#instrument with gamma=0.1\n",
    "\n",
    "x1 = randn(10000) + a - 0.1*z\n",
    "y = 1 - 0.3*x1 + 0.7*x2 + e\n",
    "reg_iv_001   = iv.IV2SLS.from_formula (formula='y ~ 1 + [x1 ~ z]',  data=df).fit()\n",
    "print(reg_iv_001.first_stage)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    First Stage Estimation Results    \n",
      "======================================\n",
      "                                    x1\n",
      "--------------------------------------\n",
      "R-squared                       0.0512\n",
      "Partial R-squared               0.0512\n",
      "Shea's R-squared                0.0512\n",
      "Partial F-statistic             530.81\n",
      "P-value (Partial F-stat)        0.0000\n",
      "Partial F-stat Distn           chi2(1)\n",
      "========================== ===========\n",
      "Intercept                       0.0084\n",
      "                              (0.5929)\n",
      "z                              -0.3288\n",
      "                             (-23.039)\n",
      "--------------------------------------\n",
      "\n",
      "T-stats reported in parentheses\n",
      "T-stats use same covariance type as original model\n"
     ]
    }
   ],
   "source": [
    "#instrument with gamma=0.3\n",
    "seed(1)\n",
    "x1 = randn(10000) + a - 0.3*z\n",
    "y = 1 - 0.3*x1 + 0.7*x2 + e\n",
    "reg_iv_03   = iv.IV2SLS.from_formula (formula='y ~ 1 + [x1 ~ z]',  data=df).fit()\n",
    "print(reg_iv_03.first_stage)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "**Validity of the Instruments**\n",
    "\n",
    "- In contrast to the relevance (strenght) of the instrument, which is testable, we can't test the second assumption regarding the validity (exogeneity) of the instrument\n",
    "- We have to justify the validity by arguments and theory"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "**Control Functions**\n",
    "\n",
    "- IV does not work in models that are non-linear in parameters (e.g. discrete choice models such a sprobit and logit, count data models, semiparametric)\n",
    "- In this case **control functions** can serve as an alternative\n",
    "- The control function method use a similar identifying assumptions as IV methods\n",
    "- Procedure is:\n",
    "> <ol><li> Estimate first stage as before</li>\n",
    "> <li> Store the first stage residuals</li>\n",
    "> <li> Estimate the second stage but use the ednogenous variable (not its estimate) and add the first stage residuals as ``control function\"</li></ol>\n",
    "- Sometimes also called **Two Stage Residual Inclusion** method (2SRI) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                            OLS Regression Results                            \n",
      "==============================================================================\n",
      "Dep. Variable:                      y   R-squared:                       0.045\n",
      "Model:                            OLS   Adj. R-squared:                  0.044\n",
      "Method:                 Least Squares   F-statistic:                     233.5\n",
      "Date:                Thu, 16 Sep 2021   Prob (F-statistic):          7.41e-100\n",
      "Time:                        14:07:19   Log-Likelihood:                -17606.\n",
      "No. Observations:               10000   AIC:                         3.522e+04\n",
      "Df Residuals:                    9997   BIC:                         3.524e+04\n",
      "Df Model:                           2                                         \n",
      "Covariance Type:            nonrobust                                         \n",
      "==============================================================================\n",
      "                 coef    std err          t      P>|t|      [0.025      0.975]\n",
      "------------------------------------------------------------------------------\n",
      "Intercept     -1.1124      0.026    -42.805      0.000      -1.163      -1.061\n",
      "x1            -0.2935      0.043     -6.870      0.000      -0.377      -0.210\n",
      "fs_res         0.0160      0.045      0.358      0.721      -0.072       0.104\n",
      "==============================================================================\n",
      "Omnibus:                        0.250   Durbin-Watson:                   1.985\n",
      "Prob(Omnibus):                  0.883   Jarque-Bera (JB):                0.230\n",
      "Skew:                          -0.010   Prob(JB):                        0.891\n",
      "Kurtosis:                       3.013   Cond. No.                         7.26\n",
      "==============================================================================\n",
      "\n",
      "Warnings:\n",
      "[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.\n"
     ]
    }
   ],
   "source": [
    "###Control function method###\n",
    "\n",
    "#first stage regression\n",
    "seed(1)\n",
    "a=randn(10000)\n",
    "#instrument with gamma=0.3\n",
    "x1 = rand(10000) + a - 0.3*z\n",
    "y = 1 - 0.3*x1 + 0.7*x2 + e\n",
    "\n",
    "first_stage = smf.ols(formula='x1 ~ z', data=df).fit()\n",
    "df['fs_res'] = first_stage.resid\n",
    "\n",
    "#second stage with control function\n",
    "control_function = smf.ols(formula='y ~ x1 + fs_res', data=df).fit()\n",
    "print(control_function.summary())\n",
    "#df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "- In the case of endogeneity in a non-linear model you simply estimate the first-stage as you do in 2SLS, you then store the residuals and plug them into the second stage of your non-linear model and estimate it by OLS (probit , logit, count data model, semiparametric model).\n",
    "- Standard errors are corrected by Bootstraping."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "**Simultaneity/Reverse causality**\n",
    "\n",
    "- As we mentioned already, omitted variable bias is not the only source of potential endogeneity.\n",
    "-  Endogeneity can also arise from **two-way causality**:\n",
    "\n",
    "\\begin{equation*}\n",
    "y_i=\\beta_0+\\beta_1x_{1,i}+\\beta_2x_{2,i} +u_{1,i}\n",
    "\\end{equation*}\n",
    "\n",
    "\\begin{equation*}\n",
    "x_{1,i}=\\gamma_0+\\gamma_1y_i+\\gamma_2c_i+u_{2,i}\n",
    "\\end{equation*}\n",
    "\n",
    "    \n",
    "- A shock in $u_{1,i}$ affects $y_i$ and as $y_i$ affects $x_{1,i}$ it also affects $x_{1,i}$\n",
    "- Because of the reverse casuality of $y_i$ and $x_{1,i}$ we have $E(u_{i}|x_{i})\\neq 0$\n",
    "- For instance demand-supply relation: firms ask for higher prices if there is more demand and consumers buy less if prices are high\n",
    "- But we only observe the market equilibrium outcome\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "**Illustration of Simultaneity Bias**\n",
    "\n",
    "- We are interested in estimating the demand elasticity for wine.\n",
    "\n",
    "\\begin{equation*}\n",
    "ln(Q_i^{Wine})=\\beta_0+\\beta_1ln(P_i^{Wine})+u\n",
    "\\end{equation*}\n",
    "\n",
    "where $Q_i^{wine}$ is the $i^{th}$ observation on the quantity of wine consumed, $P_i^{wine}$ is its price, and $u_i$ represents other factors that affect demand, such as income and consumer tastes.  \n",
    "\n",
    "- A 1% increase in the price of wine causes approximately a $\\beta_1$ percent change in demand, so $\\beta_1$ is the demand elasticity.\n",
    "- But because of the interactions between supply and demand, the regressor, $ln(P_i^{Wine})$ is likely to be correlated with the error term.\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "Let's assume the following:  \n",
    "\n",
    "\n",
    "- In the first period’s equilibrium price and quantity are determined by their intersection.\n",
    "- In year 2, demand increases (say, because of an increase in income), and supply decreases (because of an increase in the cost of producing wine);\n",
    "- The equilibrium price and quantity are determined by the intersection of the new supply and demand curves.\n",
    "- In year 3, the factors affecting demand and supply change again; demand increases again, supply increases, and quantity and price are determined in a new equilibrium."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "<p>\n",
    "\n",
    "<center> <img src=\"figs\\wine_1.png\" width=\"400\"/> </center>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "<p>\n",
    "\n",
    "<center> <img src=\"figs\\wine_2.png\" width=\"400\"/> </center>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "- The figure shows the equilibrium quantity and price pairs for these three periods and for eight subsequent years, where in each year the supply and demand curves are subject to shifts associated with factors other than price that affect market supply and demand.\n",
    "\n",
    "- Fitting a line to these points by OLS will estimate neither a demand curve nor a supply curve because the points have been determined by changes in both demand and supply.\n",
    "\n",
    "- A way to get around this problem was to find some third variable that shifts supply but does not shift demand - an exogenous instrument!\n",
    "\n",
    "- Then we can identify the demand curve.\n",
    "\n",
    "- In the case of wine this may be for instance weather conditions that shift the grape harvest (reduces supply)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "<p>\n",
    "\n",
    "<center> <img src=\"figs\\wine_3.png\" width=\"400\"/> </center>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "**Instruments are not always intuitive:**\n",
    "    \n",
    "    \n",
    "- Assume we want to estimate the effect of the number of children on the participation of women in the labor market.\n",
    "- Why can't we simply regress participation in the labor market on the number of kids?\n",
    "- Do you have any idea why a dummy variable indicating whether a women with two children has two children of the same gender could be an instrument for the number of children?\n",
    "\n",
    "- Assume we want to know the effect of education on earnings.\n",
    "- Why can't we simply regress earnings on education?\n",
    "- Why could it be that the quarter of birth is a reasonable instrument for education?\n",
    "\n",
    "https://www.google.com/search?q=Does+Compulsory+School+Attendance+Affect+Schooling+and+Earnings%3F&rlz=1C1CHBF_deFR818FR818&oq=Does+Compulsory+School+Attendance+Affect+Schooling+and+Earnings%3F&aqs=chrome..69i57.491j0j7&sourceid=chrome&ie=UTF-8"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "**Some examples for IV:**\n",
    "\n",
    "**Size of police forces and level of crime**\n",
    "\n",
    "- At the beginning we asked the question: Does the presence of more police officers on the street deter crime?\n",
    "- We already argued that we would need an experiment to analyze this in an causal way\n",
    "\n",
    "What was the argument for this again and why can't we just do an experiment?\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "**Size of police forces and level of crime**\n",
    "\n",
    "- We have endogeneity because the size of the police force and the leve of crime are determined simultaneity:\n",
    "\n",
    "\n",
    "more crime $\\rightarrow$ more police, more police $\\rightarrow$ less crime).\n",
    "\n",
    "- An experiment which randomizes the size of the police force is morally problematic, so that does not work.\n",
    "\n",
    "But: we sometimes have \"natural experiments\"!\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "<p>\n",
    "\n",
    "<center> <img src=\"graphs\\levitt_crime_paper.jpg\" width=\"600\"/> </center>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "- In the paper \"Using Electoral Cycles in Police Hiring to Estimate the Effect of Police on Crime\" Steven Levitt used an IV to adress the endogeneity.\n",
    "- He first shows, that the size of police forces increases disproportionally in mayoral and governatorial election years.\n",
    "- As elections are regularly and are not linked to crime, he used election years as an instrument for the size of the police force.\n",
    "- Using this IV he showed that each additional police officer is estimated to eliminate eight to ten serious crimes.\n",
    "- Existing estimates of the costs of crime suggest that the social benefit of reduced crime is approximately $100,000 per officer per year, implying that the current number of police is below the optimal level.\n",
    "\n",
    "http://pricetheory.uchicago.edu/levitt/Papers/LevittUsingElectoralCycles2002.pdf"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "**Juvenile Incarceration, Human Capital, and Future Crime: Evidence from Randomly Assigned Judges**. Anna Aizer, Joseph J. Doyle, Jr.\n",
    "\n",
    "- In this paper the authors were interested in the effect of juvenile incarcernation on future outcomes such as high school completion and adult recidivism of these kids.\n",
    "- Why didn't they just simply regress future outcomes (high school completion and adult recidivism) on juvenile incarcernation?\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "**Juvenile Incarceration, Human Capital, and Future Crime: Evidence from Randomly Assigned Judges**. Anna Aizer, Joseph J. Doyle, Jr.\n",
    "\n",
    "- To overcome endogeneity problems here the authors used dummies for each of the judges that handled the cases as instruments\n",
    "- Do you have any idea why this instrument can make sense?\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "**Juvenile Incarceration, Human Capital, and Future Crime: Evidence from Randomly Assigned Judges**. Anna Aizer, Joseph J. Doyle, Jr.\n",
    "\n",
    "\n",
    "a) the instrument is probably valid as judges are randomly assigned to a case\n",
    "\n",
    "<p>\n",
    "\n",
    "<center> <img src=\"figs\\judges_random.png\" width=\"400\"/> </center>\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "**Juvenile Incarceration, Human Capital, and Future Crime: Evidence from Randomly Assigned Judges**. Anna Aizer, Joseph J. Doyle, Jr.\n",
    "\n",
    "b) The instrument is relevant: judges differ in their incarceration tendency \n",
    "\n",
    "\n",
    "<p>\n",
    "\n",
    "<center> <img src=\"figs\\judges.png\" width=\"400\"/> </center>\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "**Juvenile Incarceration, Human Capital, and Future Crime: Evidence from Randomly Assigned Judges**. Anna Aizer, Joseph J. Doyle, Jr.\n",
    "\n",
    "Thus: the judge assigned for a case can be used as an instrumental variable to estimate causal effects of juvenile incarceration on high school completion and adult recidivism.\n",
    "- They find that juvenile incarceration results in substantially lower high school completion rates and higher adult incarceration rates, including for violent crimes. \n",
    "\n",
    "https://www.researchgate.net/publication/272413343_Juvenile_Incarceration_Human_Capital_and_Future_Crime_Evidence_from_Randomly-Assigned_Judges/link/5729f96b08ae2efbfdbc11bd/download"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "**Estimating the Payoff to Schooling Using the Vietnam-Era Draft Lottery**\n",
    "Joshua D. Angrist, Alan B. Krueger\n",
    "\n",
    "- Between 1970 and 1973 priority for military service was randomly assigned to draft-age men in a series of lotteries.\n",
    "- Many men who were at risk of being drafted managed to avoid military service by enrolling in school and obtaining an educational deferment.\n",
    "- The authors use the draft lottery as an instrument to estimate the return to education.\n",
    "- They find that an extra year of schooling acquired in response to the lottery is associated with 6.6 percent higher weekly earnings.\n",
    "\n",
    "https://sites.duke.edu/niou/files/2011/06/Angrist_lifetime-earningsmall.pdf"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "\n",
    "- Let's assume we want to estimate the effect of price on electricity generation\n",
    "- Any ideas about a potential instrument for electricity price?\n",
    "- Now assume we want to estimate the effect of electricity consumption on the price\n",
    "- Any idea about a potential instrument for electricity demand?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "**Direct versus Indirect Colonial Rule in India: Long-term Consequences**\n",
    "\n",
    "What is the IV in this paper? How is it justified? What do you think about it?\n",
    "\n",
    "https://www.hbs.edu/ris/Publication%20Files/05-041_1feff996-f50e-4e5a-b057-e0119cd19a62.pdf"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "**INSIDE THE FAMILY FIRM: THE ROLE OF FAMILIES IN SUCCESSION DECISIONS AND PERFORMANCE**\n",
    "\n",
    "\n",
    "What is the IV in this paper? How is it justified? What do you think about it?\n",
    "\n",
    "http://www.kaspermeisnernielsen.com/iff_qje.pdf"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "Another example:\n",
    "\n",
    "    \n",
    "**Economic Shocks and Civil Conflicts**\n",
    "    \n",
    "http://web.mit.edu/14.773/www/conflict_15apr03.pdf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "celltoolbar": "Slideshow",
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {
    "height": "352px",
    "width": "294px"
   },
   "number_sections": false,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
