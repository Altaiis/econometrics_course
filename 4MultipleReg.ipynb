{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "<h1> Introductory Econometrics in Python"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "**Table of Content**\n",
    "- Simple Regression with Cross-sectional Data\n",
    "- ***Multiple Regression with cross-sectioal Data, including Inference and Hypothesis testing***\n",
    "- Binary Dependent Variables\n",
    "- Regression Analysis with Panel Data\n",
    "- Estimation of Treatment Effects: Difference-in-difference Analysis "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "**Multiple Regression with cross-sectional data**\n",
    "1. Basic Concept\n",
    "2. Some notion on low R2\n",
    "3. Perfect Collinearity\n",
    "4. Endogeneous and exogeneous variables (e.g., Omitted Variable Bias)\n",
    "5. Potential Outcomes, Treatment Effects, and Policy\n",
    "6. Inference\n",
    "7. Further Issues: specification, functional forms, data problems\n",
    "8. Predictions\n",
    "9. Multiple Regressions with qualitative variables"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Multiple Regression Analysis ##"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Multiple Regression Analysis: Estimation\n",
    "\n",
    "- SLR.4 was: $E(u|x)=0$\n",
    "- But: often not the case (or at least unclear) that all other factors affecting $y$ are uncorrelated with $x$\n",
    "- Multiple regression analysis is more amenable to **ceteris paribus** analysis because it allows us to explicitly control for many other factors that simultaneously affect the dependent variable.\n",
    "- Important both for testing economic theories and for evaluating policy effects when we must rely on nonexperimental data.\n",
    "- Multiple regression models can accommodate many explanatory variables that may be correlated\n",
    "\n",
    "    $\\Rightarrow$ we can hope to infer causality in cases where simple regression analysis would be misleading."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "**Multiple Regression Analysis: Estimation**\n",
    "\n",
    "- Naturally: \n",
    "adding more factors that are useful for explaining $y$ to the model $\\rightarrow$ more of the variation in $y$ explained.\n",
    "- Thus: multiple regression analysis can be used to build better models for predicting the dependent variable.\n",
    "- Additional advantage of multiple regression analysis: fairly general functional form relationships can be incorporated.\n",
    "    - In the simple regression model, only one function of a single explanatory variable can appear in the equation:\n",
    "    - Multiple regression model allows for much more flexibility."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "**Multiple Regression Analysis**\n",
    "\n",
    "- We begin with some simple examples to show how multiple regression analysis can be used to solve problems that cannot be solved by simple regression.\n",
    "- The first example is a simple variation of the wage equation  for obtaining the effect of education on hourly wage but additionally include years of labor market experience _exper_:\n",
    "\n",
    "\\begin{equation*}\n",
    "wage=\\beta_0+\\beta_1educ+\\beta_2exper+u\n",
    "\\end{equation*}\n",
    "\n",
    "- Thus:\n",
    "    - wage is determined by the two explanatory or independent variables, education and experience,\n",
    "    - and by other unobserved factors, which are contained in $u$.\n",
    "    \n",
    "- We are still primarily interested in the effect of _educ_ on _wage_, holding fixed all other factors affecting _wage_, that is, we are interested in the parameter $\\beta_1$.\n",
    "- _exper_ is now taken out of the error term and put explicitly in the equation\n",
    "- Because exper appears in the equation, its coefficient, $\\beta_2$, measures the ceteris paribus effect of _exper_ on _wage_, which is also of some interest.\n",
    "- Allows us to measure the effect of education on wage, holding experience fixed.\n",
    "- In a simple regression analysis—which puts _exper_ in the error term—we would have to assume that experience is  uncorrelated with education, a tenuous assumption.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "**Multiple Regression Analysis**\n",
    "\n",
    "- Multiple regression analysis is also useful for generalizing functional relationships between variables.\n",
    "- As an example, suppose family consumption (_cons_) is a quadratic function of family income (_inc_)\n",
    "\n",
    "\\begin{equation*}\n",
    "cons=\\beta_0+\\beta_1inc+\\beta_2inc^2+u\n",
    "\\end{equation*}\n",
    "\n",
    "- In a model with $n$ variables the key assumption about how $u$ is related to $x_1$ and $x_2$ is\n",
    "\n",
    "\\begin{equation*}\n",
    "E(u|x_1,x_2)=0\n",
    "\\end{equation*}\n",
    "\n",
    "- For the _wage_ equation this implies that other factors affecting _wage_ are not related on average to _educ_ and _exper_\n",
    "- If we think innate ability is part of $u$, then we will need average ability levels to be the same across all combinations of education and experience in the working population.\n",
    "- This may or may not be true, but, as we will later, this is the question we need to ask in order to determine whether the method of ordinary least squares produces unbiased estimators.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "**Multiple Regression Analysis**\n",
    "\n",
    "- The general multiple linear regression (MLR) model can be written in the population as\n",
    "\n",
    "\\begin{equation*}\n",
    "y=\\beta_0+\\beta_1x_1+\\beta_2x_2+...+\\beta_kx_k+u\n",
    "\\end{equation*}\n",
    "\n",
    "- In _Python_ it is estimated\n",
    "\n",
    "```python\n",
    "reg = smf.ols(formula='y ~ xl + x2 + x3', data=sample)\n",
    "results = reg.fit()\n",
    "```\n",
    "\n",
    "- The constant is again added automatically\n",
    "- `smf.ols` creates an object which contains all relevant information and `fit` performes the estimation.\n",
    "- The estimation results are stored in a variable `results` using the code`results = reg.fit()`.\n",
    "- We can use this variable for further analyses.\n",
    "- For a typical regression output including a coefficient table, call `results.summary()`."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "**Example: Hourly Wage Equation**\n",
    "\n",
    "\n",
    "- Using the 526 observations on workers in WAGE1, we include _educ_ (years of education), _exper_ (years of labor market experience), and _tenure_ (years with the current employer) in an equation explaining _log(wage)_.\n",
    "- The estimated equation is  \n",
    "\n",
    "\n",
    "\\begin{equation*}\n",
    "\\hat{log(wage)}=0.284+0.092 educ+0.0041 exper + 0.022 tenure\n",
    "\\end{equation*}\n",
    "\n",
    "- As in the simple regression case, the coefficients have a percentage interpretation.\n",
    "- The only difference here is that they also have a ceteris paribus interpretation.\n",
    "- The coefficient .092 means that, holding _exper_ and _tenure_ fixed, another year of education is predicted to increase _log(wage)_ by .092, which translates into an approximate 9.2% increase in wage.\n",
    "- Alternatively, if we take two people with the same levels of experience and job tenure, the coefficient on _educ_ is the proportionate difference in predicted wage when their education levels differ by one year.\n",
    "- This measure of the return to education at least keeps two important productivity factors fixed; whether it is a good estimate of the ceteris paribus return to another year of education requires us to study the statistical properties of\n",
    "OLS (later)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "results.summary(): \n",
      "                            OLS Regression Results                            \n",
      "==============================================================================\n",
      "Dep. Variable:           np.log(wage)   R-squared:                       0.316\n",
      "Model:                            OLS   Adj. R-squared:                  0.312\n",
      "Method:                 Least Squares   F-statistic:                     80.39\n",
      "Date:                Tue, 14 Sep 2021   Prob (F-statistic):           9.13e-43\n",
      "Time:                        10:18:07   Log-Likelihood:                -313.55\n",
      "No. Observations:                 526   AIC:                             635.1\n",
      "Df Residuals:                     522   BIC:                             652.2\n",
      "Df Model:                           3                                         \n",
      "Covariance Type:            nonrobust                                         \n",
      "==============================================================================\n",
      "                 coef    std err          t      P>|t|      [0.025      0.975]\n",
      "------------------------------------------------------------------------------\n",
      "Intercept      0.2844      0.104      2.729      0.007       0.080       0.489\n",
      "educ           0.0920      0.007     12.555      0.000       0.078       0.106\n",
      "exper          0.0041      0.002      2.391      0.017       0.001       0.008\n",
      "tenure         0.0221      0.003      7.133      0.000       0.016       0.028\n",
      "==============================================================================\n",
      "Omnibus:                       11.534   Durbin-Watson:                   1.769\n",
      "Prob(Omnibus):                  0.003   Jarque-Bera (JB):               20.941\n",
      "Skew:                           0.021   Prob(JB):                     2.84e-05\n",
      "Kurtosis:                       3.977   Cond. No.                         135.\n",
      "==============================================================================\n",
      "\n",
      "Warnings:\n",
      "[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import wooldridge as woo\n",
    "import numpy as np\n",
    "import statsmodels.formula.api as smf\n",
    "#from scipy import stats\n",
    "\n",
    "wage1 = woo.dataWoo('wage1')\n",
    "\n",
    "reg = smf.ols(formula='np.log(wage) ~ educ + exper + tenure  ', data=wage1)\n",
    "results = reg.fit()\n",
    "print(f'results.summary(): \\n{results.summary()}\\n')\n",
    "\n",
    "#stats.describe(wage1.tenure)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "**Example: Explaining Arrest Records**\n",
    "\n",
    "- CRIME1 contains data on arrests during the year 1986 and other information on 2,725 men born in either 1960 or 1961 in California.\n",
    "- Each man in the sample was arrested at least once prior to 1986.\n",
    "    - The variable _narr86_ is the number of times the man was arrested during 1986: it is zero for most men in the sample (72.29%), and it varies from 0 to 12. (The percentage of men arrested once during 1986 was 20.51.)\n",
    "    - The variable _pcnv_ is the proportion (not percentage) of arrests prior to 1986 that led\n",
    "to conviction,\n",
    "    - _avgsen_ is average sentence length served for prior convictions (zero for most people),\n",
    "    - _ptime86_ is months spent in prison in 1986,\n",
    "    - and _qemp86_ is the number of quarters during which the man was employed in 1986 (from zero to four).  \n",
    "    \n",
    "A linear model explaining arrests is\n",
    "\n",
    "\\begin{equation*}\n",
    "narr96=\\beta_0+\\beta_1pcnv+\\beta_2avgsen+\\beta_3ptime86+\\beta_4qemp86+u\n",
    "\\end{equation*}\n",
    "\n",
    "\n",
    "where\n",
    "- _pcnv_ is a proxy for the likelihood for being convicted of a crime\n",
    "- and _avgsen_ is a measure of expected severity of punishment, if convicted.\n",
    "- _ptime86_ captures the incarcerative effects of crime: if an individual is in prison, he cannot be arrested for a crime outside of prison.\n",
    "- Labor market opportunities are crudely captured by _qemp86_.  \n",
    "\n",
    "\n",
    "First, we estimate the model without the variable _avgsen_. We obtain  \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "results.summary(): \n",
      "                            OLS Regression Results                            \n",
      "==============================================================================\n",
      "Dep. Variable:                 narr86   R-squared:                       0.041\n",
      "Model:                            OLS   Adj. R-squared:                  0.040\n",
      "Method:                 Least Squares   F-statistic:                     39.10\n",
      "Date:                Tue, 15 Sep 2020   Prob (F-statistic):           9.91e-25\n",
      "Time:                        13:39:04   Log-Likelihood:                -3394.7\n",
      "No. Observations:                2725   AIC:                             6797.\n",
      "Df Residuals:                    2721   BIC:                             6821.\n",
      "Df Model:                           3                                         \n",
      "Covariance Type:            nonrobust                                         \n",
      "==============================================================================\n",
      "                 coef    std err          t      P>|t|      [0.025      0.975]\n",
      "------------------------------------------------------------------------------\n",
      "Intercept      0.7118      0.033     21.565      0.000       0.647       0.776\n",
      "pcnv          -0.1499      0.041     -3.669      0.000      -0.230      -0.070\n",
      "ptime86       -0.0344      0.009     -4.007      0.000      -0.051      -0.018\n",
      "qemp86        -0.1041      0.010    -10.023      0.000      -0.124      -0.084\n",
      "==============================================================================\n",
      "Omnibus:                     2394.860   Durbin-Watson:                   1.836\n",
      "Prob(Omnibus):                  0.000   Jarque-Bera (JB):           106169.153\n",
      "Skew:                           4.002   Prob(JB):                         0.00\n",
      "Kurtosis:                      32.513   Cond. No.                         8.27\n",
      "==============================================================================\n",
      "\n",
      "Warnings:\n",
      "[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import wooldridge as woo\n",
    "import statsmodels.formula.api as smf\n",
    "\n",
    "crime1 = woo.dataWoo('crime1')\n",
    "\n",
    "# model without avgsen:\n",
    "reg = smf.ols(formula='narr86 ~ pcnv + ptime86 + qemp86', data=crime1)\n",
    "results = reg.fit()\n",
    "print(f'results.summary(): \\n{results.summary()}\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "\\begin{equation*}\n",
    "\\hat{narr86}=0.712-0.150 pcnv-0.034 ptime86-0.104 qemp86\n",
    "\\end{equation*}\n",
    "\n",
    "\\begin{equation*}\n",
    "n=2,725, R^2=0.0413\n",
    "\\end{equation*}\n",
    "\n",
    "\n",
    "- This equation says that, as a group, the three variables _pcnv, ptime86_, and _qemp86_ explain about 4.1% of the variation in narr86.\n",
    "- Each of the OLS slope coefficients has the anticipated sign:\n",
    "    - increase in the proportion of convictions lowers the predicted number of arrests.\n",
    "    - If we increase pcnv by .50 (a large increase in the probability of conviction), then, holding the other factors fixed, $\\Delta\\hat{narr86}=-0.15\\cdot0.5=-0.75$  \n",
    "\n",
    "\n",
    "- For example, among 100 men, the predicted fall in arrests when _pcnv_ increases by .50 is 0.75.\n",
    "- Similarly, a longer prison term leads to a lower predicted number of arrests.\n",
    "- In fact, if _ptime86_ increases from 0 to 12, predicted arrests for a particular man fall by $0.0341122\\cdot12=0.408$.\n",
    "- Another quarter in which legal employment is reported lowers predicted arrests by .104, which would be 10.4 arrests among 100 men.\n",
    "\n",
    "\n",
    "Now let us add _avgsen_ to the model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "results.summary(): \n",
      "                            OLS Regression Results                            \n",
      "==============================================================================\n",
      "Dep. Variable:                 narr86   R-squared:                       0.042\n",
      "Model:                            OLS   Adj. R-squared:                  0.041\n",
      "Method:                 Least Squares   F-statistic:                     29.96\n",
      "Date:                Tue, 15 Sep 2020   Prob (F-statistic):           2.01e-24\n",
      "Time:                        13:39:05   Log-Likelihood:                -3393.5\n",
      "No. Observations:                2725   AIC:                             6797.\n",
      "Df Residuals:                    2720   BIC:                             6826.\n",
      "Df Model:                           4                                         \n",
      "Covariance Type:            nonrobust                                         \n",
      "==============================================================================\n",
      "                 coef    std err          t      P>|t|      [0.025      0.975]\n",
      "------------------------------------------------------------------------------\n",
      "Intercept      0.7068      0.033     21.319      0.000       0.642       0.772\n",
      "pcnv          -0.1508      0.041     -3.692      0.000      -0.231      -0.071\n",
      "avgsen         0.0074      0.005      1.572      0.116      -0.002       0.017\n",
      "ptime86       -0.0374      0.009     -4.252      0.000      -0.055      -0.020\n",
      "qemp86        -0.1033      0.010     -9.940      0.000      -0.124      -0.083\n",
      "==============================================================================\n",
      "Omnibus:                     2396.990   Durbin-Watson:                   1.837\n",
      "Prob(Omnibus):                  0.000   Jarque-Bera (JB):           106841.658\n",
      "Skew:                           4.006   Prob(JB):                         0.00\n",
      "Kurtosis:                      32.611   Cond. No.                         10.2\n",
      "==============================================================================\n",
      "\n",
      "Warnings:\n",
      "[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import wooldridge as woo\n",
    "import statsmodels.formula.api as smf\n",
    "\n",
    "crime1 = woo.dataWoo('crime1')\n",
    "\n",
    "# model with avgsen:\n",
    "reg = smf.ols(formula='narr86 ~ pcnv + avgsen + ptime86 + qemp86', data=crime1)\n",
    "results = reg.fit()\n",
    "print(f'results.summary(): \\n{results.summary()}\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "If _avgsen_ is added to the model, we know that $R^2$ will increase. The estimated equation is \n",
    "\n",
    "\\begin{equation*}\n",
    "\\hat{narr86}=0.707-0.151 pcnv-0.037 ptime86-0.103 qemp86\n",
    "\\end{equation*}\n",
    "\n",
    "\\begin{equation*}\n",
    "n=2,725, R^2=0.0422\n",
    "\\end{equation*}\n",
    "\n",
    "- Thus, adding the average sentence variable increases $R^2$ from .0413 to .0422, a practically small effect.\n",
    "- The sign of the coefficient on _avgsen_ is also unexpected: it says that a longer average sentence length increases criminal activity."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "**Some notion on the low $R^2$:**\n",
    "    \n",
    "- The fact that the four explanatory variables included\n",
    "in the second regression explain only about 4.2% of the variation in narr86 does not necessarily\n",
    "mean that the equation is useless.\n",
    "- Even though these variables collectively do not explain much of the variation in arrests, it is still possible that the OLS estimates are reliable estimates of the ceteris paribus effects of each independent variable on narr86.\n",
    "- As we will see, whether this is the case does not directly depend on the size of $R^2$.\n",
    "- Generally, a low $R^2$ indicates that it is hard to predict individual outcomes on $y$ with much accuracy, something we study in more detail later.\n",
    "- In the arrest example, the small $R^2$ reflects what we already suspect in the social sciences: it is generally very difficult to predict individual behavior.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "**Some notion on the low $R^2$:**\n",
    "    \n",
    "- Also, the $R^2$ has the property that is increasing whenever new variables are added to the model.\n",
    "- This does not mean that our model really gets better by adding everything to it.\n",
    "- Because of this, there is also an adjusted version of the $R^2$ which takes the reduction in degrees of freedom into account, i.e. punishes the addition of new variables.\n",
    "\n",
    "- The Adjusted $R^2$ is routinely reported by most statistical software packages.\n",
    "- Moreover, you can only compare the $R^2$ for models based on the same set of observations.\n",
    "- When you add a variable which has missings for some observations the comparison of $R^2$ becomes obsolete."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "**Perfect collinearity:**\n",
    "\n",
    "- Assumption SLR.3 (sample variation in the explanatory variable) has to be extended in the multiple linear regression case.\n",
    "- The assumption is now that in the sample, \n",
    "\n",
    "    1. none of the independent variables is constant, \n",
    "    \n",
    "    AND\n",
    "    2. there are no exact linear relationships among the independent variables.\n",
    "    \n",
    "- Note: this does not exclude correlation between variables in general, they are most often correlated!\n",
    "- Perfect collinearity can arise due to many reasons:\n",
    "    - Obvious: two independent variables can be perfectly correlated when one variable is a constant multiple of another: \n",
    "        - a researcher inadvertently puts the same variable measured in different units into a regression equation (e.g. in \\\\$ or k \\\\$)\n",
    "        - What sense would it make to hold income measured in dollars fixed while changing income measured in thousands of dollars?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "**Perfect collinearity:**\n",
    "\n",
    "\n",
    "- Perfect collinearity can also arise due to more subtle reasons:    \n",
    "    -  in the case of adding a squared term of a variable but using logs\n",
    "    - why would this be a problem?\n",
    "       "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "**Perfect collinearity:**\n",
    "\n",
    "\n",
    "\n",
    "- Because $log(cons)=\\beta_0+\\beta_1log(inc)+\\beta2log(inc^2)+u$\n",
    "- As $log(inc^2)=2 log(inc)$ this is a linear combination\n",
    "\n",
    "Or another example:\n",
    "- For example, suppose we want to estimate the effect of campaign spending on campaign outcomes.\n",
    "- Assume that each election has two candidates and let _voteA_ be the percentage of the vote for Candidate A, and _expendA_ be campaign expenditures by Candidate A, let _expendB_ be campaign expenditures by Candidate B, and let _totexpend_ be total campaign expenditures\n",
    "          \n",
    "\\begin{equation*}\n",
    "voteA=\\beta_0+\\beta_1expendA+\\beta_2expendB+\\beta_3totalexpend+u\n",
    "\\end{equation*}\n",
    "\n",
    "What would be the problem here? How would you interpret this equation in a ceteris paribus fashion?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "**Perfect collinearity:**\n",
    "\n",
    "- Trying to interpret this equation in a ceteris paribus fashion reveals the problem: The parameter of $\\beta_1$ is supposed to measure the effect of increasing expenditures by Candidate A by one dollar on Candidate A’s vote, holding Candidate B’s spending and total spending fixed.\n",
    "- This is nonsense, because if expendB and totexpend are held fixed, then we cannot increase expendA."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "__Perfect collinearity__\n",
    "\n",
    "- What is the problem here?\n",
    "\n",
    "$log(wage)=\\beta_0+\\beta_1log(education)+\\beta2log(exper)+\\beta_3log(exper\\cdot educ)$\n",
    "   "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "**Multiple Regression Analysis**\n",
    "\n",
    "- The **Zero conditional mean** assumption is similar as before\n",
    "- The error $u$ has an expected of zero given any values of the independent variables:\n",
    "\n",
    "\\begin{equation*}\n",
    "E(u|x_1,x_2,...,x_k)=0\n",
    "\\end{equation*}\n",
    "\n",
    "- This assumption can fail if the functional relationship between the explained and explanatory variables is misspecified, for example (e.g. it's quadratic but we don't include a squared term)\n",
    "- Another functional form misspecification occurs when we use the level of a variable when the log of the variable is what actually shows up in the population model, or vice versa (e.g. the true model has log(wage) as the dependent variable but we use wage as the dependent variable in our regression analysis)\n",
    "- Then the estimators will be **biased**.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "**Multiple Regression Analysis**\n",
    "\n",
    "- Probably most important: Omitting an important factor that is correlated with any of $x_1, x_2, . . . , x_k$ causes  the zero conditional mean assumption to fail also.\n",
    "- With multiple regression analysis, we are able to include many factors among the explanatory variables, and omitted variables are less likely to be a problem in multiple regression analysis than in simple regression analysis.\n",
    "- Nevertheless, in any application, there are always factors that, due to data limitations or ignorance, we will not be able to include.\n",
    "- If we think these factors should be controlled for and they are correlated with one or more of the independent variables, then the zero conditional mean assumption will be violated.\n",
    "- We will derive this bias later and discuss potential solutions to overcome it."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "**Multiple Regression Analysis**\n",
    "\n",
    "- There are other ways how $u$ can be correlated with an explanatory variable, which we will discuss later.\n",
    "- When the zero conditional mean assumption holds, we often say that we have **exogenous explanatory variables**.\n",
    "- If $x_j$ is correlated with $u$ for any reason, then $x_j$ is said to be an **endogenous explanatory variable**.\n",
    "- The zero conditional mean assumption resricts the relationship between the unobserved factors in $ $and the explanatory variables but unfortunately, we will never know for sure whether the average value of the unobserved factors is unrelated to the explanatory variables.\n",
    "- But this is the critical assumption! We will see how to deal with it later.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "**Omitted Variable Bias**\n",
    "\n",
    "- Two special cases exist in which the simple regression of $y$ on $x_1$ will produce the same OLS estimate on $x_1$ as the regression of $y$ on $x_1$ and $x_2$.\n",
    "    - write the simple regression of $y$ on $x_1$ as $\\tilde{y}=\\tilde{\\beta}_0+\\tilde{\\beta}_1x_1$ and\n",
    "    - write the multiple regression as $\\hat{y}=\\hat{\\beta}_0+\\hat{\\beta}_1x_1+\\hat{\\beta_2}x_2$\n",
    "\n",
    "- We know that in the simple regression coefficient $\\tilde{\\beta}_1$  does not usually equal the multiple regression coefficient $\\hat{\\beta}_1$\n",
    "- It turns out there is a simple relationship between $\\tilde{\\beta}_1$ and $\\hat{\\beta}_1$, which allows for interesting comparisons between simple and multiple regression:\n",
    "\n",
    "\\begin{equation*}\n",
    "\\tilde{\\beta}_1=\\hat{\\beta}_1+\\hat{\\beta}_2\\tilde{\\delta}_1\n",
    "\\end{equation*}\n",
    "\n",
    "where $\\tilde{\\delta}_1$ is the slope coefficient from the simple regression of $x_2$ on $x_1$, $i=1, . . . , n$.\n",
    "- The confounding term is the partial effect of $x_2$ on $\\hat{y}$ times the slope in the simple regression of $x_2$ on $x_1$.\n",
    "- Thus, the bias of $\\tilde{\\beta}_1$ is of the magnitude $\\hat{\\beta}_2\\tilde{\\delta}_1$\n",
    "-  The relationship between $\\tilde{\\beta}_1$ and $\\hat{\\beta}_1$ also shows there are two distinct cases where they are equal:\n",
    "\n",
    "    - The partial effect of $x_2$ on $\\hat{y}$ is zero in the sample ($\\hat{\\beta}_2=0$)\n",
    "    - $x_1$ and $x_2$ are uncorrelated in the sample ($\\tilde{\\delta}_1=0$)\n",
    "- If none of these two cases applies there is a so called **omitted variable bias**."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "**Omitted Variable Bias**\n",
    "\n",
    "- Sometimes we know (at least) the direction of the bias.\n",
    "\n",
    "|Sign of omitted parameter $\\beta_2$| Corr($x_1,x_2)>0$ | Corr($x_1,x_2)<0$ |\n",
    "|---| :--- | :--- |\n",
    "|$\\beta_2>0$|  Positive bias | Negative bias |\n",
    "|$\\beta_2<0$| Negative bias | Positive bias |\n",
    "\n",
    "- Suppose we are interested in the effect of education on wages again and the true model is\n",
    "\n",
    "\\begin{equation*}\n",
    "wage=\\beta_0+\\beta_1educ+\\beta_2abil+u\n",
    "\\end{equation*}\n",
    "\n",
    "- Because we do not observe ability,  we estimate\n",
    "\n",
    "\\begin{equation*}\n",
    "wage=\\beta_0+\\beta_1educ+v\n",
    "\\end{equation*}\n",
    "\n",
    "where $v=\\beta_2abil+u$\n",
    "\n",
    "- What is the direction of the bias?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "- So even if don't observe ability we know how it affects our estimates.\n",
    "- But we observe experience. What direction is the bias if we do not include experience?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "results.summary(): \n",
      "                            OLS Regression Results                            \n",
      "==============================================================================\n",
      "Dep. Variable:           np.log(wage)   R-squared:                       0.249\n",
      "Model:                            OLS   Adj. R-squared:                  0.246\n",
      "Method:                 Least Squares   F-statistic:                     86.86\n",
      "Date:                Sat, 11 Sep 2021   Prob (F-statistic):           2.68e-33\n",
      "Time:                        20:33:37   Log-Likelihood:                -338.01\n",
      "No. Observations:                 526   AIC:                             682.0\n",
      "Df Residuals:                     523   BIC:                             694.8\n",
      "Df Model:                           2                                         \n",
      "Covariance Type:            nonrobust                                         \n",
      "==============================================================================\n",
      "                 coef    std err          t      P>|t|      [0.025      0.975]\n",
      "------------------------------------------------------------------------------\n",
      "Intercept      0.2169      0.109      1.997      0.046       0.004       0.430\n",
      "educ           0.0979      0.008     12.848      0.000       0.083       0.113\n",
      "exper          0.0103      0.002      6.653      0.000       0.007       0.013\n",
      "==============================================================================\n",
      "Omnibus:                        7.740   Durbin-Watson:                   1.789\n",
      "Prob(Omnibus):                  0.021   Jarque-Bera (JB):                9.485\n",
      "Skew:                           0.165   Prob(JB):                      0.00872\n",
      "Kurtosis:                       3.569   Cond. No.                         130.\n",
      "==============================================================================\n",
      "\n",
      "Warnings:\n",
      "[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import wooldridge as woo\n",
    "import numpy as np\n",
    "import statsmodels.formula.api as smf\n",
    "\n",
    "wage1 = woo.dataWoo('wage1')\n",
    "\n",
    "reg = smf.ols(formula='np.log(wage) ~ educ+ exper ', data=wage1)\n",
    "results = reg.fit()\n",
    "print(f'results.summary(): \\n{results.summary()}\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "**Omitted Variable Bias**\n",
    "\n",
    "As a second example:\n",
    "- suppose that, at the elementary school level, the average score for students on a standardized exam is determined by\n",
    "\n",
    "\\begin{equation*}\n",
    "avgscore=\\beta_0+\\beta_1expend+\\beta_2povrate+u\n",
    "\\end{equation*}\n",
    "\n",
    "where _expend_ is expenditure per student and _povrate_ is the poverty rate of the children in the school.\n",
    "- Using school district data, we only have observations on the percentage of students with a passing grade and per-student expenditures; we do not have information on poverty rates.\n",
    "- Thus, we estimate $\\beta_1$ from the simple regression of _avgscore_ on _expend_.\n",
    "\n",
    "- We can again obtain the likely bias in $\\tilde{\\beta}_1$\n",
    "- What do you think the bias will look like?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "**Omitted Variable Bias**\n",
    "\n",
    "- First, $\\beta_2$ is probably negative: there is ample evidence\n",
    "that children living in poverty score lower, on average, on standardized tests.\n",
    "- Second, the average expenditure per student is probably negatively correlated with the poverty rate: the higher the poverty rate, the lower the average per-student spending, so that $Corr(x_1,x_2)>0$.\n",
    "- Thus, $\\tilde{\\beta}_1$ will have a positive bias.\n",
    "- This observation has important implications:\n",
    "    - It could be that the true effect of spending is zero; that is, $\\beta_1=0$.\n",
    "    - However, the simple regression estimate of $\\tilde{\\beta_1}$ will be greater than zero, and this could lead us to conclude that expenditures are important when they are not.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "**Omitted Variable Bias**\n",
    "\n",
    "- When reading and performing empirical work in economics, it is important to master the terminology associated with biased estimators\n",
    "- In the context of omitting a variable , if $E(\\tilde{\\beta}_1>\\beta_1$), then we say that $\\tilde{\\beta}_1$ has an **upward bias**\n",
    "- In the opposite case we call it a **downward bias**\n",
    "- The phrase **biased toward zero** refers to cases where $E(\\tilde{\\beta}_1)$ is closer to zero than is $\\beta_1$. \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "**Omitted Variable Bias**\n",
    "\n",
    "- Deriving the sign of omitted variable bias when there are multiple regressors in the estimated model is more difficult.\n",
    "- We must remember that correlation between a single explanatory variable and the error generally results in all OLS estimators being biased.\n",
    "- For example, suppose the population model\n",
    "\n",
    "\\begin{equation*}\n",
    "y=\\beta_0+\\beta_1x_1+\\beta_2x_2+\\beta_3x_3\n",
    "\\end{equation*}\n",
    "\n",
    "- We omit $x_3$ and estimate the model\n",
    "- Now, suppose that $x_2$ and $x_3$ are uncorrelated, but $x_1$ is correlated with $x_3$.\n",
    "- In other words, $x_1$ is correlated with the omitted variable, but $x_2$ is not.\n",
    "- It is tempting to think that, while $\\beta_1$ is probably biased based on the derivation in the previous subsection, $\\beta_2$ is unbiased because $x_2$ is uncorrelated with $x_3$.\n",
    "- Unfortunately, this is not generally the case: $\\beta_1$ and $\\beta_2$ will normally be biased.\n",
    "- The only exception to this is when $x_1$ and $x_2$ are also uncorrelated.\n",
    "- For instance, in the example\n",
    "\n",
    "\n",
    "\\begin{equation*}\n",
    "y=\\beta_0+\\beta_1educ+\\beta_2exper+\\beta_3abil+u\n",
    "\\end{equation*}\n",
    "\n",
    "both, $\\beta_1$ and$\\beta_2$ will be biased if we omitt $abil$, even if $exper$ is uncorrelated with $abil$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "**Simulating Omitted Variable Bias**\n",
    "\n",
    "- Consider a model $y=\\beta_0+\\beta_{1}x_1+\\beta_{2}x_2+u$ \n",
    "- Assume there is a common component $r$ affecting $x_1$ and $x_2$ \n",
    "- Assume $\\beta_0$ = 1, $\\beta_1$=-0.3 and $\\beta_2$=0.7"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 1.77372292,  0.34481981, -1.14562961,  0.71533561,  0.13235647,\n",
       "       -0.18533965, -0.19659412,  0.41682005,  0.89778896,  0.78966118])"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# generate some random variables with the above characteristics\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from numpy.random import seed\n",
    "from numpy.random import rand\n",
    "from numpy.random import randn\n",
    "\n",
    "# generate a random common component for x1 and x2\n",
    "# seed random number generator\n",
    "seed(167765433)\n",
    "r = randn(100000)\n",
    "r[:10]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DescribeResult(nobs=100000, minmax=(-4.312902329603882, 4.258398185972333), mean=-0.0012581912394731525, variance=1.0000838718581773, skewness=-0.0014510567073173907, kurtosis=-0.002054989955218467)"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from scipy import stats\n",
    "stats.describe(r)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 576x396 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "plt.style.use('seaborn')\n",
    "count, bins, ignored = plt.hist(r, 15, density=True)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Y</th>\n",
       "      <th>X1</th>\n",
       "      <th>X2</th>\n",
       "      <th>e</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-3.240638</td>\n",
       "      <td>3.398068</td>\n",
       "      <td>-3.478395</td>\n",
       "      <td>-0.786340</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1.808476</td>\n",
       "      <td>-0.266937</td>\n",
       "      <td>-2.049493</td>\n",
       "      <td>2.163040</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>-1.300795</td>\n",
       "      <td>-1.673801</td>\n",
       "      <td>-2.962245</td>\n",
       "      <td>-0.729364</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1.257625</td>\n",
       "      <td>-0.357633</td>\n",
       "      <td>-1.955675</td>\n",
       "      <td>1.519308</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>-1.773668</td>\n",
       "      <td>0.997764</td>\n",
       "      <td>-2.803746</td>\n",
       "      <td>-0.511717</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          Y        X1        X2         e\n",
       "0 -3.240638  3.398068 -3.478395 -0.786340\n",
       "1  1.808476 -0.266937 -2.049493  2.163040\n",
       "2 -1.300795 -1.673801 -2.962245 -0.729364\n",
       "3  1.257625 -0.357633 -1.955675  1.519308\n",
       "4 -1.773668  0.997764 -2.803746 -0.511717"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# generate x1 and x2\n",
    "seed(1)\n",
    "x1 = randn(100000)+r\n",
    "x2 = randn(100000)-3+r\n",
    "\n",
    "# generate random error\n",
    "e = randn(100000)\n",
    "\n",
    "# generate y\n",
    "y = 1 - 0.3*x1 + 0.7*x2 + e\n",
    "\n",
    "# generate dataframe\n",
    "df = pd.DataFrame({'Y' : y, 'X1': x1, 'X2':x2,'e':e})\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "scrolled": true,
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Y</th>\n",
       "      <th>X1</th>\n",
       "      <th>X2</th>\n",
       "      <th>e</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>100000.000000</td>\n",
       "      <td>100000.000000</td>\n",
       "      <td>100000.000000</td>\n",
       "      <td>100000.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>-1.101529</td>\n",
       "      <td>0.003995</td>\n",
       "      <td>-2.997574</td>\n",
       "      <td>-0.002028</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>1.321183</td>\n",
       "      <td>1.409322</td>\n",
       "      <td>1.412244</td>\n",
       "      <td>1.002965</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>-6.476633</td>\n",
       "      <td>-6.468601</td>\n",
       "      <td>-9.589595</td>\n",
       "      <td>-4.197432</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>-1.998156</td>\n",
       "      <td>-0.941525</td>\n",
       "      <td>-3.954581</td>\n",
       "      <td>-0.675182</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>-1.107798</td>\n",
       "      <td>0.006621</td>\n",
       "      <td>-2.992871</td>\n",
       "      <td>-0.006408</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>-0.210972</td>\n",
       "      <td>0.957663</td>\n",
       "      <td>-2.043472</td>\n",
       "      <td>0.673711</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>4.366939</td>\n",
       "      <td>6.223094</td>\n",
       "      <td>3.203332</td>\n",
       "      <td>4.530903</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                   Y             X1             X2              e\n",
       "count  100000.000000  100000.000000  100000.000000  100000.000000\n",
       "mean       -1.101529       0.003995      -2.997574      -0.002028\n",
       "std         1.321183       1.409322       1.412244       1.002965\n",
       "min        -6.476633      -6.468601      -9.589595      -4.197432\n",
       "25%        -1.998156      -0.941525      -3.954581      -0.675182\n",
       "50%        -1.107798       0.006621      -2.992871      -0.006408\n",
       "75%        -0.210972       0.957663      -2.043472       0.673711\n",
       "max         4.366939       6.223094       3.203332       4.530903"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "We first estimate the unbiased model $\\hat{y}=\\hat{\\beta}_0+\\hat{\\beta}_1x_1+\\hat{\\beta}_2x_2+\\hat{u}$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                            OLS Regression Results                            \n",
      "==============================================================================\n",
      "Dep. Variable:                      y   R-squared:                       0.329\n",
      "Model:                            OLS   Adj. R-squared:                  0.329\n",
      "Method:                 Least Squares   F-statistic:                 2.454e+04\n",
      "Date:                Mon, 14 Sep 2020   Prob (F-statistic):               0.00\n",
      "Time:                        16:49:05   Log-Likelihood:            -1.4219e+05\n",
      "No. Observations:              100000   AIC:                         2.844e+05\n",
      "Df Residuals:                   99997   BIC:                         2.844e+05\n",
      "Df Model:                           2                                         \n",
      "Covariance Type:            nonrobust                                         \n",
      "==============================================================================\n",
      "                 coef    std err          t      P>|t|      [0.025      0.975]\n",
      "------------------------------------------------------------------------------\n",
      "Intercept      0.9940      0.010     98.945      0.000       0.974       1.014\n",
      "x1            -0.3010      0.002   -134.273      0.000      -0.305      -0.297\n",
      "x2             0.6987      0.003    219.619      0.000       0.692       0.705\n",
      "==============================================================================\n",
      "Omnibus:                        0.210   Durbin-Watson:                   1.999\n",
      "Prob(Omnibus):                  0.901   Jarque-Bera (JB):                0.214\n",
      "Skew:                          -0.003   Prob(JB):                        0.899\n",
      "Kurtosis:                       2.997   Cond. No.                         11.7\n",
      "==============================================================================\n",
      "\n",
      "Warnings:\n",
      "[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.\n"
     ]
    }
   ],
   "source": [
    "# estimate unbiased OLS model\n",
    "import statsmodels.formula.api as smf    # for the ols and robust ols model\n",
    "import statsmodels.api as sm\n",
    "\n",
    "formula = \"y ~ x1 + x2 \"\n",
    "results = smf.ols(formula, df).fit()\n",
    "print(results.summary())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "Now we assume we don't observe $x_2$ and instead estimate\n",
    "\n",
    "\\begin{equation*}\n",
    "\\tilde{y}=\\tilde{\\beta}_0+\\tilde{\\beta}_1x_1\n",
    "\\end{equation*}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                            OLS Regression Results                            \n",
      "==============================================================================\n",
      "Dep. Variable:                      y   R-squared:                       0.006\n",
      "Model:                            OLS   Adj. R-squared:                  0.006\n",
      "Method:                 Least Squares   F-statistic:                     575.3\n",
      "Date:                Mon, 14 Sep 2020   Prob (F-statistic):          9.03e-127\n",
      "Time:                        16:49:05   Log-Likelihood:            -1.6187e+05\n",
      "No. Observations:              100000   AIC:                         3.237e+05\n",
      "Df Residuals:                   99998   BIC:                         3.238e+05\n",
      "Df Model:                           1                                         \n",
      "Covariance Type:            nonrobust                                         \n",
      "==============================================================================\n",
      "                 coef    std err          t      P>|t|      [0.025      0.975]\n",
      "------------------------------------------------------------------------------\n",
      "Intercept     -1.0994      0.004   -284.705      0.000      -1.107      -1.092\n",
      "x1             0.0464      0.002     23.985      0.000       0.043       0.050\n",
      "==============================================================================\n",
      "Omnibus:                        8.077   Durbin-Watson:                   1.997\n",
      "Prob(Omnibus):                  0.018   Jarque-Bera (JB):                8.081\n",
      "Skew:                           0.020   Prob(JB):                       0.0176\n",
      "Kurtosis:                       2.982   Cond. No.                         2.00\n",
      "==============================================================================\n",
      "\n",
      "Warnings:\n",
      "[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.\n"
     ]
    }
   ],
   "source": [
    "formula = \"y ~ x1\"\n",
    "results = smf.ols(formula, df).fit()\n",
    "print(results.summary())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "Let's now compare the two regression\n",
    "   - the one where we omit $x_2$ that is correlated with our variable of interest and the dependent variable \n",
    "   - the other one where $x_2$ is also included"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "===========================\n",
      "             y        y    \n",
      "            (1)      (2)   \n",
      "---------------------------\n",
      "Intercept 1.00***  -1.10***\n",
      "          (0.01)   (0.00)  \n",
      "x1        -0.30*** 0.05*** \n",
      "          (0.00)   (0.00)  \n",
      "x2        0.70***          \n",
      "          (0.00)           \n",
      "N         100000   100000  \n",
      "R2        0.42     0.00    \n",
      "===========================\n",
      "Standard errors in\n",
      "parentheses.\n",
      "* p<.1, ** p<.05, ***p<.01\n"
     ]
    }
   ],
   "source": [
    "import statsmodels.api as sm\n",
    "from statsmodels.iolib.summary2 import summary_col\n",
    "\n",
    "formula = \"y ~ x1 + x2\"\n",
    "reg1 = smf.ols(formula, df).fit()\n",
    "formula = \"y ~ x1\"\n",
    "reg2 = smf.ols(formula, df).fit()\n",
    "\n",
    "dfoutput = summary_col([reg1,reg2],stars=True,float_format='%0.2f',\n",
    "                  model_names=['y\\n(1)','y\\n(2)'],\n",
    "                  info_dict={'N':lambda x: \"{0:d}\".format(int(x.nobs)),\n",
    "                             'R2':lambda x: \"{:.2f}\".format(x.rsquared)})\n",
    "print(dfoutput)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "**Note:** The bias of the parameter of interest is not introduced because a variable that affects $y$ is omitted in the regression model!\n",
    "\n",
    "The bias results because the missing (unobserved) variable is also correlated with one of the $x$ variables!\n",
    "\n",
    "- Now consider a model $y=\\beta_0+\\beta_{1}x_1+\\beta_{2}x_2+\\beta_{3}x_3+u$ \n",
    "- Assume $\\beta_1$ = 1, $\\beta_1$=-0.3 and $\\beta_2$=0.7 AND $\\beta_3$=0.5\n",
    "- Again assume that $x_1$ and $x_2$ are correlated but uncorrelated with $x_3$\n",
    "- Though $x_3$ affects $y$ omitting it does not introduce a bias\n",
    "- Not necessarily important to put everything into the model that affects $y$, that's not the issue"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "# generate x3 which is uncorrelated to x1 and x2\n",
    "seed(1)\n",
    "x1 = randn(100000)+r\n",
    "x2 = randn(100000)-3+r\n",
    "x3 = randn(100000)\n",
    "e = randn(100000)\n",
    "\n",
    "# adjust y\n",
    "y = 1 - 0.3*x1 + 0.7*x2 - 0.4*x3 + e\n",
    "\n",
    "# generate dataframe\n",
    "df = pd.DataFrame({'y' : y, 'x1': x1, 'x2':x2,'x3':x3,'e':e})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=============================================\n",
      "             y        y        y        y    \n",
      "            (0)      (1)      (2)      (3)   \n",
      "---------------------------------------------\n",
      "Intercept -1.10*** -1.10*** 1.00***  1.01*** \n",
      "          (0.00)   (0.00)   (0.01)   (0.01)  \n",
      "x1        0.05***  0.05***  -0.30*** -0.30***\n",
      "          (0.00)   (0.00)   (0.00)   (0.00)  \n",
      "x2                          0.70***  0.70*** \n",
      "                            (0.00)   (0.00)  \n",
      "x3                 -0.40*** -0.40***         \n",
      "                   (0.00)   (0.00)           \n",
      "N         100000   100000   100000   100000  \n",
      "R2        0.01     0.10     0.40     0.30    \n",
      "=============================================\n",
      "Standard errors in parentheses.\n",
      "* p<.1, ** p<.05, ***p<.01\n"
     ]
    }
   ],
   "source": [
    "import statsmodels.api as sm\n",
    "from statsmodels.iolib.summary2 import summary_col\n",
    "\n",
    "formula = \"y ~ x1\"\n",
    "reg1 = smf.ols(formula, df).fit()\n",
    "formula = \"y ~ x1 + x3\"\n",
    "reg2 = smf.ols(formula, df).fit()\n",
    "formula = \"y ~ x1 + x2 + x3\"\n",
    "reg3 = smf.ols(formula, df).fit()\n",
    "formula = \"y ~ x1 + x2\"\n",
    "reg4 = smf.ols(formula, df).fit()\n",
    "\n",
    "dfoutput = summary_col([reg1,reg2,reg3,reg4],stars=True,float_format='%0.2f',\n",
    "                  model_names=['y\\n(0)','y\\n(1)','y\\n(2)','y\\n(3)'],\n",
    "                  info_dict={'N':lambda x: \"{0:d}\".format(int(x.nobs)),\n",
    "                             'R2':lambda x: \"{:.2f}\".format(x.rsquared)})\n",
    "print(dfoutput)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "**Potential Outcomes, Treatment Effects, and Policy Analysis**\n",
    "\n",
    "- For most practicing economists, the most exciting applications of multiple regression are in trying to estimate causal effects of policy interventions.\n",
    "    - Do job training programs increase labor earnings? By how much?\n",
    "    - Do school choice programs improve student outcomes? Does legalizing marijuana increase crime rates?\n",
    "    \n",
    "- We introduced the potential outcomes approach to studying policy questions already.\n",
    "- In particular, we studied simple regression in the context of a binary policy intervention, using the notion of **counterfactual outcomes**.\n",
    "- We now change notation slightly, using $w$ to denote the binary intervention or policy indicator.\n",
    "- As before, for each unit in the population we imagine the existence of the potential outcomes, $y(0)$ and $y(1)$  representing different states of the world.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "**Potential Outcomes, Treatment Effects, and Policy Analysis**\n",
    "\n",
    "- If we assume a constant treatment effect, say $\\tau$, then we can write, for any unit $i$,\n",
    "\n",
    "\\begin{equation*}\n",
    "y_i(1)=\\tau+y_i(0)\n",
    "\\end{equation*}\n",
    "\n",
    "- When the treatment effect can vary by $i$, the average treatment effect is\n",
    "\n",
    "\\begin{equation*}\n",
    "\\tau_{ate}=E[y_i(1)]-y_i(0)\n",
    "\\end{equation*}\n",
    "\n",
    "\n",
    "where the expectation is taken over the entire population.\n",
    "\n",
    "- For a random draw $i$, the outcome we observe, $y_i$, can be written\n",
    "\n",
    "\\begin{equation*}\n",
    "y_i=(1-w_i)y_i(0)+w_iy_i(1)\n",
    "\\end{equation*}\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "**Potential Outcomes, Treatment Effects, and Policy Analysis**\n",
    "\n",
    "- Recall: the simple regression of $y$ on $w$ (with an intercept, as usual) is an unbiased estimator of $\\tau_{ate}$ only if we have random assignment of $w$ — that is, $w$ is independent of $[y(0), y(1)]$.\n",
    "- Random assignment is still pretty rare in business, economics, and other social sciences because true experiments are still somewhat rare.\n",
    "- Fortunately, if we can control variables — variables that help predict the potential outcomes and determine assignment into the treatment and control groups — we can use multiple regression.\n",
    "- Letting $x$ again denote a set of control variables, consider the following assumption: \n",
    "\n",
    "$w$ is independent of $[y(0), y(1)]$ conditional on $x$. \n",
    "\n",
    "\n",
    "- This assumption is called **conditional independence**, where it is important to note the variables in $x$ that are in the conditioning set.\n",
    "- In the treatment effects literature, it is also called **unconfounded assignment** or **unconfoundedness conditional on $x$**."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "**Example for conditional independence**\n",
    "- Consider a job training program some workers attended in 2017\n",
    "- We are interested in how it affect on a workers earning in 2018\n",
    "- Let us first estimate a simple regression (earnings in 1000 USD)\n",
    "\n",
    "\\begin{equation*}\n",
    "\\hat{earn18}=10.61 - 2.05\\mathit{train17}\n",
    "\\end{equation*}\n",
    "\n",
    "- Damn! Job traings reduce your income, don't do them or you get poor!\n",
    "- Really?\n",
    "- Problem with the above simple regression? Who does job trainings?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "**Example for conditional independence**\n",
    "\n",
    "- Problem: Participation in a job training program is not random! \n",
    "- People with already lower income or less education  are probably more likely to attend a job training on average.\n",
    "- Previous earnings and education both affect earnings AND are correlated with participation in a job training program.\n",
    "\n",
    "$\\rightarrow$  $w$ is not independent of $[y(0),y(1)]$ when we only regress $earn18$ on $train17$\n",
    "\n",
    "- Let us add other factors\n",
    "\n",
    "\\begin{equation*}\n",
    "\\hat{earn18}=4.67 + 2.41\\mathit{train17}+0.373\\mathit{earn16}+0.363\\mathit{educ}+0.181\\mathit{exper}+2.48\\mathit{married}\n",
    "\\end{equation*}\n",
    "\n",
    "- Effect is now positive\n",
    "- Interpretation:\n",
    "    - Consider the group of people with 12 years of schooling who are 35 years old and who had average earnings of 25,000 USD the past two years.\n",
    "    - What the **conditional indepence assumption** requires is that within this group, assignment to the treatment\n",
    "and control groups is random.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "**Example for conditional independence**\n",
    "\n",
    "- The more variables we observe prior to implementation of the program the more likely the unconfoundness assumption\n",
    "is to hold.\n",
    "- If we observe no information to include in $x$ then we are back to assuming pure random\n",
    "assignment.\n",
    "- But: still possible that we did not include all the correct variables in $x$.\n",
    "- For example: perhaps everyone in a sample from the eligible population was administered a test to measure intelligence, and assignment to the program is partly based on the score from the test.\n",
    "- If we cannot observe the test score, it must be excluded from $x$ and the unconfoundness assumption would generally fail—although it could be \"close\" to being true if we have other good controls in $x$."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "<h3>Inference</h3>\n",
    "\n",
    "- We now turn to the problem of testing hypotheses about the parameters in the population regression model\n",
    "- We begin by finding the distributions of the OLS estimators under the added assumption that the population error is normally distributed.\n",
    "- We then cover hypothesis testing about individual parameters"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "**Sampling Distribution of the OLS Estimators**\n",
    "\n",
    "So far:\n",
    "\n",
    "- we have formed a set of assumptions under which OLS is unbiased\n",
    "- We have also derived and discussed the bias caused by omitted variables.\n",
    "- We have obtained the variances of the OLS estimators under the basic assumptions.\n",
    "\n",
    "Thus: \n",
    "\n",
    "- we know the expected value and variance of the OLS estimators\n",
    "\n",
    "This is useful for describing the precision of the OLS estimators.\n",
    "\n",
    "- But: in order to perform statistical inference, we need to know more than just the first two moments of $\\hat{\\beta}_j$:\n",
    "\n",
    "$\\rightarrow$ we need to know the full sampling distribution of the $\\hat{\\beta}_j$."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "**Sampling Distribution of the OLS Estimators**\n",
    "\n",
    "- Even under the basic assumptions, the distribution of $\\hat{\\beta}_j$ can have virtually any shape.\n",
    "- When we condition on the values of the independent variables in our sample, it is clear that the sampling distributions of the OLS estimators depend on the underlying distribution of the errors.\n",
    "- To make the sampling distributions of the $\\hat{\\beta}_j$  tractable, we now assume that the unobserved error is normally distributed in the population.\n",
    "- We call this the **normality assumption**.\n",
    "\n",
    "<blockquote> $\\textbf{Normality}$: The population error $u$ is independent of the explanatory variables $x_1, x_2, . . . , x_k$ and is normally distributed with zero mean and variance $\\sigma^2:u\\backsim Normal(0,\\sigma^2)$.</blockquote> "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "**Sampling Distribution of the OLS Estimators**\n",
    "\n",
    "- Obviously, the **normality assumption** includes the zero conditional mean assumption and the homoscedasticity assumption as it includes \n",
    "\n",
    "\\begin{equation}\n",
    "E(u|x_1,x_2,...,x_k)=E(u)=0 \n",
    "\\end{equation}\n",
    "\n",
    "and \n",
    "\n",
    "\\begin{equation}\n",
    "Var(u|x_1,...,x_k)=Var(u)=\\sigma^2\n",
    "\\end{equation}\n",
    "\n",
    "\n",
    "- But: It is an even stronger assumption as it additionall requires that error terms are normally disributed\n",
    "- If the normality assumption is additionally fullfilled, it can be shown that the OLS estimator has the smallest variance among unbiased estimators (not only among linear estimators)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "**Sampling Distribution of the OLS Estimators**\n",
    "\n",
    "- How is the normality assumption justified?\n",
    "- The argument justifying the normal distribution for the errors usually runs something like this:\n",
    "- Because $u$ is the sum of many different unobserved factors affecting $y$, we can invoke the **central limit theorem (CLT)** (with large $n$ the sample mean $\\bar{y}$ of a random sample will eventually _always_ be normally distributed, no matter what the distribution of $y$ is) to conclude that u has an approximate normal distribution.\n",
    "- This argument has some merit, but it is not without weaknesses.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "**Sampling Distribution of the OLS Estimators**\n",
    "\n",
    "- First, the factors in $u$ can have very different distributions in the population (for example, ability and quality of schooling in the error in a wage equation).\n",
    "- Although the CLT can still hold in such cases, the normal approximation can be poor depending on how many factors appear in u and how different their distributions are.\n",
    "- A more serious problem with the CLT argument is that it assumes that all unobserved factors affect $y$ in a separate, additive fashion.\n",
    "- Nothing guarantees that this is so: if $u$ is a complicated function of the unobserved factors, then the CLT argument does not really apply.\n",
    "- In any application, whether normality of $u$ can be assumed is really an empirical matter.\n",
    "- For example, there is no theorem that says wage conditional on educ, exper, and tenure is normally distributed."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "**Sampling Distribution of the OLS Estimators**\n",
    "\n",
    "- If anything, simple reasoning suggests that the opposite is true: because wage can never be less than zero, it cannot, strictly speaking, have a normal distribution.\n",
    "- Further, because there are minimum wage laws, some fraction of the population earns exactly the minimum wage, which also violates the normality assumption.\n",
    "- Nevertheless, as a practical matter, we can ask whether the conditional wage distribution is \"close\" to being normal.\n",
    "- Past empirical evidence suggests that normality is not a good assumption for wages.\n",
    "- Often, using a transformation, especially taking the log, yields a distribution that is closer to normal.\n",
    "- For example, something like log(price) tends to have a distribution that looks more normal than the distribution of price.\n",
    "- But: non-normality of the errors is not a serious problem with large sample sizes, so we can make this assumption in general."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "**Sampling Distribution of the OLS Estimators**\n",
    "\n",
    "- Normality of the error term translates into normal sampling distributions of the OLS estimators:\n",
    "\n",
    "<blockquote> **Normal Sampling Distribution**\n",
    "\n",
    "Conditional on the sample values of the independent\n",
    "variables,\n",
    "\n",
    "\\begin{equation*}\n",
    "\\hat{\\beta}_j\\backsim Normal[\\beta_j, Var(\\hat{\\beta}_j],\n",
    "\\end{equation*}\n",
    "\n",
    "which can be rewritten as\n",
    "\n",
    "\\begin{equation*}\n",
    "(\\hat{\\beta}_j-\\beta_j)/sd(\\hat{\\beta}_j)\\backsim Normal(0,1),\n",
    "\\end{equation*}\n",
    "\n",
    "by standardizing a normal random variable by subtracting off its mean and dividing by its standard deviation.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "**Hypothesis Testing**\n",
    "\n",
    "- We now study how to test hypotheses about a particular $\\beta_j$ in a population regression model of the form\n",
    "\n",
    "\\begin{equation*}\n",
    "y=\\beta_0+\\beta_1x_1+...+\\beta_kx_k+u\n",
    "\\end{equation*}  \n",
    "\n",
    "\n",
    "where we asume that it satisfies the introduced assumptions.\n",
    "\n",
    "- Remember: the $\\beta_j$ are unknown features of the population, and we will never know them with certainty. \n",
    "- But: we can hypothesize about the value of $\\beta_j$ and then use statistical inference to test our hypothesis.\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "**Hypothesis Testing**\n",
    "\n",
    "Example: wage equation\n",
    "\n",
    "\\begin{equation*}\n",
    "log(wage)=\\beta_0+\\beta_1educ+\\beta_2IQ+u\n",
    "\\end{equation*}  \n",
    "\n",
    "Hypothesis:\n",
    "\n",
    "Given IQ, educ does not affect log(Wage) $\\Leftrightarrow \\beta_1=0$\n",
    "\n",
    "$\\rightarrow$ We use OLS analyses to test the hypothesis of no ceteris paribus effect of education."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "**Hypothesis Testing**\n",
    "\n",
    "- In order to construct hypotheses tests, we need the following result:\n",
    "\n",
    "<blockquote> $\\textbf{t Distribution for the Standardized Estimators}$\n",
    "\n",
    "\\begin{equation*}\n",
    "(\\hat{\\beta}_j-\\beta_j)/se(\\hat{\\beta}_j)\\backsim t_{n-k-1}=t_{df},\n",
    "\\end{equation*}\n",
    "\n",
    "\n",
    "where $k+1$ is the number of unknown parameters in the population model $y=\\beta_0+\\beta_1x1+...+\\beta_kx_k+u$ (_k_ slope parameters and the intercept) and $n-k$ is the degree of freedoms (df).\n",
    "</blockquote>\n",
    "\n",
    "- The $t$ distribution above (in contrast to the normal distribution from the previous formula) comes from the fact that the constant $\\sigma$ in $sd(\\hat{\\beta}_1)$ has been replaced with the random variable $\\hat{\\sigma}$. (The proof that this\n",
    "leads to a t distribution with $n-k-1$ degrees of freedom is difficult and not especially instructive.)\n",
    "- Advantage of this standardized estimator: the t-distribution with many dfs is asymptotically standard normal distribution.\n",
    "- Thus: with the standardized estimator we get the same distribution for every parameter (regardless of the actual  mean and standard deviation of $\\beta$)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "**Hypothesis Testing**\n",
    "\n",
    "- The above theorem allows us to test hypotheses involving the **unknown** $\\beta_j$.\n",
    "- In most applications, our primary interest lies in testing the **null hypothesis** \n",
    "\n",
    "\\begin{equation*}\n",
    "H_0:\\beta_j=0\n",
    "\\end{equation*}\n",
    "where $j$ corresponds to any of the $k$ independent variables.\n",
    "\n",
    "- Because $\\beta_j$ measures the partial effect of $x_j$ on (the expected value of) _y_, after controlling for all other independent variables, this means that, once $x_1$, $x_2$, . . . , $x_k$ have been accounted for, $x_j$ has no effect on the expected value of $y$.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "**Hypothesis Testing**\n",
    "\n",
    "- As an example consider\n",
    "\n",
    "\\begin{equation*}\n",
    "log(wage)=\\beta_0+\\beta_1educ+\\beta_2exper+\\beta_3tenure+u\n",
    "\\end{equation*}\n",
    "\n",
    "- The null hypothesis $H_0:\\beta_2=0$ means that, once education and tenure have been accounted for, the number of years in the workforce (_exper_) has no effect on hourly wage.\n",
    "- If it is true, it implies that a person’s work history prior to the current employment does not affect wage.\n",
    "- If $\\beta_2>0$, then prior work experience contributes to productivity, and hence to wage.\n",
    "- The statistic we use to test the null hypothesis (against any alternative) is called a **t- statistic** of $\\hat{\\beta}_j$ and is defined as\n",
    "\n",
    "\n",
    "\\begin{equation*}\n",
    "t_\\hat{{\\beta}_j}=\\hat{{\\beta}_j}/se(\\hat{\\beta}_j)\n",
    "\\end{equation*}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "**Hypothesis Testing**\n",
    "\n",
    "- In any interesting application, the point estimate $\\hat{\\beta}_j$ will never exactly be zero, whether or not $H_0$ is true.\n",
    "- The question is: How far is $\\hat{\\beta}_j$ from zero?\n",
    "- A sample value of $\\hat{\\beta}_j$ very far from zero provides evidence against $H_0:\\beta_j=0$.\n",
    "- However, we must recognize that there is a sampling error in our estimate $\\hat{\\beta}_j$, so the size of $\\hat{\\beta}_j$ must be weighed against its sampling error.\n",
    "- Because the standard error of $\\hat{\\beta}_j$ is an estimate of the standard deviation of $\\hat{\\beta}_j$, $t_\\hat{{\\beta}_j}$ measures how many estimated standard deviations $\\hat{\\beta}_j$ is away from zero.\n",
    "- This is precisely what we do in testing whether the mean of a population is zero, using the standard t statistic from introductory statistics.\n",
    "- Values of $t_\\hat{{\\beta}_j}$  sufficiently far from zero will result in a rejection of $H_0$.\n",
    "- The precise rejection rule depends on the alternative hypothesis and the chosen significance level of the test."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "**Hypothesis Testing**\n",
    "\n",
    "- To determine a rule for rejecting $H_0$, we need to decide on the relevant alternative hypothesis.\n",
    "- First, consider a one-sided alternative of the form\n",
    "\n",
    "\\begin{equation*}\n",
    "H_1: \\beta_j>0\n",
    "\\end{equation*}\n",
    "\n",
    "- How should we choose a rejection rule?\n",
    "- We must first decide on a **significance level** for the probability of rejecting $H_0$ when it is in fact true.\n",
    "- Suppose we have decided on a 5% significance level, as this is the most popular choice.\n",
    "- Thus, we are willing to mistakenly reject $H_0$ when it is true 5% of the time.\n",
    "\n",
    "| Decision $\\downarrow$/Reality $\\rightarrow$| $H_0$ is true | $H_0$ is false |\n",
    "| :- | --- | --- |\n",
    "| not reject $H_0$  | correct | Type II error |\n",
    "| reject $H_0$ | Type I error | correct! |\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "**Hypothesis Testing**\n",
    "\n",
    "- Now, while $t_\\hat{{\\beta}_j}$ has a _t_ distribution under $H_0$ — so that it has zero mean — under the alternative $\\beta_j>0$ the expected value of $t_\\hat{{\\beta}_j}$ is positive.\n",
    "- Thus, we are looking for a \"sufficiently large\" positive value of $t_\\hat{{\\beta}_j}$ in order to reject $H_0: \\beta_j=0$ in favor of $H_1: \\beta_j>0$.\n",
    "- The definition of \"sufficiently large,\" with a 5% significance level, is the 95th percentile in a _t<span>_ distribution with _n-k-1_ degrees of freedom; denote this by _c<span>_.\n",
    "- In other words, the **rejection rule** is that $H_0$ is rejected in favor of $H_1$ at the 5% significance level if\n",
    "\n",
    "\\begin{equation*}\n",
    "H_1: \\beta_j>c\n",
    "\\end{equation*}\n",
    "\n",
    "- By our choice of the **critical value**, _c<span>_, rejection of $H_0$ will occur for 5% of all random samples when H0 is true.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "**Hypothesis Testing**\n",
    "\n",
    "- The rejection rule here is an example of a **one-tailed test**.\n",
    "- To obtain _c_, we only need the significance level and the degrees of freedom.\n",
    "- For example, for a 5% level test and with _n-k-1_=28 degrees of freedom, the critical value is _c=1.701_.\n",
    "- If $t_\\hat{{\\beta}_j}\\leq1.701$, then we fail to reject $H_0$ in favor of $H_1$ at the 5% level.\n",
    "- The same procedure can be used with other significance levels.\n",
    "-  You should note a pattern in the critical values: as the significance level falls, the critical value increases, so that we require a larger and larger value $t_\\hat{{\\beta}_j}$ in order to reject $H_0$.\n",
    "- Thus, if $H_0$ is rejected at, say, the 5% level, then it is automatically rejected at the 10% level as well.\n",
    "- As the degrees of freedom in the $t$ distribution get large, the $t$ distribution approaches the standard normal distribution. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "**5% rejection rule for the alternative $H_1: \\beta_j>0$ with 28 df.**\n",
    "\n",
    "<br>  \n",
    "\n",
    "\n",
    "<center><img src=\"figs/wool_4_2.png\" width=\"500\"/> \n",
    "    \n",
    "\n",
    "<p>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "**Hypothesis Testing**\n",
    "\n",
    "- In applications, it is common to test the null hypothesis $H_0: \\beta_j=0$ against a **two-sided alternative**; that is,\n",
    "\n",
    "\\begin{equation*}\n",
    "H_1: \\beta_j\\neq 0\n",
    "\\end{equation*}\n",
    "\n",
    "\n",
    "- Under this alternative, $x_j$ has a ceteris paribus effect on $y$ without specifying whether the effect is positive or negative.\n",
    "- This is the relevant alternative when the sign of $\\beta_j$ is not well determined by theory (or common sense).\n",
    "- When the alternative is two-sided, we are interested in the _absolute value_ of the _t_ statistic.\n",
    "- The rejection rule for $H_0: \\beta_j=0$ here  is\n",
    "$|t_\\hat{{\\beta}_j}|\\geq c$\n",
    "-  To find $c$, we again specify a significance level, say 5%.\n",
    "- For a two-tailed test, $c$ is chosen to make the area in each tail of the t distribution an equal 2.5%.\n",
    "- In other words, $c$ is the 97.5th percentile in the $t$ distribution with _n-k-1_ degrees of freedom. \n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "**Hypothesis Testing**\n",
    "\n",
    "- When a specific alternative is not stated, it is usually considered to be two-sided.\n",
    "- If $H_0$ is rejected in favor of $H_1$ at the 5% level, we usually say that $x_j$ is **statistically significant**, or **statistically different from zero**, at the 5% level.\n",
    "- If $H_0$ is not rejected, we say that $x_j$ is **statistically insignificant** at the 5% level."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "**5% rejection rule for the alternative $H_1: \\beta_j\\neq0$ with 25 df.**\n",
    "\n",
    "<br>  \n",
    "\n",
    "\n",
    "<center><img src=\"figs/wool_4_3.png\" width=\"500\"/> \n",
    "    \n",
    "\n",
    "<p>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "**Example: Wage and Education**\n",
    "\n",
    "<blockquote> We use again the _wage_ data and estimate\n",
    "    \n",
    "\\begin{equation*}\n",
    "wage=\\beta_0+\\beta_1educ+\\beta_2exper+\\beta_3tenure+u\n",
    "\\end{equation*}\n",
    "\n",
    "For the critical values of the t tests, using the normal approximation instead of the exact t distribution\n",
    "with _n — k — 1 = 522_ d.f. doesn’t make much of a difference:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>wage</th>\n",
       "      <th>educ</th>\n",
       "      <th>exper</th>\n",
       "      <th>tenure</th>\n",
       "      <th>nonwhite</th>\n",
       "      <th>female</th>\n",
       "      <th>married</th>\n",
       "      <th>numdep</th>\n",
       "      <th>smsa</th>\n",
       "      <th>northcen</th>\n",
       "      <th>south</th>\n",
       "      <th>west</th>\n",
       "      <th>construc</th>\n",
       "      <th>ndurman</th>\n",
       "      <th>trcommpu</th>\n",
       "      <th>trade</th>\n",
       "      <th>services</th>\n",
       "      <th>profserv</th>\n",
       "      <th>profocc</th>\n",
       "      <th>clerocc</th>\n",
       "      <th>servocc</th>\n",
       "      <th>lwage</th>\n",
       "      <th>expersq</th>\n",
       "      <th>tenursq</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>526.000000</td>\n",
       "      <td>526.000000</td>\n",
       "      <td>526.00000</td>\n",
       "      <td>526.000000</td>\n",
       "      <td>526.000000</td>\n",
       "      <td>526.000000</td>\n",
       "      <td>526.000000</td>\n",
       "      <td>526.000000</td>\n",
       "      <td>526.000000</td>\n",
       "      <td>526.000000</td>\n",
       "      <td>526.000000</td>\n",
       "      <td>526.000000</td>\n",
       "      <td>526.000000</td>\n",
       "      <td>526.000000</td>\n",
       "      <td>526.000000</td>\n",
       "      <td>526.000000</td>\n",
       "      <td>526.000000</td>\n",
       "      <td>526.000000</td>\n",
       "      <td>526.000000</td>\n",
       "      <td>526.000000</td>\n",
       "      <td>526.000000</td>\n",
       "      <td>526.000000</td>\n",
       "      <td>526.000000</td>\n",
       "      <td>526.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>5.896103</td>\n",
       "      <td>12.562738</td>\n",
       "      <td>17.01711</td>\n",
       "      <td>5.104563</td>\n",
       "      <td>0.102662</td>\n",
       "      <td>0.479087</td>\n",
       "      <td>0.608365</td>\n",
       "      <td>1.043726</td>\n",
       "      <td>0.722433</td>\n",
       "      <td>0.250951</td>\n",
       "      <td>0.355513</td>\n",
       "      <td>0.169202</td>\n",
       "      <td>0.045627</td>\n",
       "      <td>0.114068</td>\n",
       "      <td>0.043726</td>\n",
       "      <td>0.287072</td>\n",
       "      <td>0.100760</td>\n",
       "      <td>0.258555</td>\n",
       "      <td>0.366920</td>\n",
       "      <td>0.167300</td>\n",
       "      <td>0.140684</td>\n",
       "      <td>1.623268</td>\n",
       "      <td>473.435361</td>\n",
       "      <td>78.150190</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>3.693086</td>\n",
       "      <td>2.769022</td>\n",
       "      <td>13.57216</td>\n",
       "      <td>7.224462</td>\n",
       "      <td>0.303805</td>\n",
       "      <td>0.500038</td>\n",
       "      <td>0.488580</td>\n",
       "      <td>1.261891</td>\n",
       "      <td>0.448225</td>\n",
       "      <td>0.433973</td>\n",
       "      <td>0.479124</td>\n",
       "      <td>0.375287</td>\n",
       "      <td>0.208874</td>\n",
       "      <td>0.318197</td>\n",
       "      <td>0.204680</td>\n",
       "      <td>0.452826</td>\n",
       "      <td>0.301298</td>\n",
       "      <td>0.438257</td>\n",
       "      <td>0.482423</td>\n",
       "      <td>0.373599</td>\n",
       "      <td>0.348027</td>\n",
       "      <td>0.531538</td>\n",
       "      <td>616.044772</td>\n",
       "      <td>199.434664</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>0.530000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.00000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-0.634878</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>3.330000</td>\n",
       "      <td>12.000000</td>\n",
       "      <td>5.00000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.202972</td>\n",
       "      <td>25.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>4.650000</td>\n",
       "      <td>12.000000</td>\n",
       "      <td>13.50000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.536867</td>\n",
       "      <td>182.500000</td>\n",
       "      <td>4.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>6.880000</td>\n",
       "      <td>14.000000</td>\n",
       "      <td>26.00000</td>\n",
       "      <td>7.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.750000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.928619</td>\n",
       "      <td>676.000000</td>\n",
       "      <td>49.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>24.980000</td>\n",
       "      <td>18.000000</td>\n",
       "      <td>51.00000</td>\n",
       "      <td>44.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>6.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>3.218076</td>\n",
       "      <td>2601.000000</td>\n",
       "      <td>1936.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             wage        educ      exper      tenure    nonwhite      female  \\\n",
       "count  526.000000  526.000000  526.00000  526.000000  526.000000  526.000000   \n",
       "mean     5.896103   12.562738   17.01711    5.104563    0.102662    0.479087   \n",
       "std      3.693086    2.769022   13.57216    7.224462    0.303805    0.500038   \n",
       "min      0.530000    0.000000    1.00000    0.000000    0.000000    0.000000   \n",
       "25%      3.330000   12.000000    5.00000    0.000000    0.000000    0.000000   \n",
       "50%      4.650000   12.000000   13.50000    2.000000    0.000000    0.000000   \n",
       "75%      6.880000   14.000000   26.00000    7.000000    0.000000    1.000000   \n",
       "max     24.980000   18.000000   51.00000   44.000000    1.000000    1.000000   \n",
       "\n",
       "          married      numdep        smsa    northcen       south        west  \\\n",
       "count  526.000000  526.000000  526.000000  526.000000  526.000000  526.000000   \n",
       "mean     0.608365    1.043726    0.722433    0.250951    0.355513    0.169202   \n",
       "std      0.488580    1.261891    0.448225    0.433973    0.479124    0.375287   \n",
       "min      0.000000    0.000000    0.000000    0.000000    0.000000    0.000000   \n",
       "25%      0.000000    0.000000    0.000000    0.000000    0.000000    0.000000   \n",
       "50%      1.000000    1.000000    1.000000    0.000000    0.000000    0.000000   \n",
       "75%      1.000000    2.000000    1.000000    0.750000    1.000000    0.000000   \n",
       "max      1.000000    6.000000    1.000000    1.000000    1.000000    1.000000   \n",
       "\n",
       "         construc     ndurman    trcommpu       trade    services    profserv  \\\n",
       "count  526.000000  526.000000  526.000000  526.000000  526.000000  526.000000   \n",
       "mean     0.045627    0.114068    0.043726    0.287072    0.100760    0.258555   \n",
       "std      0.208874    0.318197    0.204680    0.452826    0.301298    0.438257   \n",
       "min      0.000000    0.000000    0.000000    0.000000    0.000000    0.000000   \n",
       "25%      0.000000    0.000000    0.000000    0.000000    0.000000    0.000000   \n",
       "50%      0.000000    0.000000    0.000000    0.000000    0.000000    0.000000   \n",
       "75%      0.000000    0.000000    0.000000    1.000000    0.000000    1.000000   \n",
       "max      1.000000    1.000000    1.000000    1.000000    1.000000    1.000000   \n",
       "\n",
       "          profocc     clerocc     servocc       lwage      expersq  \\\n",
       "count  526.000000  526.000000  526.000000  526.000000   526.000000   \n",
       "mean     0.366920    0.167300    0.140684    1.623268   473.435361   \n",
       "std      0.482423    0.373599    0.348027    0.531538   616.044772   \n",
       "min      0.000000    0.000000    0.000000   -0.634878     1.000000   \n",
       "25%      0.000000    0.000000    0.000000    1.202972    25.000000   \n",
       "50%      0.000000    0.000000    0.000000    1.536867   182.500000   \n",
       "75%      1.000000    0.000000    0.000000    1.928619   676.000000   \n",
       "max      1.000000    1.000000    1.000000    3.218076  2601.000000   \n",
       "\n",
       "           tenursq  \n",
       "count   526.000000  \n",
       "mean     78.150190  \n",
       "std     199.434664  \n",
       "min       0.000000  \n",
       "25%       0.000000  \n",
       "50%       4.000000  \n",
       "75%      49.000000  \n",
       "max    1936.000000  "
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import wooldridge as woo\n",
    "import statsmodels.formula.api as smf\n",
    "import scipy.stats as stats\n",
    "\n",
    "wage1 = woo.dataWoo('wage1')\n",
    "wage1.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cv_t: [1.64777794 2.33351273]\n",
      "\n",
      "cv_n: [1.64485363 2.32634787]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import scipy.stats as stats\n",
    "import numpy as np\n",
    "\n",
    "# CV for alpha=5% and 1% using the t distribution with 522 d.f.:\n",
    "alpha = np.array([0.05, 0.01])\n",
    "cv_t = stats.t.ppf(1 - alpha, 522)\n",
    "print(f'cv_t: {cv_t}\\n')\n",
    "\n",
    "# CV for alpha=5% and 1% using the normal approximation:\n",
    "cv_n = stats.norm.ppf(1 - alpha)\n",
    "print(f'cv_n: {cv_n}\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "- The below script presents the standard `summary` which directly contains all the information to test the hypotheses  $H_0:\\beta_j=0, H_1:\\beta_j\\neq 0$ for all parameters.\n",
    "- The _t<span>_ statistics for all coefficients are larger in absolute value than the critical value _c<span>_ = 2.33 for a = 1%.\n",
    "- So we would reject $H_0$ for all usual significance levels.\n",
    "- By construction, we draw the same conclusions from the _p<span>_ values values.\n",
    "In order to confirm that statsmodels is exactly using the formulas introduced above, we next reconstruct\n",
    "the _t<span>_ and _p<span>_ values manually.\n",
    "- We extract the coefficients (`params`) and standard errors (`bse`) from\n",
    "the regression results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "results.summary(): \n",
      "                            OLS Regression Results                            \n",
      "==============================================================================\n",
      "Dep. Variable:           np.log(wage)   R-squared:                       0.316\n",
      "Model:                            OLS   Adj. R-squared:                  0.312\n",
      "Method:                 Least Squares   F-statistic:                     80.39\n",
      "Date:                Mon, 14 Sep 2020   Prob (F-statistic):           9.13e-43\n",
      "Time:                        16:49:06   Log-Likelihood:                -313.55\n",
      "No. Observations:                 526   AIC:                             635.1\n",
      "Df Residuals:                     522   BIC:                             652.2\n",
      "Df Model:                           3                                         \n",
      "Covariance Type:            nonrobust                                         \n",
      "==============================================================================\n",
      "                 coef    std err          t      P>|t|      [0.025      0.975]\n",
      "------------------------------------------------------------------------------\n",
      "Intercept      0.2844      0.104      2.729      0.007       0.080       0.489\n",
      "educ           0.0920      0.007     12.555      0.000       0.078       0.106\n",
      "exper          0.0041      0.002      2.391      0.017       0.001       0.008\n",
      "tenure         0.0221      0.003      7.133      0.000       0.016       0.028\n",
      "==============================================================================\n",
      "Omnibus:                       11.534   Durbin-Watson:                   1.769\n",
      "Prob(Omnibus):                  0.003   Jarque-Bera (JB):               20.941\n",
      "Skew:                           0.021   Prob(JB):                     2.84e-05\n",
      "Kurtosis:                       3.977   Cond. No.                         135.\n",
      "==============================================================================\n",
      "\n",
      "Warnings:\n",
      "[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.\n",
      "\n",
      "tstat:\n",
      "Intercept     2.729230\n",
      "educ         12.555246\n",
      "exper         2.391437\n",
      "tenure        7.133070\n",
      "dtype: float64\n",
      "\n",
      "pval:\n",
      "[6.56246239e-03 8.82420368e-32 1.71356231e-02 3.29440824e-12]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#import wooldridge as woo\n",
    "#import statsmodels.formula.api as smf\n",
    "#import scipy.stats as stats\n",
    "\n",
    "wage1 = woo.dataWoo('wage1')\n",
    "\n",
    "\n",
    "#store and display results\n",
    "reg = smf.ols(formula='np.log(wage) ~ educ + exper + tenure', data=wage1)\n",
    "results = reg.fit()\n",
    "print(f'results.summary(): \\n{results.summary()}\\n')\n",
    "\n",
    "#manually confirm the formulas, i.e. extract coefficients and SE\n",
    "b=results.params\n",
    "se=results.bse\n",
    "\n",
    "#reproduce t statistics\n",
    "tstat=b/se\n",
    "print(f'tstat:\\n{tstat}\\n')\n",
    "\n",
    "#reproduce p-value\n",
    "pval=2 * stats.t.cdf(-abs(tstat),522)\n",
    "print(f'pval:\\n{pval}\\n')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "**Computing p-Values for t Tests**\n",
    "\n",
    "- So far, we have talked about how to test hypotheses using a classical approach: after stating the alternative hypothesis, we choose a significance level, which then determines a critical value.\n",
    "- Once the critical value has been identified, the value of the $t$ statistic is compared with the critical value, and the null is either rejected or not rejected at the given significance level.\n",
    "- Even after deciding on the appropriate alternative, there is a component of arbitrariness to the classical approach, which results from having to choose a significance level ahead of time.\n",
    "- Different researchers prefer different significance levels, depending on the particular application.\n",
    "- There is no \"correct\" significance level.\n",
    "- Committing to a significance level ahead of time can hide useful information about the outcome of a hypothesis test.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "**Computing p-Values for t Tests**\n",
    "\n",
    "\n",
    "- For example, suppose that we wish to test the null hypothesis that a parameter is zero against a two-sided alternative, and with 40 degrees of freedom we obtain a t statistic equal to 1.85.\n",
    "- The null hypothesis is not rejected at the 5% level, because the t statistic is less than the two-tailed critical value of c=2.021.\n",
    "- A researcher whose agenda is not to reject the null could simply report this outcome along with the estimate: the null hypothesis is not rejected at the 5% level.\n",
    "- Of course, if the t statistic, or the coefficient and its standard error, are reported, then we can also determine that the null hypothesis would be rejected at the 10% level, because the 10% critical value is c=1.684.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "**Computing p-Values for t Tests**\n",
    "\n",
    "\n",
    "\n",
    "- Rather than testing at different significance levels, it is more informative to answer the following question: given the observed value of the t statistic, what is the smallest significance level at which the null hypothesis would be rejected?\n",
    "- This level is known as the p-value for the test.\n",
    "- In the previous example, we know the p-value is greater than .05, because the null is not rejected at the 5% level, and we know that the p-value is less than .10, because the null is rejected at the 10% level.\n",
    "- We obtain the actual p-value by computing the probability that a t random variable, with 40 df, is larger than 1.85 in absolute value.\n",
    "- That is, the p-value is the significance level of the test when we use the value of the test statistic, 1.85 in the above example, as the critical value for the test."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "**Obtaining the p-value against a two-sided alternative, when t=1.85 and df=40**\n",
    "\n",
    "<br>  \n",
    "\n",
    "\n",
    "<center><img src=\"figs/wool_4_6.png\" width=\"500\"/> \n",
    "    \n",
    "\n",
    "<p>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "**Computing p-Values for t Tests**\n",
    "\n",
    "- Because a p-value is a probability, its value is always between zero and one.\n",
    "- In order to compute p-values, we either need extremely detailed printed tables of the t distribution — which is not very practical —or a computer program that computes areas under the probability density function of the t distribution.\n",
    "- Most modern regression packages have this capability. Some packages compute p-values routinely with each OLS regression, but only for certain hypotheses.\n",
    "- If a regression package reports a p-value along with the standard OLS output, it is almost certainly the p-value for testing the null hypothesis $H_0: \\beta_j=0$ against the two-sided alternative.\n",
    "- The p-value in this case is\n",
    "\n",
    "\n",
    "\\begin{equation*}\n",
    "P(|T|>|t|),\n",
    "\\end{equation*}\n",
    "\n",
    "where we let T denote a t distributed random variable with $n-k-1$ degrees of freedom and let t denote the numerical value of the test statistic."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "**Confidence Interval**\n",
    "\n",
    "- We can now also easily construct a **confidence interval (CI)** for the population parameter $\\beta_j$.\n",
    "- Confidence intervals are also called _interval estimates_ because they provide a range of likely values for the population parameter, and not just a point estimate.\n",
    "- using the fact that $(\\hat{\\beta}_j-\\hat{\\beta}_j/se(\\hat{\\beta}_j)$ has a t distribution with n-k-1 degrees of freedom, simple manipulation lead to a CI for the unknown $\\beta_j$: a 95% CI, given by \n",
    "\n",
    "\\begin{equation*}\n",
    "\\hat{\\beta}_j\\pm c\\cdot se(\\beta_j),\n",
    "\\end{equation*}\n",
    "\n",
    "where the constant c is the 97.5th percentile in a $t_{n-k-1}$ distribution. More precisely, the lower and upper bounds of the confidence interval are given by\n",
    "\n",
    "\\begin{equation*}\n",
    "\\beta_j^{lower}\\equiv \\hat{\\beta}_j- c\\cdot se(\\hat{\\beta}_j),\n",
    "\\end{equation*}\n",
    "\n",
    "and\n",
    "\n",
    "\\begin{equation*}\n",
    "\\beta_j^{upper}\\equiv \\hat{\\beta}_j + c\\cdot se(\\hat{\\beta}_j)\n",
    "\\end{equation*}\n",
    "\n",
    "- Thus: If random samples were obtained over and over again, with $\\beta_j^{lower}$ and $\\beta_j^{upper}$ computed each time, then the (unknown) population value $\\beta_j$ would lie in the interval $(\\beta_j^{lower}, \\beta_j^{upper})$ for 95% of the samples."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "<h3>More on Functional Forms</h3>\n",
    "\n",
    "- In several previous examples, we have encountered the most popular device in econometrics for allowing nonlinear relationships between the explained and explanatory variables: using logarithms for the dependent or independent variables.\n",
    "- We have also seen models containing quadratics in some explanatory variables, but we have yet to provide a systematic treatment of them.\n",
    "- We will now cover some variations and extensions on functional forms that often arise in applied work.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "**More on Using Logarithmic Functional Forms**\n",
    "\n",
    "- We begin by reviewing how to interpret the parameters in the model\n",
    "- Let's use the example of average housing prices in 506 communities in Boston and various charactarestics\n",
    "\n",
    "\\begin{equation*}\n",
    "log(price)=\\beta_0+\\beta_1log(nox)+\\beta_2rooms+u\n",
    "\\end{equation*}\n",
    "\n",
    "where $nox$ is the amount of nitrogen oxide in the air and $rooms$ is the averge number of rooms in the community.\n",
    "\n",
    "- Let's run the above regression:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 181,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "results.summary(): \n",
      "                            OLS Regression Results                            \n",
      "==============================================================================\n",
      "Dep. Variable:          np.log(price)   R-squared:                       0.514\n",
      "Model:                            OLS   Adj. R-squared:                  0.512\n",
      "Method:                 Least Squares   F-statistic:                     265.7\n",
      "Date:                Wed, 16 Sep 2020   Prob (F-statistic):           1.79e-79\n",
      "Time:                        10:03:28   Log-Likelihood:                -83.009\n",
      "No. Observations:                 506   AIC:                             172.0\n",
      "Df Residuals:                     503   BIC:                             184.7\n",
      "Df Model:                           2                                         \n",
      "Covariance Type:            nonrobust                                         \n",
      "===============================================================================\n",
      "                  coef    std err          t      P>|t|      [0.025      0.975]\n",
      "-------------------------------------------------------------------------------\n",
      "Intercept       9.2337      0.188     49.184      0.000       8.865       9.603\n",
      "np.log(nox)    -0.7177      0.066    -10.818      0.000      -0.848      -0.587\n",
      "rooms           0.3059      0.019     16.086      0.000       0.269       0.343\n",
      "==============================================================================\n",
      "Omnibus:                       52.327   Durbin-Watson:                   0.603\n",
      "Prob(Omnibus):                  0.000   Jarque-Bera (JB):              327.013\n",
      "Skew:                           0.042   Prob(JB):                     9.77e-72\n",
      "Kurtosis:                       6.937   Cond. No.                         102.\n",
      "==============================================================================\n",
      "\n",
      "Warnings:\n",
      "[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.\n",
      "\n",
      "table: \n",
      "                  b      se        t  pval\n",
      "Intercept    9.2337  0.1877  49.1835   0.0\n",
      "np.log(nox) -0.7177  0.0663 -10.8182   0.0\n",
      "rooms        0.3059  0.0190  16.0863   0.0\n",
      "\n"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "How do we have to interpret the coefficients?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "- Remember: \n",
    "  - The coefficient $\\beta_1$ is the elasticity of $price$ with respect to $nox$ (pollution).\n",
    "  - The coefficient $\\beta_2$ is the change in $log(price)$, when $\\Delta rooms=1$; as we have seen many times, when multiplied by 100, this is the approximate percentage change in price.\n",
    "  - Recall that 100$\\cdot \\beta_1$ is sometimes called the semi-elasticity of $price$ with respect to $rooms$."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "- Thus, when $nox$ increases by 1%, price falls by .718%, holding only rooms fixed.\n",
    "- When rooms increases by one, price increases by approximately 100*(0.306)=30.6%.\n",
    "- The estimate that one more room increases price by about 30.6% turns out to be somewhat inaccurate for this application.\n",
    "- The approximation error occurs because, as the change in $log(y)$ becomes larger and larger, the approximation $\\%\\Delta y \\approx 100\\cdot\\Delta log(y)$ becomes more and more inaccurate.\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "- Fortunately, a simple calculation is available to compute the exact percentage change:\n",
    "    \n",
    "\\begin{equation*}\n",
    "\\hat{log(y)}=\\hat{\\beta}_0log(x_1)+\\hat{\\beta}_2x_2\n",
    "\\end{equation*}\n",
    "\n",
    "- Using simple algebraic properties of the exponential and logarithmic functions gives the exact percentage change in the predicted $y$ as\n",
    "\n",
    "\\begin{equation*}\n",
    "\\%\\Delta\\hat{y}=100\\cdot[exp(\\hat{\\beta}_2\\Delta x_2)-1]\n",
    "\\end{equation*}\n",
    "\n",
    "where the multiplication by 100 turns the proportionate change into a percentage change. When $\\Delta x_2=1$,\n",
    "\n",
    "\\begin{equation*}\n",
    "\\%\\Delta\\hat{y}=100\\cdot[exp(\\hat{\\beta}_2)-1]\n",
    "\\end{equation*}\n",
    "\n",
    "which in our case of $\\hat\\beta_2=0.306$ yields $\\%\\Delta\\hat{price}=35.8\\%$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "Ok, so we now know that a $\\beta_2$ of 0.306 means, that if if $x_2$ increases by one room, $\\hat{y}$ increases by 36\\%.\n",
    "\n",
    "But: what happens if $x_2$ decreases by one unit?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "- For a decrease of room by one the effect is different with -26.4%!\n",
    "\n",
    "- Thus: the estimated parameter is also useful as it is in between the effect of an increase and a decrease!\n",
    "\n",
    "- The point just made about computing percentage changes is essentially the one made in introductory economics when it comes to computing price elasticities of demand based on large price changes: \n",
    "    - the result depends on whether we use the beginning or ending price and quantity in computing the percentage changes.\n",
    "\n",
    "- Another potential benefit of using logs is that taking the log of a variable often narrows its range. \n",
    "- This is particularly true of variables that can be large monetary values, such as firms’ annual sales or baseball players' salaries.\n",
    "- Population variables also tend to vary widely.\n",
    "- Narrowing the range of the dependent and independent variables can make OLS estimates less sensitive to outlying (or extreme) values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Text(0.5, 0, 'roe')"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 576x396 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#comparing level-level and log-level estimates before and after dropping some outliers\n",
    "\n",
    "import statsmodels.formula.api as smf\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "ceosal1 = woo.dataWoo('ceosal1')\n",
    "\n",
    "# OLS regression:\n",
    "reg = smf.ols(formula='salary ~ roe', data=ceosal1)\n",
    "results = reg.fit()\n",
    "\n",
    "# scatter plot and fitted values:\n",
    "plt.plot('roe', 'salary', data=ceosal1, color='grey', marker='o', linestyle='')\n",
    "plt.plot(ceosal1['roe'], results.fittedvalues, color='black', linestyle='-')\n",
    "plt.ylabel('salary')\n",
    "plt.xlabel('roe')\n",
    "\n",
    "# we see that salary has a few outliers. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=====================================================================================================\n",
      "          salary outlier salary without outlier  log(salary) with outlier log(salary) without outlier\n",
      "               (0)                 (1)                     (2)                        (3)            \n",
      "-----------------------------------------------------------------------------------------------------\n",
      "Intercept 963.191***     878.161***              6.712***                 6.685***                   \n",
      "          (213.240)      (93.715)                (0.087)                  (0.076)                    \n",
      "roe       18.501*        15.303***               0.014***                 0.014***                   \n",
      "          (11.123)       (4.885)                 (0.005)                  (0.004)                    \n",
      "N         209            206                     209                      206                        \n",
      "R2        0.01           0.05                    0.04                     0.05                       \n",
      "=====================================================================================================\n",
      "Standard errors in parentheses.\n",
      "* p<.1, ** p<.05, ***p<.01\n"
     ]
    }
   ],
   "source": [
    "import wooldridge as woo\n",
    "import statsmodels.formula.api as smf\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "df1 = woo.dataWoo('ceosal1')\n",
    "\n",
    "#generate dataframe without outliers for salary\n",
    "df2 = df1[df1.salary<6000]\n",
    "\n",
    "formula = \"salary ~ roe\"\n",
    "reg1 = smf.ols(formula, data=df1).fit()\n",
    "formula = \"salary ~ roe\"\n",
    "reg2 = smf.ols(formula, data=df2).fit()\n",
    "\n",
    "formula = \"np.log(salary) ~ roe\"\n",
    "reg3 = smf.ols(formula, data=df1).fit()\n",
    "formula = \"np.log(salary) ~ roe\"\n",
    "reg4 = smf.ols(formula, data=df2).fit()\n",
    "\n",
    "dfoutput = summary_col([reg1,reg2,reg3,reg4],stars=True,float_format='%0.3f',\n",
    "                  model_names=['salary outlier\\n(0)','salary without outlier \\n(1)','log(salary) with outlier\\n(2)','log(salary) without outlier\\n(3)'],\n",
    "                  info_dict={'N':lambda x: \"{0:d}\".format(int(x.nobs)),\n",
    "                             'R2':lambda x: \"{:.2f}\".format(x.rsquared)})\n",
    "print(dfoutput)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "**More on Using Logarithmic Functional Forms**\n",
    "\n",
    "- One limitation of the log is that it cannot be used if a variable takes on zero or negative values.\n",
    "- In cases where a variable $y$ is nonnegative but can take on the value 0, $log(y+1)$ is sometimes used.\n",
    "- The percentage change interpretations are often closely preserved, except for changes beginning at $y=0$ (where the percentage change is not even defined).\n",
    "- Generally, using $log(y+1)$ and then interpreting the estimates as if the variable were $log(y)$ is acceptable when the data on $y$ contain relatively few zeros.\n",
    "- Also, in some cases taking logs can actually create extreme values:\n",
    "    - An example is when a variable $y$ is between zero and one (such as a proportion) and takes on values close to zero.\n",
    "    - In this case, $log(y)$ (which is necessarily negative) can be very large in magnitude whereas the original variable, $y$, is bounded between zero and one.\n",
    "- Also: You should not compare the $R^2$ of level and log estimations because you would compare variation in different variables!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "**Models with Quadratics**\n",
    "\n",
    "Also used quite often in applied economics:\n",
    "- quadratic function\n",
    "- allows to capture decreasing or increasing marginal effects.\n",
    "    \n",
    "    \n",
    "Simple case: $y$ depends on a single observed factor $x$, but it does so in a quadratic fashion:\n",
    "\n",
    "\\begin{equation*}\n",
    "y=\\beta_0+\\beta_1x+\\beta_2x^2+u\n",
    "\\end{equation*}\n",
    "\n",
    "\n",
    "- For example, take $y=wage$ and $x=exper$. \n",
    "- If we write the estimated equation as\n",
    "\n",
    "\\begin{equation*}\n",
    "\\hat{y} =\\hat{\\beta}_0+\\hat{\\beta}_1x + \\hat{\\beta}_2x^2\n",
    "\\end{equation*}\n",
    "\n",
    "then we have the approximation\n",
    "\n",
    "\\begin{equation*}\n",
    "\\Delta\\hat{y} \\approx (\\hat{\\beta}_1+2\\hat{\\beta}_2x)\\Delta x\n",
    "\\end{equation*}\n",
    "\n",
    "so\n",
    "\n",
    "\\begin{equation*}\n",
    "\\Delta \\hat{y}/\\Delta x \\approx\\hat{\\beta}_1+2\\hat{\\beta}_2x\n",
    "\\end{equation*}\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "**Models with Quadratics**\n",
    "\n",
    "This says:\n",
    "\n",
    "- the slope of the relationship between $x$ and $y$ depends on the value of $x$;\n",
    "\n",
    "The estimated slope is $\\hat{\\beta}_1+2\\hat{\\beta}_2x$\n",
    "- If we plug in $x=0$, we see that $\\hat{\\beta}_1$ can be interpreted as the approximate slope in going from $x=0$ to $x=1$\n",
    "- After that, the second term $2\\hat{\\beta}_2x$ must be accounted for.\n",
    "- If we are only interested in computing the predicted change in $y$ given a starting value for $x$ and a change in $x$, we could use $\\hat{y} =\\hat{\\beta}_0+\\hat{\\beta}_1x + \\hat{\\beta}_2x^2$ directly: there is no reason to use the calculus approximation at all.\n",
    "- However, we are usually more interested in quickly summarizing the effect of $x$ on $y$, and the interpretation of $\\hat{\\beta}_1$ and $\\hat{\\beta}_2$ in $\\Delta \\hat{y}/\\Delta x \\approx\\hat{\\beta}_1+2\\hat{\\beta}_2x$ provides that summary.\n",
    "- Typically, we might plug in the average value of $x$ in the sample, or some other interesting values, such as the median or the lower and upper quartile values.\n",
    "- In many applications, $\\hat{\\beta}_1$ is positive and $\\hat{\\beta}_2$ is negative.\n",
    "- Let's check the $wage$ example for this."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "- In _Python_ you can either generate the quadratic variable separately, e.g. `x_sq=x ** 2`\n",
    "- Or just use `I(x ** 2)` directly in the formula.\n",
    "- The `I(...)` brackets describe any parts of the formula in which we describe arithmetic transformations\n",
    "- The latter version is useful to get a graphical illustration of the effect."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>wage</th>\n",
       "      <th>educ</th>\n",
       "      <th>exper</th>\n",
       "      <th>tenure</th>\n",
       "      <th>nonwhite</th>\n",
       "      <th>female</th>\n",
       "      <th>married</th>\n",
       "      <th>numdep</th>\n",
       "      <th>smsa</th>\n",
       "      <th>northcen</th>\n",
       "      <th>...</th>\n",
       "      <th>trade</th>\n",
       "      <th>services</th>\n",
       "      <th>profserv</th>\n",
       "      <th>profocc</th>\n",
       "      <th>clerocc</th>\n",
       "      <th>servocc</th>\n",
       "      <th>lwage</th>\n",
       "      <th>expersq</th>\n",
       "      <th>tenursq</th>\n",
       "      <th>exper_sq</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>3.10</td>\n",
       "      <td>11</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1.131402</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>3.24</td>\n",
       "      <td>12</td>\n",
       "      <td>22</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1.175573</td>\n",
       "      <td>484</td>\n",
       "      <td>4</td>\n",
       "      <td>484</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3.00</td>\n",
       "      <td>11</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1.098612</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>6.00</td>\n",
       "      <td>8</td>\n",
       "      <td>44</td>\n",
       "      <td>28</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1.791759</td>\n",
       "      <td>1936</td>\n",
       "      <td>784</td>\n",
       "      <td>1936</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5.30</td>\n",
       "      <td>12</td>\n",
       "      <td>7</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1.667707</td>\n",
       "      <td>49</td>\n",
       "      <td>4</td>\n",
       "      <td>49</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 25 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   wage  educ  exper  tenure  nonwhite  female  married  numdep  smsa  \\\n",
       "0  3.10    11      2       0         0       1        0       2     1   \n",
       "1  3.24    12     22       2         0       1        1       3     1   \n",
       "2  3.00    11      2       0         0       0        0       2     0   \n",
       "3  6.00     8     44      28         0       0        1       0     1   \n",
       "4  5.30    12      7       2         0       0        1       1     0   \n",
       "\n",
       "   northcen    ...     trade  services  profserv  profocc  clerocc  servocc  \\\n",
       "0         0    ...         0         0         0        0        0        0   \n",
       "1         0    ...         0         1         0        0        0        1   \n",
       "2         0    ...         1         0         0        0        0        0   \n",
       "3         0    ...         0         0         0        0        1        0   \n",
       "4         0    ...         0         0         0        0        0        0   \n",
       "\n",
       "      lwage  expersq  tenursq  exper_sq  \n",
       "0  1.131402        4        0         4  \n",
       "1  1.175573      484        4       484  \n",
       "2  1.098612        4        0         4  \n",
       "3  1.791759     1936      784      1936  \n",
       "4  1.667707       49        4        49  \n",
       "\n",
       "[5 rows x 25 columns]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import wooldridge as woo\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import statsmodels.formula.api as smf\n",
    "\n",
    "wage1 = woo.dataWoo('wage1')\n",
    "\n",
    "wage1['exper_sq']=wage1['exper'] ** 2\n",
    "\n",
    "wage1.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "results.summary(): \n",
      "                            OLS Regression Results                            \n",
      "==============================================================================\n",
      "Dep. Variable:                   wage   R-squared:                       0.093\n",
      "Model:                            OLS   Adj. R-squared:                  0.089\n",
      "Method:                 Least Squares   F-statistic:                     26.74\n",
      "Date:                Tue, 14 Sep 2021   Prob (F-statistic):           8.77e-12\n",
      "Time:                        22:07:38   Log-Likelihood:                -1407.5\n",
      "No. Observations:                 526   AIC:                             2821.\n",
      "Df Residuals:                     523   BIC:                             2834.\n",
      "Df Model:                           2                                         \n",
      "Covariance Type:            nonrobust                                         \n",
      "=================================================================================\n",
      "                    coef    std err          t      P>|t|      [0.025      0.975]\n",
      "---------------------------------------------------------------------------------\n",
      "Intercept         3.7254      0.346     10.769      0.000       3.046       4.405\n",
      "exper             0.2981      0.041      7.277      0.000       0.218       0.379\n",
      "I(exper ** 2)    -0.0061      0.001     -6.792      0.000      -0.008      -0.004\n",
      "==============================================================================\n",
      "Omnibus:                      203.746   Durbin-Watson:                   1.802\n",
      "Prob(Omnibus):                  0.000   Jarque-Bera (JB):              721.819\n",
      "Skew:                           1.806   Prob(JB):                    1.82e-157\n",
      "Kurtosis:                       7.460   Cond. No.                     1.76e+03\n",
      "==============================================================================\n",
      "\n",
      "Warnings:\n",
      "[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.\n",
      "[2] The condition number is large, 1.76e+03. This might indicate that there are\n",
      "strong multicollinearity or other numerical problems.\n",
      "\n",
      "coef:\n",
      "Intercept        3.725406\n",
      "exper            0.298100\n",
      "I(exper ** 2)   -0.006130\n",
      "dtype: float64\n",
      "\n",
      "se:\n",
      "Intercept        0.345939\n",
      "exper            0.040966\n",
      "I(exper ** 2)    0.000903\n",
      "dtype: float64\n",
      "\n",
      "tstat:\n",
      "Intercept        10.768961\n",
      "exper             7.276850\n",
      "I(exper ** 2)    -6.791991\n",
      "dtype: float64\n",
      "\n",
      "pval:\n",
      "[1.47404846e-24 1.26182496e-12 3.02079086e-11]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import wooldridge as woo\n",
    "import statsmodels.formula.api as smf\n",
    "import scipy.stats as stats\n",
    "\n",
    "wage1 = woo.dataWoo('wage1')\n",
    "\n",
    "\n",
    "#store and display results\n",
    "reg = smf.ols(formula='wage ~ exper + I(exper ** 2)', data=wage1)\n",
    "results = reg.fit()\n",
    "print(f'results.summary(): \\n{results.summary()}\\n')\n",
    "\n",
    "#manually confirm the formulas, i.e. extract coefficients and SE\n",
    "b=results.params\n",
    "se=results.bse\n",
    "\n",
    "print(f'coef:\\n{b}\\n')\n",
    "print(f'se:\\n{se}\\n')\n",
    "\n",
    "#reproduce t statistics\n",
    "tstat=b/se\n",
    "print(f'tstat:\\n{tstat}\\n')\n",
    "\n",
    "#reproduce p-value\n",
    "pval=2 * stats.t.cdf(-abs(tstat),522)\n",
    "print(f'pval:\\n{pval}\\n')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x1a3c5e65b00>]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYIAAAEKCAYAAAAfGVI8AAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADl0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uIDMuMC4yLCBodHRwOi8vbWF0cGxvdGxpYi5vcmcvOIA7rQAAIABJREFUeJzsvXl0HNd54Pu7XdV7N7qxEwS4ipsoUpRESNZmWbKkWNZ4TRzLyjL2JHme5DjP4xfnzGQmZ5bzZs55SSZxJjNzPBPN2GNnsWNb3mJHVizL2mVLohaImyhSXAGCWAj0vlb1fX8U0ASIKhAFdqOB7vs7p08DhUbVreqq+333W4WUEoVCoVC0Lp5GD0ChUCgUjUUJAoVCoWhxlCBQKBSKFkcJAoVCoWhxlCBQKBSKFkcJAoVCoWhxlCBQKBSKFkcJAoVCoWhxlCBQKBSKFkdv9ACWQldXl9y8eXOjh6FQKBRrildffXVSStl9pc+tCUGwefNmDhw40OhhKBQKxZpCCHFmKZ9TpiGFQqFocZQgUCgUihZHCQKFQqFocZQgUCgUihZHCQKFQqFoceoWNSSE2AD8FbAOqACPSCn/QgjxH4D/C5iY+ei/kVI+Vq9xKBSrndFEnqHhBFPZEh1hH/sG4vTFg40elqKFqOeKwAA+L6W8FrgV+IwQYvfM3/5cSnnDzEsJAUXLMprI88SRMfIlk66In3zJ5IkjY4wm8o0emqKFqNuKQEo5CozO/JwWQhwF+ut1PIViLTI0nCAa0IkGvADV96HhhFoVKFaMFfERCCE2AzcCL81s+l0hxJtCiC8LIdod/ufTQogDQogDExMTdh9RKNY8U9kSYf98fSzs15nKlho0IkUrUndBIISIAN8GPielTAH/A7gGuAFrxfBndv8npXxESjkopRzs7r5ihrRCsSbpCPvIFo1527JFg46wr0EjUrQidRUEQggvlhD4WynldwCklGNSSlNKWQH+F3BLPcegUKxm9g3ESRcM0oUyFSlJF8qkCwb7BuKNHpqihaibIBBCCOBLwFEp5RfmbO+b87GPAofqNQaFYrXTFw9y/+5egj6NyUyRoE/j/t29yj+gWFHqWXTuDuDXgYNCiDdmtv0b4GEhxA2ABE4D/7yOY1AoVj198aCa+BUNpZ5RQ88DwuZPKlxUoVAoVhEqs1ihUChaHCUIFAqFosVRgkChUChaHCUIFAqFosVRgkChUChaHCUIFAqFosVRgkChUChaHCUIFAqFosWpZ2axokVQjVUUirWNWhEorgrVWEWhWPsoQaC4KuY2VvEIQTTgJRrQGRpONHpoCoViiShBoLgqVGMVhWLtowSB4qpQjVUUirWPEgSKq0I1VlEo1j4qakhxVcw2VhkaTjCZKdIR9nHr1k4VNVRHVJSWotYoQaC4alRjlZVjNkorGtDpivjJFg2eODKmupoprgplGlIo1hAqSktRD9SKQKFg7ZhbprIluiL+edvCfp3JTLFBI1I0A0oQrALWyiTUrKwlc8tslFY04K1uU1FaiqtFmYYajMrMbTxrydyiorQU9UAJggazliahZmUtJcXNRmkFfRqTmSJBn7YqVy6KtYUyDTUYZfNtPGvN3KKitBS1Rq0IGozKzG08ytyiaHWUIGgwahJqPMrcomh1lGmowajM3NWBMrcoWhklCFYBahJSKBSNRJmGFAqFosVRgkChUChaHCUIFAqFosVRgkChUChaHCUIFAqFosWpmyAQQmwQQjwlhDgqhDgshPgXM9s7hBBPCCGOz7y312sMCoVCobgy9QwfNYDPSylfE0JEgVeFEE8AnwKelFL+kRDiD4A/AP5VHcehaEHqXdFVVYxVNBN1WxFIKUellK/N/JwGjgL9wIeBr8587KvAR+o1BkVrUu+KrqpirKLZWBEfgRBiM3Aj8BLQK6UcBUtYAD0rMQZF61Dviq6qYqyi2ai7IBBCRIBvA5+TUqZc/N+nhRAHhBAHJiYm6jdARdNR77LSa6lstUKxFOoqCIQQXiwh8LdSyu/MbB4TQvTN/L0PGLf7XynlI1LKQSnlYHd3dz2HqWgy6l3RVVWMVTQb9YwaEsCXgKNSyi/M+dPfA5+c+fmTwPfrNQZFa1Lviq6qYqyi2ajniuAO4NeB9woh3ph5PQj8EXC/EOI4cP/M7wpFzah3WWlVtlrRbNQtfFRK+TwgHP58b72Oq1BA/Su6qoqximZCZRYrFApFi6P6ESgUy0AllCmaCbUiUChcohLKFM2GEgQKhUtUQpmi2VCCQKFwiUooUzQbShAoFC5RCWWKZkM5ixVNST2dufsG4jxxZAywVgLZokG6YHDr1s5VN9ZmGI+i/qgVgaLpqLczt5YJZavN8bzaxqNYGdSKoIVpVs1vrjMXqL4PDSdqml1ci32txFjX8ngUK4NaEbQozaz5rSVn7mob62obj2JlUCuCNUgtNPlm1vxmnbmz5wSr15m72sa62sajWBnUimCNUStNvpk1v7VUHXS1jXW1jUexMihBsMaoVTJTM4dALubMHU3kefzQKF976QyPHxptuClstVUyXW3jUawMyjS0xpjKluiK+OdtC/t1JjNFV/tZLASyGZzIds7c2dVUNKDTFfGTLRo8cWSs4RPdaqtkutrGo6g/akWwxqiVJu+k+QFN60RWpSEUCnvUimCNUctkJjvN7/FDo03rRK7VakqhaDbUimCNUW8bbjM7kZvZL6JQXA1qRbAGqacNt5nDB2tdGkKhaBbUikAxj2YOH1QRMQqFPWpFoJjH7GQ5NJxgMlOkI+zj1q2dTTNZqogYhWIhShAoFqAmS4WitVCmIYVCoWhxlCBQKBSKFkcJAoVCoWhxlCBQKBSKFkcJAoVCoWhxlCBQKBSKFkcJAoVCoWhxlCBQKBSKFkcllCkUi9AMvRkUiiuhVgQKhQO1aguqUKx26iYIhBBfFkKMCyEOzdn2H4QQI0KIN2ZeD9br+ArF1aIa2ShahXqahr4C/Hfgry7b/udSyj+t43FXLWvFzLBWxllvWrWRjfr+W4+6rQiklM8CU/Xa/1pjrZgZ1so4V4JWbGSjvv/WpBE+gt8VQrw5Yzpqb8DxG8JaMTOslXGuBM3cm8EJ9f23JistCP4HcA1wAzAK/JnTB4UQnxZCHBBCHJiYmFip8dWN1dgCcjSR5/FDo3ztpTM8fmiU0UR+VY6zUbRiIxv1/bcmKxo+KqUcm/1ZCPG/gB8u8tlHgEcABgcHZf1HV19WWwvIWRNANKDTFfGTLRo8cWQMryZW1TgbTav1Zlht96liZVjRFYEQom/Orx8FDjl9ttmopZnBTpN3i5MJAGTLmUMUl2hFc5iivuGjXwd+BuwUQgwLIX4T+BMhxEEhxJvAPcD/U6/jrzZqZWaolTPPyQQgES1nDlFcohXNYYo6moaklA/bbP5SvY63FqiFmWGuJg9U34eGE672vZgJoNXMIYr5qO+/9VAlJtYYtYpt3zcQ54kjY9X/zxYN0gWDW7d21mysCkWtULkN9UWVmFhj1Cq2XZkAFGsFldtQf5a0IhBC7MAK/eyVUu4RQlwPfEhK+Z/qOjrFAmqpya8lE4DSCFuXWplDFc4sdUXwv4B/DZQBpJRvAp+o16AUzrSiJq80wtZG5TbUn6X6CEJSypeFEHO3GU4fVtSXtaTJ1wKlEbY2Kreh/ixVEEwKIa4BJIAQ4mNYmcGKJmS1mWFatfibwkIFNtSfpZqGPgP8JbBLCDECfA74nbqNStEwVqMZphWLvyku0Yrm0JVmSSsCKeVJ4D4hRBjwSCnT9R2WolHU2gxTi9WF0gjrw2pb+S1Gq5lDV5qlRg393mW/AySBV6WUb9RhXIoGUUszjFM9I7fa3KxGODScYDJTpCPs49atnQ0TTM1Arb4bRXOwVB/B4MzrBzO//xPgFeC3hRDfklL+ST0Gp1h5aumYq+XqohYaoZr8LqEc8Iq5LNVH0AncJKX8vJTy81hCoRu4C/hUncamaAC1LDq22sL+VK39S6y270bRWJYqCDYCc++QMrBJSpkHVOhGE1FLx9xqc/Kqye8Sq+27UTSWpZqGvgb8XAjx/ZnfPwh8fcZ5fKQuI1vDuLVDrza7tVszjNP4V8LJ6+barbV4dKdza2YH/Gp7FloFIeXSer4IIQaBOwABPC+lPFDPgc1lcHBQHjiwYoe7Kubaoec+YE5atdvPrzauNP56PtjNfK2dxrpvIMbQcLIm57DaJt3lfD+r7RxWG0KIV6WUg1f63JKrj0opDwghzgKBmQNslFKevYoxNiVunXDLcdqtppv/SuOvZ9if22tXy+ijeuN0bo8dGmXXurZV44CvJW6/T+X8rx1LDR/9EFZ/4fXAOJbP4C3guvoNbW3iNvzS7edX283fyKzf5Rx7tU1+Tjid21iqwP5NHQu2N0OWtdvvU0U+1Y6lOov/I3Ar8LaUcgtwH/BC3Ua1hnHrhOsI+xiezvHamWmeeXuc185MMzydc/z8aot8aaTTsZkdnk7n1tsWaLlzdjo35fyvHUsVBGUp5UXAI4TwSCmfAm6o47jWLG7DL/vaArx6OkGyUCLq10kWSrx6OkFfW8D286vt5m9kj9vV1ge6ljid24N7+pq2p7Db77OZFYGVZqmCICGEiADPAX8rhPgLVPVRW9yGX46mCgxubicW9JIuGsSCXgY3tzOaKth+frXd/I2sA7Pa+kDXEqdz27exve7Xu1FC0Yo0i/HWhRSPHTzPWxdS7BuIOZ5bI5WQZmPRqCEhxOewTEBHgRyW4PhVIAb87cwqoe6spaght3ztpTN0Rfx45pT4rkjJZKbIr7xr04LPr6XIl7XC44dGyZfMeWGl6UKZoE/jgT19DRzZytPI+2s0kefR14aZyhQpmxW8moeOiJ+P3TSwJgInViO1ihoaAP4C2AW8CbyIJRh+IKWcuupRrnFqcRO6jW1fS5EvtaSeD7wqc32JRjpgnz42zqmJLO1hLzGfj4Jhcmoiy9PHxnnYRimCteP8X+0sahqSUv6+lPJ2YB3wb4Ap4DeAQ0KIlk4kq5U5YTnL2754kAf29PEr79rEA3v6mv5BqLfpZrWZ2xpJI31QB0eSxEM6Qa+OEIKgVyce0jk4kqz7sVudpeYRBIE2LJNQDDgPHKzXoNYCtdKc1pKG36hleL211JXKsl0LZoxGZl8LAUgxf6MUCGH7cUUNWVQQCCEewcoVSAMvYZmGviClnF6BsV0V9X7oamlOWAvL20bmL9TbdLMSwng5168RgqORpSf2rG/jwJkEQggCXg+FcoVkoczgJuX8rTdXihraCPiBC8AIMAys+lKNKxEF0mrmhEbmL6zEta63uc3t9WtUJFMjo8Du3tnL5o4QFVkhmS9TkRU2d4S4e2dv3Y/d6iy6IpBSPiCsLjTXAbcDnwf2CCGmgJ9JKf/9CozRNSvh8FqtRbvqRSMdqrW81o0qCLgas2adzq1RK9S+eJCPDW5Y9eazZuSKeQTS4hDwGPAjrKiha4B/UeexLZuVcHi1Wh/VRq6AGpUvUEutfLVlza7G3AlovUCI1cKVfASfxVoJ3IHVg+AF4GfAl1nFzuKVcnitBdt+rVhMK18JW3YtrvVKFAR0wu2qpt73sKrTo5jLlVYEm4FHgVuklFullL8upfyilHJISlmp//CWh8o4rD1OWjmwKjVLO9xq2bXUyt2uaup9D6+2UiWKxnIlH8HvLfb31cpaCslcS9hp5Y8fGsWoVDg+liFdLBP1e+mK+lalZulWy661Vu5mVVPve3itNelR1Jcl9yNYa7SS2aaRnJzIcG4qT8in0xbwUihbQqFQNhs9tAW4Nc80OiCgnvdwo89NsbpYatE5hcKWZL6MxwNBn2Zlg/o0PB5r+2rDrXmmmQMCmvncFO6p24pACPFl4APAuJRyz8y2DuAbWL6H08DHV0ty2nIcnvV2kj55eJRvHBhmLF2gNxrgocEB7r2udkXQahFKGQ/6SOUN8mWDgK5RMEwqFYgHFzcxNCqM00nLXgmHd616ENf7WjQDayGLezVRzxXBV4AHLtv2B8CTUsrtwJMzvzec5YTS1Tv87snDo3zhJyfIlAzWtwXIlAy+8JMTPHl4tCb7r1UoZTyks6M3il/3kCqU8esedvRG2dIdrvuxa3WtnfY/dHa6Zset1TFWa9jnakJdI/fUbUUgpXxWCLH5ss0fBu6e+fmrwNPAv6rXGJbKckLp6t1r+BsHhomFdNpDVhJSe0irbq/FqqBWoZSFsonmge090cuarDtHtzQyjNPNeGrZH7hWx2j2sM9aaPLNfo3qwUr7CHqllKMAM+89Th8UQnxaCHFACHFgYmKiroNaTiid2/9xq6WMpQvELtt/zK8zlrZvWOOWWoVSSnDVTKSWx65VqKPT/sdShZodt1bHaOawz1pp8s18jerFqnUWSykfkVIOSikHu7u763qsjrCPkek8r52dsvoGn51iZDq/aCid20xRt7VmeqMBkpftP1k06I3at7B0y3J6K9t9XgBDw0l2rWvjwb3r2bWujaHh5KIPb62OXatQx5XoD1yrYzRzjata1bNq5mtUL1ZaEIwJIfoAZt7HV/j4tvS1BThweppkvmz1Dc6XOXB62rFvMLhP+HGrpTw0OEAyZzCdK1IxTaZzRZI5g4cGB5Z/olcxfqfPg3T98Nbq2LXqTbwS/YFrdYxmTpaslSbfzNeoXqy0IPh74JMzP38S+P4KH992IhhNFdi/OU4s4LP6Bgd87N8cd+wbDO7D79xqKfde18fv3beNiE/nfKpAxKfze/dtW5Z/wO6caxVKKRGuH95GhXE6mR6AuvcHrlUP4mYO+6yVJt/M16heLNqz+Kp2LMTXsRzDXcAY8O+B7wHfxCpvfRb45aW0vKxVz2KnfqyZYpltPdEl9w2u5bHrfYMu57huHHZrqd/vWhprK6L6cdeeWvUsXjZSyocd/nRvvY55JZyiCUYSubqn2/fFg+wbiPHYoVHGUgV62wI8uMzqik4T9dDZ6QX7H00VXEVQuG2gspYyVFVv4pXFbQSQKg3TOJq2xIQdThNBPOhjeCrHVK5E2ZR4NUFHyMfHBjfU7NjWQ2E5Vfdv6iBbNBgaTtLTFnB1oztN1P0xP995fZR4WGd9LEiyUOaRZ0+xqTPIDRvbF5xzrergr6WHV9XXWTmW29GumZPcVjNNKwjstBGniSAe8nJyMsvpySzZskHYq6P3ehz3s5wbdTmxzXaZxWWJ7X6+cWCY7jb/nLwD6/3EeIbtvdElT36Lac2rrZGJWxpdSruVaPZY/ma7X1Zt+OjV4OQU7GsL2EYTJHJFprIltnZHuXlTJ1u7o0xlS3zv9XM1y1B0GxHhlFn8/Nvj9vHo6QKxOZM9YP0upGMEhZ0TebEw0bWerTlrnrs85wFW5tzsrnez0syx/M2YudyUgsApHnk0VbCNJhhOFNA8gtFkjsOjSUaTOTSP4Gcnp2rWp9dtRMTczGKPptEe8hML6RwcSdnHo0cDJAvzC70lC2W2dEVc9RHoawswnMjzwokJnj42xgsnJhhO5FlOmOhqY655bm7Ow9PHxup+bs04eSxGR9jH8HSO185MW7k5Z6YZns41hRmukf2760VTmoYWM2/YmTGyRYMLyQLRgJeQV6dsVjh7MUu+bNpqNctxLro1S4ylC6y/LI8h5teZzpZm4vfn7+ehwQG+87pVhygW8JIslElkDT6+f4NjHwG7pfuR0SRUZiPJZqKoKpLpXJltPfPHUw9Haz2X3E7migNnpnjPjvlJ7ss9N0dH/iKmktn3ZjEzgJWb84M3LJ+VdT+WOHMxx/672q/8z6ucZgw6aEpB4NYpGPHrGBVJdeJDYFQksaB3Wc5Fp8nAzqkK2DrVYkEvyaJRrTEEVmbxhvaQo3O2KxrgsUOjnE/m6W0L8PH9G9i30f7Bc7qZD5yZYnBTB9euj1W3pwtl3rqQqrujdbkOxqXidM5SUpNzW2z8Tsd+ZzzDeKpYt3OeHddKC5rRVIHBze1MZAqkCwaxoJdt3VFGUwX21fXI9acZgw6aUhC4DWlcHw8yni4ymsxTKBsEvDp9sQBbu8K22vdioZFXmsyWqplf19fGs8cvAtZKIFk0SOYMfvP2zY7O2X0b2x0n/stxupmlxHYVFA/6XF8Lt9S7kJ/TOe/tj9Xk3BYbv9OxE/kS62KBujlV6y1cnZjKluhvD7KhI1TdNpubs9ZZSyHTS6UpBYHbkMb2kA8Pgp6oH8P0oWsCD4JNnWHu3tnjKjTS7WTmpClu6Azze5va+caBYc6nrKih37x987Iziy+fLJ1u5r39MUam81VNLhrQ6Y4E2NIdZt9A3HWYqJuJ2u2Sezk5D19+7iQnJjJkyyZhr8a27gi/8e6tAK7Oze68Fhv/PTt7ePS1YaYyCcpmBa/moSPiJxb01sz8aEejondm63ddfh/1xWtTK6uRrKWQ6aXSlIIA3DUgAUk4YGm9Aa+HQrlCIl8CpOvQSLeT2WLLzHuv67vqktOLTZZ2N/N4qsAjz566ZNvNlzkzmefTd21xfS3cTtRul9xuJ7nxVIGTF3MYFUlQ92BUJCcv5hhPFdi3sX3J5+Z0Xl5NLD5+G99Le7S+ZoZG2bMX+Ajm3EfNwFoJmV4qTSsI7HB6gDPFMtt7wrx+NkkiXyIe9HHjxhgSceWdXobbyayWse12n19ssnzAJrN5aDjB/s1xJtMl0sUysYCPa7ojy7Ltup2o3S653U5yjx0aZV3sUq4FwHSuyGOHRpdsUlvsvAplw9HENDScYKAjtMD3UiibdTW5NcqePVu/qxb3kaL+NGX4qBNOYV/nE3mOj2cZaA8xuKmDgfYQx8ezCNzXYXJb+bBWse1O4YmnJrKu690PtIe4aVM779nRw02b2hloD9W0Br/TvupdyG8sZZ9rMbZIcUE7nHszCMfxL9bPoZ4F0hpVibOW95Gi/rTUisBJg8wUDTzCA2Jm4hcSqxaf+xWBW/uhU+kJr5Z0pU3Xqo5SLTXI5ezLzZLb7Qqit83KtZi7IkgWyvQuUm7cjsXOy2n8y/mfWtAoe3atVyLNlsm72mgpQeB0c4b9Onv745ydypIqlIkGdG7Z0kGlTpVZ57Kc2HYnR2UqX+LxQxfmmbdiQa8r00MtIyLqXdLB7ST34J4+Hnn2FLAw16JW57Wc/6n3JNcIe3Yt76NGRT61EnUrQ11L6l2G2qtBwKvPExDLLU/stpTu1146g0fA2Yt50sUyUb+XjZ1B3hxOcvPmjgVjKpRNyqZcsP/RRI4XT04RD/oI+TzkSpbD+4HrevjIjRuu2tew3AfO3jmPq2tUS+wqtLrxD8yynGu02q6FW2rhs1rOOany4cun4WWoVyNXSuqCq9de3DpIBZJXTieIB320BbwUyhVeOT3Ntm77HAavZl907iejKbyawKcLhLDevZpgJFFwFUFV68nHTe7EShQkc5NrgZTWy7PQlbYcLXu1XQs3LEcrr9VKZDmRT8qU5I6WEgTgfHPWyo7q/qYVlj/iMv9EPOSzzWF46ph90blkvsz1A3EuZorkygYhr8a1fW2kL6s/NIvTg71vIMbQcLKuy/BlhzSWSpBKQTK59FcmA4ax9Jdpzv8ZQNPA71/8FQjYbw8Gob0dOjpsX9OpPJ2x0LzTXI3lChpZTdStv0GZktzTcoLAiVppL24TaSRwy5YOW/+E3ZicHoreaICKlGztjla3T+eKjo5Qpwf7sUOj7FrXVtcHfu45aNks/okLmMMjXDc9Ds8X4Pz5S6+xMUgkrEm9sITonlAIYjFoa7Peo1HwekHXF39pmv12ISwBVCzOe+XTOVLJDGa+gN8wiGZy+JLJBZ8jl7OElwMPA6VoDCMep9wWx4i1k4u2UYm3w/YN0NkJAwOwYYP16u21xrrCNLK+jlt/Q7OXwK4HShBcAdddllwm0nSEfeRLJjdt7Khum7V/2uH0UDw0OMCXXzzDa5kpylLiFYKOSIB/+b6dtvtxerDHUgW2dEU4fnaqKsg2doTJl81Fr9MCKhVrIj91av7Efv4895wboXDmHKGL43izmQX/agSD5LrWYfSuI7h7D8HuTmtSnzvB273a2qxJv864bqloGJYwm5pa8EqfH2P4nRHC2RTBTBJteprYudNEsmn41rR1Heei6xjr+kh3ryPZtY7KwACdu7YR27H1krDo7rYE2BLO42rLc6xEfR23QQHNWBSu3ihBsAjLWWIulkjT46LUg5O24/RQjKcKM5OGsKxMQiycRObg9GBH/Dovn5qiPey1fBaGycunprh5s41dXUoYHYXjxy+9Tpy49J6/LOchEID16/GvX09l/42MhDuYjnXi6e9n4LprMNf18WRSI9ARJxzwrlrHqWuNU9ehq8t6XUYUiNvcF23xoPX9TU3B8DCcOwfDw2SOn2TsyAnaJi/Qc/RN/E//I1r5sth8v//SKmLjRti5E3btsl7btoHPt+i9PXsuV3Of1ho3K/ZmLApXb1oqamgxnPr9uo1W+NpLZ+iK+PHM0cgqUvLOeIawX7fVIuHqyxD/f48dIVM0FmTNRvw6//rB3Qs+76TVZotlTkxkL5XbKJmYo+e5U05xny+7cNLP5S7t1OeDrVth+3Zrwtm+Ha65Bvr7Yf16iMcX1VSXEx3SCKeg03c8mSnyK+/aVNdjL7hGlQql0QvEp8a43ZevCgzOnbNep0/DyMilHWgabN3KeP9mEhuvwdi+g+yW7WS3bGM6EHGMSrt/dy/jqUJNIq7qjesVWxOjooZcMHR2mr/4yXEMWUEgmMqWOH4hw851ETa5NJMsVmXS7/VwfCxTDRPtivoYGk7UJMtzLFVgfWz+TR4LeDmftM9EtltZ3NYbYOjx57ju8EHkG0OsP/0WG0ZPEyjMmex1/dJk/973Wu+zE//GjQvs19WJ+u0UHeHCsovOXSn0ciWdgotpnPUWTAuukceDvr6P020d3O4ghC6cG+fki6/DW2/Rc/40/WNn8B06wrYXnsEzZzVR6uhkpHcT7NpFeZslHMJbd0BXH08fG6NsctU9t5eLm+vajEXh6o1aEQB/+J0h3h7LEA/58WqCsilJ5IoIAQPtYdrDXgK6RsEwmc6WuXlzOw87PHRO2sj5RI5k3iDk06uF7XIlg1hQJ+wGJeYiAAAgAElEQVTTmcqVKJsSryboCPn42KCV5GTb5MRm9TL7e6ksyRkGIV3H5xX0tgUWrgikhAsX4I035r+OH2cmpZp8uI2Ja3ZxYeN2hrsHaN93Lfd88N3WZK8vTX9wq5k5rQgKZYOySU3yP2oRCw/2sf9zI67qpYm6XTUtmjvjEfRcvEDo1HHCp97Be+JtOPYW/RfO4Ju6WN1HOdrG2U07qdx4E4XrbyR13fXkN2wmXTJXJJZfafjLR60IHLB7sI+PZ4gFvPh0K17cpwtiAS/HJ9KEvBrHx9IUyiYBr0Zn2AszNYicJpV9A7EFE/VIIkehbJLMl8iVTUJeDb+uMTyVJRL0UTZMypUKXo+HC6ki33t9mKlMaV7J5FdPTXHr1g6+9sowJcPEI+BipsSJ8Sy3bo7x40PTFEwr/FQICGiCf/u+HUz8/DXOP/MzvAcP0nPyKO3Hj6JNTlSvSWb9BjLX7iH8Sx/n9fZNPBNcD5s2EvDq84TfaEcPQ29NLHkSXU7RObtSzV1hH9GAZpt9vbc/vuQVm1u7ODivOOw0zpWIVqlVBE2hbJIuS+jpJ7xhE6ffdXdVQFxIFTh3fJjw6XfYOXGG6ydO0vHWIfr+7v+g/fVfAlAMRUjs2sPUrr1M33MHh3q3cq5rgI5ooOaJZioKqP601IrASbP44ZsjBLwa0cAlZ1K6UOKdsTTt0QDSlEghEVIgNMGd13Tyydu3uNIKT4ylOHw+TSSoE/ZqZMsmmbxBuliiMxIg4tfxah7KZoVM0SCRLYIQCDwIIZFSIKng0zx4dQ/tIV/189O5EmWjQrZsEpi6yLWnD3HDuaPsO3uYneeP4y1Z0RIVr4/kNTuZ3HYtocGbONi9hfJ1e/B3dczxERi0h32cncrOm1ynsyUMs2K7cnF6GN3a0kcTeR49cG7BMXTNwzU9kQX7eezgeTzCs+QVm/OKw94u7tXEzH2xNO17pXwHbibSxcZ0z0yeytz9HBlJ8IWfnCAW0uc1RBrcGCOXK7L94lk2njpK17FDdL99mP6zb6PPmJeMcITEzusY376HvvfeQftdt8GOHfMS8paj3bs9ByUcLqFWBDYMDScwKpUFdvr+WJCTkzmEENVJOpkzCPo02gL6AgfsyYms6zj8C6kiXVE/4xmrE1rY76Un6mcsnSdeqXAxW6JkVPDpHnQPDCfydAR94BFVDZ+K5GyuxK1bO/DpGkjJhrGz3HH0VWJvHOCW82/RP34OgLKm886Gnfzgtg+x8b47Ke+5ntyWbUivt9p60m6cI4kcJdPknYksiVyJeMiHX/cwkS5yMVOiZEiMSgXd4+FCssDTx8Z4+F2bba/3cvoLhAM6+XIFo1Im6NUJB6yQVqcIp4vZMqnJUnU15dU1QLpqHPPK6al55Txm3185PcXdO5fey3ilolVqFUFjt5+vvHiKHb0RioZJrmwSD3rpjQY4OZmlJxZkbMu1JHdcR+G9v0giXyKEwf7cOP6h12g/dpgNp46y47t/g/6NL1k7jEbh9tvhrrvgrrt4MzTgWrt3OgeBex+Ryji2p6UEwcmJDOem8oR8erWcw/GxDL2xAD1tAd4ezzCZLRL2e7l1awdvXUhTkZKSYVa1b00IEJZD2SPEArPEWKrA/k0d844b9uvkyya5kkmbX2dd1E+uZDKZKaIJGE9ZJYr9Xg/FcoWpokHJqFCsmAQ1Lx6P1dOkUsyy7+QR3nfoDNeePsSW428SySQBmA62MbRpN9/edz9DG3ZzpH8nJa8P3QP/8SPXz9OmZvMF7MaZLZR5/vhFYiGdjqBVmO3Hh8cJeUHTrAc47NUpm1ZD+5dOTTkKArdmjJMTGd66kCZXMClLE6/QGE5orI8FbMttRP06qbxBCUBaRcO9HsG5KXeNY4Swb88phLtexo0OsazFmGaDDjxztPhKpcLJyQx32PTseO1skpeiA4Tu3UTgfR+jYJgUckWuT4/ykDYBL78Mzz0Hf/iHANzn85G8/iYS+28jMXgryX2DhEOhRWP8nc7BqdyKk1CxW3Eev5BedFXbKrSUIEjmy1zMFnjrQonMjEbZHfXRFozw4N4+uMyuj4DxVHFGO7LKNkT8fnra/AiwjbeP+HWGp3PVPILZVUfQq9EZ8VE0KuRLFUJ+jfawl1yxjNerISQUDQPd46EtpHMx6yGaSnL7+SPsOXOY604fYvvIcbymNSGe7t7IT3fexuHN1/H2tut5w99FqSII+nQ0j8CsSAolg2hQt89EbgvYbh9Pl9jeG66OMxa0Vi6vnJrimp75fhSfLriYca4v7zZ643wiz/lEnvaQn7DmpWxKzifytAV02/185cVTRIM6GzvD1X1M54qcGM+wvTdqYxe3bxyzZ32b7bXYs77NVeXW1Rit4nZMTqW6YwG92rNjW0/EUqLGsxRKZTxRH0GvNZUEvToFr8nJvi3w4D+BT33K2snFi/D885z97o+IHfg5m//3f8Xzl39ORdNI7NpDcvBWGHsQ7rzTKr+xhHNwKrfiJFSePjbG6akc8aCPWNAK2Dg9lVt0VdsqNK0gsFsCZgtlDg6nEAg0D2QLJheSBSI+3bYnwC2b2vnO66O0h31snlO2+ME9fRwZTVrmGjmjaUuBEBD1a7x6OnEps7hQ4szFHD1RH6YUdIbnRw11twWIB31kSwayWGLXqYPccPQVNr/2AttGjuORkqLu4+jATv7uzo9xduc+XurdwUSwzfJZC/B7BGEpqRTKFA2DigSPAF2DqN++DPWDe/oYGk4u2I7AViMUQlAyKvNWRyWjwrrY4rX83ZgxMkUD3SOonhgS3SPIFA3b/cSCXlJ5g3zJrF5TK6dO2k4Q+bLJ/bsX1m8C+6KDc53IS53YV6Lks+tsdxdjcirVvWd9jAvp0oKaWAGvRqXCgu8gFrwsw7uzEz78YQLv+QV+eGSMdrPA+qNvEH75RdoP/JzNf/cV+KrliGbPnqopibvugr4+V+VWnFZsh86niAW81az9oE9DSi+HzjuXAGkVmlIQOEWHHB/PoGsCTQgqSHwegSnh6GiKd+/oWaBBliV8+q4tPHZolPPJPL1tAT6+fwP7NrZzeDTFzZvbOXsxb9UI8nu5eXM7B0eS7FgX5shomhPjGeIhH7v7ouRKJr1tASbTpern++NhtkycYd+br9D1s2cYOPgK/kKeiqZzduf1PHrjb/LUwPW80XMN3qCf/ngQryZY59PQ0vNXNUNnE0QDPorlCoY00YWG32s5Up00wp62wILtI4mcrUa4tTtM2K9TMiwBpnkE7WEf79qyPLOH3WQW9lvafaZQrq7ANnaG8Wr2SWhbuyMEvNr8a9oeoS1lvwparAnMYlrzajIbjCbyM5FVxWpk1fHxDB+7aaAm49y3sZ1P38WCe/7waIp42MerZxNV39H+jXFOX8yxrSey4DtYv4QY/2P7bqPj9vcQG4gjAgJeeQWefdZ6/dVfwRe/aP3T3r3w/vfDAw/AHXdYiYu4N3vNK+44S7UJVWvTlILAyZE7lioS9GqE5phPciWD9ExzmrnMLjEfcMierNYI2nTpb+lCmWzR4EIFBtqDbOuOUDBMLiSLtIe8ZEsmYnKcPW/8jB1DP2f70M+ITFo3cnrTVsZ+8WFGBu/g9J6b6VnfxT/OhInuEJaPwKdrpPIFJIKuSIC+mJXzkC9ZGr8Qgp62QNXXkCqUWR8LOE5+dtudNMJP3rqJI2OZeRNQR8S/wJm6FJwE9UA8yImJLH2xUFW7TORL3LghZruffQNxxlNFtvdGlrTaWcxW34jmLcvh6WPjnJrI0h72EvP5KBgmpyayPH1s3DG3xS12pbqPjKZ460Jm3n391oUMO3rC6B7Pgu9gsSRJx2v97ndbrz/8Q6s+0xtvwE9/Co8/Dn/+5/Anf2I5n++9F97/fvre/35XZq+9/TFeOT2NEKIaZZbIGfblU1qMphQETtEhum5psYYpKZomfk2jPexD89g7ETvCPsdGJk7aSGSmD+2szTQiK6w//BLbhn7OtQdfouf4YQDykTaGb7qd7l/6IKW77+U1T1tVO757pun8ndu6FlQx/d7rw3h1Oc9Wny1J2oJeNneGuZAqkC6WCWgedvVG2LnOfhIFe63cSSPct7Gd3f21ibhwEtRezRKwJ8bSZMsGYa/Ott4od+/std3PYvZvu9XOWpjor8TBkSTxkD7PJi9DkoMjSR6u65GlrSk0FvJy9053fpElmbZ0HQYHrde//JeQTsOTT1pC4Uc/gu99D4C+3bvpe//7rRXDDXdadZYcuHtnDycnszb31/KUmWaKPmqIIBBCnAbSgAkYS4lzdYOT7XDv+hgnJ3PEg156fFbkTiJf5p4d3QxP5RbEr+/ui/LIs6eIh3XWx4IkC2UeefYUn75rRmuySRzLFMucPX6OjpefZt+rz7DnyMv4SwVMTWN63yAnPvsHTN3+HlK7ryddrlRj0h+47ByeOjZOf3uQDR2XatVXpCQe8pEpGGS0cjXUtViqsLU7yq1bO5dc/nqx5Cqn5i31bjQymsxbSx+g2i+6svi63c1qpxmYNxnPMjMp1xOJsDWFVqS7a73sXgHRKHzkI9ZLSjh61BIIjz8O/+2/wZ/9GYTD1dUCDzwAmzcv2E1b0MvmrnB1Vdt2uS+jnuewimnkiuAeKeVkPXbspK1/6vYtfPOVswyNpDhzsUwk4GVffxvv29PHsydmhzLjqPQIfnpsnHj4Uh7B7Ptjh0bpaQvw2MFR3h7PkC2W0YaHGf/+3/Dhl3/KujcPoFVMLnb08vydH+Ctfbdzds8gN+7ZeKkl5XCKjZ1BxyxYJ2G2qy9KyKdxZDTNxRlb7U0b4/RE/ZRN2N4TXdISfWg4gVmRHB9PzxMcQ8OJ6t8v13aePDzKNw4MM5Yu0BsN8NDgAPdet3h5ATvNqSPss42sGpnOMZWz/A9BrwfNIxi+Qq5CrXDS8Fab5rdnfRvPvj05L5/Dpwvu2rGwsmktcTKFOpVLd6ImWcJCwO7d1uvzn7eaDz31lCUYfvQj+Pu/tz63axc8+CB89KNw++0MDScYiAe5dl3bvHNY7J6v2zmsMhqSWTyzIhhcqiBYTmaxU42YL79wasHScGtX2DaD9Osvn2FwU8eCCJrzyTy7eiIc+slL3HP0eW5+41k2nn4LgJH+rRy55b2cfvcvkNi1h4IhSeRLVCoVPB7PpaqeM/bvwU1x20nOKQNzsXo2YH8z212L770+wtmpHCG/VrWX5oom7SEv62LBBfsP6vCVn51bkHH6e/dtcxQGTufQH/Pzndfn9GyY8UOkCyXKFbkgy7o3GuC/PHyjq+/fDcu51o164IfOTvNfnzxOyazgmfUdaR4+e+/2ulYCrVW9n+VmXy9ZIEsJb799SSg884zVIKivj7fvuJ/kgx8itf9W5Ey9rCtVBrY7RiOrz7pltWcWS+DHQggJ/KWU8pGVOOjTx8a5mCmxtSdSnfwuZkpMpAvs7mvj8cMX5kVE+L3a/AiaSoW2oQPcdeApNj/3BL89PgzAye3X891PfJYX997J6/5ufuvdW5ie04z+5s3t/PzkRbIFg0SuhGFKdE3g9XiomkAuY7n278tvXKdl7EgiR75sVUXNlyoEfR78uoeL40XbGPyvvHAKv1dQKFdI5Qv4dA9+r+AbB4YdBYGT5vTymWkGN7dXzVixoJdt3VG+eeAs0YC+IMv6Yq6+DUUa2a3NLaOpAndu715gAhxNFdhXx+PWKkdiOdnXrkwxQlj9F3buhM99zvIt/MM/wKOPcs0Pv4n26F9R6uhk/N4HGb//n3D2+ltI5EusiwWW/D07rWjXr8IV5FJplCC4Q0p5XgjRAzwhhHhLSvns3A8IIT4NfBpg48aNrnbudOO8emaKzohvgaPt1TPTHB5Jki9XMCuSkek8J8fT3L61k9GLGWLP/JTBN57hpjeeI568iNR1hrbfxBPv+1WO3HIPqfZuAIolA6az+HVtwRIaoIJkPF2kUDYIeHX6YgGmc4snZLmxf9vdhE6T3Hi6wMVMmYjfS8jnIVesMJ4qEvIJ2wiqsXSB9pAPv67j1z2YFSgaJudKWcebf7EuaPs3dSzwfwjss6x39kYcr1EtuNI4L9/eyKbpU9mSre9oOd23apWP4GY/y8m+vipTTDQKn/gEfOITTIxM8tZXvsU1zz1O3z98h4Fv/TXXRWPsvOM+8h/8CNO334X0+atjc7qmC7oQzuQKbboxuGZ9Bw0RBFLK8zPv40KI7wK3AM9e9plHgEfAMg252b/TjTOdK2FWJOcTCdIlg6hPZ308yESqwFSuhJTWylKTJredeZP7vv0iNw89RyCXoeAPcnDPbYzc/T5u/b9/nW+9Os6rp6fIZyWl1BQ+zUPQK9i7PmabwIWUTGVLrGsLVktdT2WLnE/Y9wtYDDe1+WeLyC2o0FmqEPZ7ODOVJV8yCPp0NnYECOj2Mfh+zUO5IgnPxPTrGmRKEq/AMa7dsb+yQ1ZzV8RHomAsyLLuii6uLbqx7Tv5LNyMs9ZN0922jHTTE3uxYzqN1akBjaO59bmTC6rk/sa7tzoqMW5XFrVqPbmuvwv5mU8x9OGP8OLFFNuHXmTXiz9h2z/8AO/j38aIRJm4532M/8IHOH3T7XS02Ssgo6mCba7Qy2emV90KcqmsuCAQQoQBj5QyPfPzLwD/by2P4VQHCOD1cwkifo2ITydbMnj9XIKpTAlTSnZfeIcPHn6aDx59lt7MFGl/iLH3fYDp932AqdvuouIPIAtl3kjDDQMxfnRwFFNaxp0ckC7Ab27t4M4dC2/0185OkSsZTKQKlCpWMls4oJMpGq7OzekBdqq78vZYiuPjmQWlMEqGyflEgXBApyMUJFc2OTWR4+Yt7baCbP+mdl45PU1alAjPXLtiyaQrHnCMa797Z4+t9ucU53/d+hgjiQLZklE1n4V9OgPtYZsr4Xwt5tr23Wxf6jhr2TTdrfBw2xPbCaexfv/1YQ6OpBdEyv3ijQVGksUF4xxN5Hj5zDTxoI/OkI9cqcLLZ6bpiJzjd+7ZYXtstxFdtSzmd+nYffCenfDZf8boWIIjf/1dtj33OOuf/jF9P3iU3cEQxgMPwq88BB/4gNVmdYZTE1lOjmcwzApBr4ZhVjg5niFvSNcryNVCI1YEvcB3heVo0YGvSSkfr+UBBPDMsXFKpmXq0TyCUxNZimWTzrAPsMol+HWdjckxdj7/D3zkyNNsu3iOskfnme0385+ufQ9PbruF//Kp2xYUbJvMFDk8kqQjHCCZL1E0K/g1D7GgjzeGk/zyLZsX3Oi5okkqb1VM1D2CioRU3iBXNF1phE4PsFWbP8bxM5cqq27sDJIuGOiaZ0H8d6pg0NNm3dxF0yTssxrkZAqmbVhsT5ufjrCPV84mmM6VaAv5ePe2Lo6NZ5zj2t+1yZWfY2g4QU9bYcna7mK2/aBX44V3Jqs+n2vXRR1t/qOpQk3yEZajuboVHov1xHbyEbipxPrCyYts7AgtiJT7xoFh3r+3b8E4v35sgu5ogEhgJm8m4EFKyc9OTvE79zietivqXcyvrzcOv/UJhh54gBeTWbYdPsDuF58g/NgP4LuPQiwGDz0E//Sfwu23M5LIMZIs0B7y4/dZq/uRZIGQ17Mi1WfrwYoLAinlSairX4tErsj5ZIF40EfIp5ErVZjMFCiVywxu6aRwfoI9r/yYO176MdvefgOAlweu498+8Ls8vutOksEoRkWia87VJw+dT1M0TBACTbMqkhYNk0Pn07YPXqFsCQHN46EiJR6PwKxUSOSKrjRCpwc4WzR45bSlmc1WVrWyKLGN/z5yPkHIpxHw6lVTVaFskC+btnWX9g3E2NgZ4br++LyHcTJTWjSu3a2fYzw1tuQQWKdrcXQ0RbZoEvHrdIR85Eomzx2fJOTTHDW2WuQjLEdzdVq9OoUVT2VLDLSHqitcWNxH4LyCtE+iLJZNYnO2gZVhfmgkaV+/yTDxXjaLeHVIFZzbubplOeYktybDed/zHdvg05+wspufesoqd/E3fwOPPALbtnH7jfeR3Hc/hdAl36Xu8RDwaq6KFK4mmjKzeDhRYGdPhHTJmKn06aHfrxP+yZN86GtPce3rL6CbBqPrt/DDhz7DX3Tv51SkZ04Aj8QjoD1kX7Dt1q2dJHNFJjNF9JkevQYVMoUyEmlb6rZgVECAWZGAxJxJV0gXDVfx/E424ohfJ1eqLCgKFvHrts7rDe1hQn6NolEhVzIJ+jx0+n3kiqathuqkNXs1OHAmYaXtz4TFJgtlBje578PcF7fv7ua2Tn0yVyZVKHF8vEzRkPh1QWfYi2HWt1/AlTRXu0nIqYqtU9mD5fR4sO9QZjCcyC/oBre9J2Jba6o3au8v2dgRIpk38AhPNeQ3mTfYtS66/Atpg9ukNTu/1V3bumxNg4uFXnP//dbri1+Eb38bvvpVHvzW/+TBb/1P3t51E8/e9iCHbruP9o42dE1zFFirPZqoKQWBlBAJ6vRGfAwcfIXdP/0B25//RwK5DBfbOnn8vb/M0Lsf5HDvVpJ5kxAVAlM5ZEVW614Kj+CGDXHHL7ZsVjAqkgomQkqkEFQqkmSuyJEL6QWtJ9P5Mt1RPwJRLW8hkaTyZV4/Oz3PLj7syzORDjKeWmiT7Y/5OXB6eoGNeGNHgD39Ec5OZS3NP6Bzy5YOprMl26zphwYH+M7ro3SEfcQ6L8XyzxaXm8tiWvPdO3uZTJeYypVI5k28mmBzR6haFsKNZgbYrkacGqQ7TbzZYonh6YLVYUy3Jqfh6QKbOqirxraY5uqkmWeLZdvSDbPtUJd6zk7n4DaL+707e/jO66PA/FpTDw0OMJIsLjjuJ2/dxNdeGaZQNikZJhUJsaCPX96/YbmX8apxqsc0lsyzf9PCBkRPHxuvdqhzXJVHo1ZJ7U99iu9/7wW8X/8a73ruh/zW//lPlP/2T3nzlveS+uWH6YteR99l3evWQiZyUwqCvf0xnj0+wS999T9z30++ST4Q4rWb38ux936Q9G13cng8Z9mOgz7etTXKqYkc0ZCXs1N58uUKQa+HjR1BbtjQ4aiJSEADDHNWeEh0ASUTLiTzmBVZ9U9oHsv0ohsSs2IiBORNA83jwavB6aksQoIhK+jCw4QoMp21j+d/+cy0rY14LFUgX5q/HM+XTOIhL5PZ0pxRW1nTu/vjTGWL/M1L57iYLdIZ9vNr79pANOTnyPkkRy+k59nXd/W1OU7qHxvc4DjZOzlzn317YsGqqSvqc2Uvd5p4/+uTb+PTLQ3VnCnWJ0SFRN6se78Ap/vFSTN/64J9FVunyhpuzSROMe/JfJld69q4dv2lWlTpQnnRiruz3//lx+2KBmyjjJxwqt9VKxarx3TXjoUd55w61Dndd7fcfROPtvXwyq/8NuuOvM7+Z37I3ucfx//8Y/AnfwC/9mvwyU/CtddW97PaM5GbUhDs7mvjJ0fGePrWBzm2dS+vXX8nhELsXBflhoF2dm+4pD1VpGQsVeTeDX2uQvJ8mobwQFC7lGJvmCZmBcZSecom1WWpVwO/phH2a5xPlMgbFYK6h/XxIMmcSSpnzMTO6xTLFbJFg3LZpGhUHDugXW4jnkgVbFcKe/qjtmn133t9mOdPXKRkmAR8GiXD5HtDF7h7ewdPHBmf16HsiSPj9Mf8i2o1bia/bx44S8GQCxqEvDOZ4cG96+ftY7lRF7pHoHs8+D1gVmA2g75WNYjcLvWdNHMhsDXdLVa6wc05OMa8dwZt76982XSsuOt0XKfaVHYMnZ1etH5XLXCqxxT0arbmLacOdY55BPEgH7tpwPr+172HyQ/ez1RXgL5nn7D8CX/6p/DHfww33wyf/CTpne8m1rf0lqeNoCkFwWiqwJauEK/kruGFtg20oXNzVwhTSo6OJjkyeknb3d0XZW9/jNOT2WrdoLDfi9kjeWDPOscHPhb0MpEpUDYrlvNXWJq/qFj5AiBmGsSYgCTi09A0DxVprSQqEiYzVkP4njY/RgUrksnrIez3MZ0tO3ZAs7uZK8C23hBvjWas2Oagj119Ec5N57mmZ769NuzXefzwBaayZdoCOm1ejWLZ5OxUjm++mmdLd4SJdInJTJawz0t/e4Anjk7YRo0sptU4TX7HxzNs7ghzPpmrZjVHfTrjmZKj/dtN7kR3xEeqYGJUKpQqFXweD37dS1fEfj9uBcNyWh462fb3rG+ztdV/7KaBRY+/1HMYTRVss7jfmUi78k3UiscOjeLTBdPZEiOJPCGvhl/XeOzQaM0EwZ71bbZ+q9u2drjqULeY78hWKH7844z+wgc5+sbbxL/7KNse/w5tv/u7fDQY5NwDH2X8V/8Z6Wv3Lmn/K01TCoI3zyV46dQ0ppSEfDplo8JLp6bpj/s5N11c0I/3I/t6OTicYDpfxjAl6YJBsWRwZCRhGzt9/+5e2oIaZkVSNpmZ8C2Ns1KZMRsJ8ABIMCUk8yZ+n4kH8GpW7aJ82cSomGieILHg/Po6Ib9GvmQ5PucWF9veY98+cTYrd24rwfFUiXzZsL3Jx5JFOsJegr6Z5bNPR0rJqcks62JBuiJ++rRAtd/BZKbgSmsC58lPAmenc0QDVlRX2ZScnc7RFtRtz21rV9gx8sXO0X7L5g4eO3QBjyaI6Bqlmb7TH9jbW5Nm508fG+PIhRTlsqz2Vr6QWrw4npNtf9ZMZnHliqtu7c1OmchvnJu2DSsGWdcCfKcmc+RLBgGvRsirUzYrpAtFsqXaRRk5+a0+cqPlt7DrUHd5Uty27gi/8e6tro5b/W7aOjE+/RnOfPKf433jdW778TfZ8L1H2fLdr5HYt58Tv/TrXLjzAW690V3FhHrSlILg0Pkk07lSNV7fI8CoWJm8e/pjTKSLTGSKRH06A+0BvvP6eXxeDZ/mweOx7PTZsslXXjzNPdf2cnwsM8++OjScIFUwkdIyQUgpEcJ6N4GQDrpHq243Kgb5EkT8GtHAJS0gXSiRyBKYlMYAABgtSURBVJrEQz7Khkm2VMbr8RAP+YgGNEwpGc8U5pWkkAjH/r0eD/Pa8BUMqz+C3eTq9wrKZoWpbKkqaDQhQQgSuTLZUoGCYRDQdcI+DZ+mcfh8grdGM9Xm5bv6IlzbF3OcIPYNxBdozh0hHwOxIOcSeea2pDQqkp5owPbcnExMz7w9TtCrE/JrVa327bE07SEvN22Mc+BMgnS5TNCrM7gpTiToI+B11+zcbtJ94fgEqaJBxO+t9lZO5Mq8dHLKURA42faHhhNUkJxPFqqr1HjI6xg15tbe7CSMIwGdvf2xBb6JqWzJVZKea4enlJhS4tOt+9Sna2RLBrNtwtwKG7d+q9nvYi5DZ6c5eTGHUZEEdQ9GRXLyYo7xVMHVudl9N+kbbuSVWwa54Y/+mOn/8b/p/7uvMvjvPsdNHZ14fvM34Ld/G7a6Ezj1oCkFwXgqTzJXpFSRyAoID/hmhMI74ynG0uXqxJTKFxlPl+mMeJHykjlHCMmFZIGBjjAhn16NzT8+lqFQNrmYKc44gjVmJzSzYiJMiV/XMSozZYI1D35dp1g2kFJimJVqdzQpJR0RH7vXRRdMlu9MZBhO5FnXFqiuFKayJceSFPGgz+rfWzaqBfUqFdjYEbKdgJ4/PsbLp5PWJK97KJZNsiWTmN/DqckMlWpVWivOfe/6KD85MnFpNVUs85MjEwzEAo4aKmBJYWCuo3pdLEAFq0fxbNvL/niQ/njIdsn91LFxWxPTVLbEho75TsFC2eTQ+SRdkQAfuam/ei2ms2VeOjnNg9f3LdiP06rGadK1VjM6U9liNQJM88DFRepGgb054a9/dpqXTk4RCep0hnxkyybPHptkMl20jRrLFg2u6Zlf+mCxc3BaiexZ32brm0jmy/TFgrZJerUon7C1O8wrp6fJFAyrxlWpQrFc4fr+sOvVzpU+v9RxPXZolHUx/7yQ2elc0bW5arGEwnV7NrHuj/8d/NG/hZ/+FM8Xvwhf+ALyT/+UyTvu4ciHf4X8/e9j36bGNFBqSkGQyhtkS5LK7IYKlLF+PzFZqH6uYEC6aKIBJdOkaFzSUf06+DWPrZadzJcpVyDo1TAl1Qncp2mUTYOyWUH3aHh9gkpFUDZNeqM+PEIwnStRMisztYk87N/UYau9/PHjRzErliPbrFTQPB40j1Uszu7mj4e8TGY8HDgzTWom83dwY5wt3WHbh+LGjR2cnMxRKJkUyiaagK6Il3zJRIgKmvBUfR8gOTmV54YN7Yyni5bvwO9loCO4qO8AIOLTyfsMjIIk6LNKe2QKZW7Y0G7rnHdTC6g95LNtnJ7IldjWE1kQNXJ8PONYNdIOpwcb4OzFLOUKVCpWcqDXA/s2dNjtZlFOjGfw+zxE/Na5RfyW0H9zOMlNNqGOI4mcKz9KXzxIsVTiS8+9Q7JQJhbw8mvv2sD9N2ywFRDxoM++6GCqgCbghZNT1fvrjq0dDHTYl/8Ae239ho3t+L0e3hrNMDUTuXfDxk6u7YstutqZfb+a1ZETY6kCUb/OOxPpqs+qK+xjLFVw/B83fTbm3V9CWM1z7r2XsSMnuPBn/50df/913vP8b5HtG+DYhx7G8/nP0Lt9ZctZN6UgSObLl4TADJf/PhcTMGdK/ljTniUkkBXOTGZ4bmpiXljpHdt66AjqnJ0q4/dqhH0aRgUKZZO2gEbU7yNVtFYdugc6Q372b4px6HzGcgb7NAwpkVJwz45u+0HJS+NBXMp1S+TKtjf/2xeS/PzkNLGQzvpolGTR4Ocnp7ndIb48FvLxsf0beP3cpWbkN26I85dPnyDst7Ts2Xr3+bJBIltiOlPEnBFipllhOlMkXTQdfQfJXJm3RpNkSmY1lHbEl6O/PUSmUCZfssxr+ZJJplCmry3uHG56YnKBQ/XWrZ3ky+aCxukjiZxt1EhI13hhJlKqWstf1/jse7fZXiMnAeTzWApE9XsSUACkXIadW0g0YZU8mc3w1oSgZNpf11jQPsnRyY9SLJX48ovnCAc0toR9pEsmX37xHPGQzzZ5bzRVsD3nfMng+0OjRPwa8ZCP3MzvH7q+z5Ujf99AjOMX0qyPB+iO+vFqAl142DcQd1z5vTOecVwdtYe9C8qqOGVlOxH2aQyNJC1/3ux9msizd32b7eedViL9MT+vnk4siNDaf1e7bVOnsgyT/8zvM/nZ36f7qX9k4O++wk1/+Z+pfOm/kP/wRxn60MOc3HEDHRF/3RPQmlIQZMvLa7bjEZapcnaSKJhwYiKHBwjoAsOUnJjIsbe/xK6+Ni5my5gVSWnm4Q37dTojXgbaw1xI5imYFQKah3WxICaC9+9dtyA+fzxTYsTmphLC8j/EI/7qBJHIFZHSPtTt8GiaHb0RioZJrmwSD3rpjQZ4+cy0bb+AjrCPoFebl/iTLpTx+XQiPoFEVBPiIj4PiZxgIlMiFvRa8fkVyUSmRGCR+ipHzidta7IIAdf0zj5kl0xGR0aTtkLuyGjKNvlpd18bQ8PJBY3Tb9vawYmJ3IKokZBfo1CuANb4fZrApwmOjKZsTQBOZpWSIfF5PHg0UR1+xbRWb27Z0mXlgFye4e0U6ri1O1LVhpfiR/nSc+8QDmjEg5ZvKh7U4P9v71yD4yrPO/579qZdXdeSJSFLlm1qW4ANBuLGBHsalxLGpUzc6ZCkhEyTGVraTjOkt2HSTCdNmaFtOi3tB/qFaTwwJSFAIC1DGRPHgZgmKUUQnBgMxWAbG4v4oru093374ZyVV6tz1lp1V2d19vnNnNGes0dn32fP2fd5L8/7f0iz70cnuGPHekcpESehvbGZtN2LDRMQiIXDpLOGV0+O0hdvdpjIdxZBfHNkwnG4ENwdr1u+gLc/nODYObNAVqXSVe3xaJgLU2naYiGaw0FmMzmmElniJVIbBSrNs/H8kRF++M4Fq5HWHmUileWB7x/jI4Md7NrcgxHh7C23cfaW24i++7+0PfwNrnz+aW546gm2bLqC4a/+Awcmt9R0AZovHcFSCAkEAkU/7Lwhay7Go+eNIRISsvk8b4xM8rHLVzOdzPDhZJpkNkc0FOSy9ggTqSw97U0MFcXtj82meP/CLLdevYat/Rcf0rwxvPj2WcfFLAbo64gxk84yk7JWHPd1xAgEnPWPEpkcfR1Rx2xqTrhVctf2t3P0wynaowE6QiHS2TyTyRwdUWsldDZnyW9YC+kMXS3uMhz7j4wQKioPWJosZyaSfHyod8HahuGTo3y8zIKf0sVPbrIXwNwkdXHUyLvnp+mLR2mOXPzuZtMZ18TvbhO8j/zkOKvbIuSMzJton15C5MutW/t46NDxBSu83VbyFhZxLXYeZSKZYUNJmGJbJMjJ0VnHysztO33qtVMMdsWYTubm5kUGu2KcvOB8Hbd7OXxylO3rOh3TRbo9kx2xsGPjZyaVI5XLM27LywcDQiTknuzJjbFkluvXxTk9nmTaDh/f1NPKWNJZGbjSPBtPDL/PqpZIkZCfNdR8+PQE1xUN/wGc69/AS3fdy8k//QobDz5L/3ceJbh2kLZoqKYL0NQR2FgtcOaijDKWJBDRSJBs1qr0QIhGgpybSrKh20pvWTrOffjUmOO4dVerc2vHbTFLS1OIjd1tC64fDQccK96h3jZnjZh250VxbpXctoEO/n7/W4zOpC3l0oCwdlUzLdEgEQnwwWSSqZQVjbS1s52O1ojrStfmSIjBTmEqlZtr7Q52Rjl+YdbRZmOcnVy5BT9uk4JO8y4PvvBOxYnfna7f1RrhwlSa9mhobuJ/Kpmhq0zeBDe2Da7i7l+hopW8Tri1pjuiYabSObsnYDGVztEcCVb0nfa2RZlOZ7ms4+LxsdkUsZDzddzupVuPtvC5bpFVTtdCrCCQ4in6SMCKeqsEEehujbKu6+Ik/GwqSyrnrAxcaf6KRDrH+s75Nnc0hRibSTn+luOxCNF4K2duv5Mzt99pvb/E5EOLxZeOIFyoyBdJEKsNkcfqAWTtbFmrm4NkslaLL5+3pSKyeVpiYbYNxHnn7Gl7nNtY49zpLDsu7ySRyS8Yt465VOBui1m2rml3TEa/e8hqZTlV4A8dOg7M14j5dBnNF6cffF88xr17rlgwdvzmyATDJ8e5frBzXs7lrWvaXSvjq/s7eOXEGGvisXnRO0O9bY42X93vnNSnWgt+3BYaVTqUcNPmHp45PEI6l0dyVu+tKRTkppIW8GJxW5lbSeSLW2v6czvWsu/Hp4A0bZEgU+kcM8kct1zZU9F3+pntAzzw/WMA83JW7x7qruheXt3fUfZz3Wx2sq21KYQB1hZV4GOzKcYT5aO3SnF7LjZ2O8+7VJq/YrAzxkQqO9cTAJhIZVm7qqUix1fLBWi+dAS/dsVqnj96fp5slwBNAkkHB7G5J8bNV/by2PAHVox1U4g7tvfzwWSKHxw9R6wpSCwUYDaTJZHK8RG74phMZDhxfoaZTJaWcIhQMDCncFg6bl0QYXMaxnB6yIsVEReTm7gvHnNtWVaKU8XU0x4tKy7nxO6hHs7PpBmdTjGRSBMOBtjQ3TL3HS3WZrfvqFKxuEsJ5C2WvdcNMDabmbcSfXNPK3uvc18NDLVNY1lOgyjeHOHRl09xbtrSlPr9XevZtbm3ou+0MM/0+PBpzkxaE5533bieq/qdHVA176WbbdOpDKdGEwt63x0x57F9N9yei3hz2HHdSaX5K/o7mhyd6F03rq/I8dVSzlqMWdrE6nKyfft2Mzw8vOjzR8YT3PPNV/jZmSkyOQgH4Zo1baTyVrheKmvmhoCaQsKWNe08+Ye7Flznb597k7dGJjk5liCRyhJrCrFuVYwr+tpZ32XFQ69qCc9r7f7y+lXsHuqpyqKYemMp5azWKtVqfUdeXac40qS0wvTqXldL/M2re7n/yAhnxhOO4Zp7ti4MkKjUhsK8S3FiqkLuh8/uqCy80ylqyCmIo1x5lvIdicirxpjtlzzPr47AaUXrc0dGGJtNk8jkyeasxV6xcIDetij37d264Efxo3fPc2o0QXMkNNfimE1nWdsZ4/RYgmg4sGDiMZnJ8ze/dU0tvgZlBbP/yAiJdG5ed78gLldppVUNlsMx1bqBU2sb6u2eLYXFOoLApU5YiRw+Pc5AZzM7N3aze6iHnRu7GehsJpnOMTmbISBWwpaAwORshkQ6y0OHjjOdyrKmI8Z0ytoPAJt6W2kKBZhMZmgKBdjU28rl3a2uCoflJh6VxmV0Ju04STo6U9l4drUoDoEMiNAWDc9FplSDQiWdSOdY3dpEIp2zcxw7R7EthcKQUSwS5Px0ilgkWFVHtm0gzlQyy1QyQ95YAQHlMuatZHw5R+AW3pXO5WmPhUhmDZOpLE3BAO2xEKOzGeItoQV5Wk+NzTJ0WceC8f5tA3HGZlJVy8yl+J9qJmCvBkvJr1wJy6XBXy1Zcbdr1zp/Rb3gS0fgls4xGhbGE9ASCbEqJKSzhmQ2Ry6XdczTemYi4fogVGvisVFZKfMi1aLWCdgrpdaOqdaOZrmopaOpJ3zpCBYk47CTtHS1RImGs8xm8iQzOaLhIPHmENPJoGsMvtuDcCmFQy9YKZXrSkjdV22q2bqsxn2utWOqtx6QUh5fOoKRyaRjOsf/fi9LLg+r20K0hIPMZHJMJ7IMrW9jfMaKeV5sDD7UV2uhXitXp0prJaTuqwXVeF6qdZ9rPexRbz0gpTy+dASjM1aCltJ0jt1tUbas6eDNkSku2Ho/1w/GGbqsnb72aFVi8L2iHitXt0prOpVho0PWtJU2bOAF1bzPOr6uFPClIyiXFjCTgz1bWhZM/vbFYyuq4i+lHsdk3SqtclLKSnnq8T67UU89ZqU8vgwfdQv72j3UW9NwMy8pOL9ivK5c3UIm47FIw4TlVZt6vM/KyseXPYJLdUv9UPGXUo9jsm49sw3dLY5Syn68L9WmHu+zsvLx5criRqXeoobqUVbBD9TbfVbql8WuLPZlj6BRqbcxWZ0wrA31dp+VlY86AhttZdUGrbQUpf7x5WRxpSyHLoqiKEq9oo6A2gtwKYqi1DOeOAIR2SMib4vIMRH5shdlKKbelCEVRVGWk2V3BCISBP4F+HXgKuAOEblquctRjMZmK4rSyHjRI/gocMwY854xJg18G9jrQTnmaCTdcUVRlFK8cAT9wKmi/dP2Mc+odYILRVGUesaL8FGnHF4LVrWJyN3A3QCDg4O1LpOGOSqK0rB40SM4DRTrOw8AZ0pPMsY8ZIzZbozZ3t3dvWyFUxRFaTS8cASvAJtEZIOIRIDfBp7xoByKoigKHgwNGWOyIvJF4HkgCOwzxryx3OVQFEVRLDyRmDDGPAc858VnK4qiKPPRlcWKoigNzoqQoRaRc8DJS5y2Gji/DMWpJ9TmxkBt9j+1snedMeaS0TYrwhEsBhEZXozutp9QmxsDtdn/eG2vDg0piqI0OOoIFEVRGhw/OYKHvC6AB6jNjYHa7H88tdc3cwSKoijK0vBTj0BRFEVZAr5wBPWW6KYWiMg+ETkrIkeKjnWKyAERecf+u8rLMlYTEVkrIi+IyFEReUNEvmQf97PNURH5HxE5bNv81/bxDSLysm3z47Y0i68QkaCI/FREnrX3fW2ziJwQkZ+LyOsiMmwf8+zZXvGOoB4T3dSIh4E9Jce+DBw0xmwCDtr7fiEL/Jkx5krgBuCP7PvqZ5tTwE3GmG3AtcAeEbkB+DrwT7bNY8BdHpaxVnwJOFq03wg2/6ox5tqisFHPnu0V7wiow0Q3tcAYcwgYLTm8F3jEfv0I8JvLWqgaYowZMca8Zr+ewqok+vG3zcYYM23vhu3NADcB37GP+8pmABEZAH4D+Fd7X/C5zS549mz7wRHUXaKbZaTXGDMCVsUJ9HhcnpogIuuB64CX8bnN9hDJ68BZ4ADwLjBujCnkUvXj8/3PwL1A3t7vwv82G+B7IvKqnXsFPHy2PRGdqzKLSnSjrExEpBV4CvhjY8yk1Vj0L8aYHHCtiMSB7wJXOp22vKWqHSJyG3DWGPOqiOwuHHY41Tc22+w0xpwRkR7ggIi85WVh/NAjWFSiG5/yCxHpA7D/nvW4PFVFRMJYTuCbxpin7cO+trmAMWYceBFrfiQuIoVGm9+e753AJ0XkBNaw7k1YPQQ/24wx5oz99yyWw/8oHj7bfnAEjZzo5hng8/brzwP/4WFZqoo9TvwN4Kgx5oGit/xsc7fdE0BEYsDNWHMjLwC326f5ymZjzF8YYwaMMeuxfrs/MMbciY9tFpEWEWkrvAZuAY7g4bPtiwVlInIrViuikOjmfo+LVHVE5DFgN5ZK4S+AvwL+HXgCGATeBz5ljCmdUF6RiMgu4CXg51wcO/4K1jyBX22+BmuSMIjVSHvCGHOfiFyO1VruBH4KfM4Yk/KupLXBHhr6c2PMbX622bbtu/ZuCPiWMeZ+EenCo2fbF45AURRFWTp+GBpSFEVR/h+oI1AURWlw1BEoiqI0OOoIFEVRGhx1BIqiKA2OOgLFl4hIzlZ2LGw1FfASkU/6VflW8T8aPqr4EhGZNsa0LtNnhYp0cRRlxaE9AqVhEJEOO2/FkL3/mIj8nv16WkT+UUReE5GDItJtH/8lEdlvi4O9JCJX2McfFpEHROQF4Osi8gURedB+r1tEnhKRV+xtp338a2LllXhRRN4TkXuKyvY7IvIzOxfBv5W7jqJUHWOMbrr5bgNywOtF22fs458AfoIlZ7C/6HwD3Gm//irwoP36ILDJfr0DSwIBrPwQzwJBe/8LRf/zLWCX/XoQSyYD4GvAj4EmrBXiF7CkprcAbwOr7fM6y11HN92qvflBfVRRnEgYY64tPWiMOSAin8JKZrSt6K088Lj9+lHgaVv59EbgySLV06ai/3nSWGqhpdwMXFX0P+0FbRngP40llZASkbNAL7b2vjHmvF3G0XLXMVZ+BkWpGuoIlIZCRAJY0s4JLB2b0y6nGqyh03Enh2Iz43I8AHzMGJMo+WywspAVyGH9BgVnmWXH6yhKtdE5AqXR+BMsRc87gH221DVYv4WC2uVngf8yxkwCx+0eBGKxrfSCDnwP+GJhR0TcHEmBg8CnbdExRKRziddRlCWhjkDxK7GS8NG/E5HNwO9i5UJ+CTgE/KV9/gywRURexRqquc8+fidwl4gcBt5gcWlQ7wG225O/bwJ/UO5kY8wbwP3AD+3PKchuV3QdRVkqGj6qKCxvuKmi1BvaI1AURWlwtEegKIrS4GiPQFEUpcFRR6AoitLgqCNQFEVpcNQRKIqiNDjqCBRFURocdQSKoigNzv8BCSTDq+rnufkAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "plt.scatter(wage1.exper, wage1.wage, alpha=0.3)\n",
    "plt.xlabel('Experience')\n",
    "plt.ylabel('Wage')\n",
    "exper_linspace = np.linspace(wage1.exper.min(), wage1.exper.max(), 20)\n",
    "exper_linspace_sq=exper_linspace**2\n",
    "est = smf.ols(formula='wage ~ exper + I(exper**2)', data=wage1).fit()\n",
    "plt.plot(exper_linspace, est.params[0] + est.params[1] * exper_linspace + est.params[2] *exper_linspace_sq , 'r')\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "**Models with Quadratics**\n",
    "\n",
    "- This estimated equation implies that $exper$ has a diminishing effect on wage:\n",
    "    - The first year of experience is worth roughly $30 cent$ per hour (0.298)\n",
    "    - The second year of experience is worth less(about 0.298-2(0.0061)(1)=0.286, or 28.6 cent)\n",
    "    - In going from 10 to 11 years of experience, wage is predicted to increase by about 0.298-2(0.0061)(10)= 0.176\n",
    "    - ....and so on.\n",
    "    \n",
    "    \n",
    "- When the coefficient on $x$ is positive and the coefficient on $x^2$ is negative, the quadratic has a parabolic shape, often called _inverted U-shape_.\n",
    "\n",
    "\n",
    "- There is always a positive value of $x$ where the effect of $x$ on $y$ is zero:\n",
    "    - before this point, $x$ has a positive effect on $y$\n",
    "    - after this point, $x$ has a negative effect on $y$.\n",
    "    \n",
    "    \n",
    "- In practice, it can be important to know where this turning point is.\n",
    "- In the estimated equation with $\\hat{\\beta}_1>0$ and $\\hat{\\beta}_2<0$, the turning point (or maximum of the function) is always achieved at the coefficient on $x$ over _twice_ the absolute value of the coefficient on $x^2$:\n",
    "\n",
    "\\begin{equation*}\n",
    "x^*=|\\hat{\\beta}_1/2\\hat{\\beta}_2)|\n",
    "\\end{equation*}\n",
    "\n",
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "**Quadratic relationship between wage and exper**\n",
    "\n",
    "<br>  \n",
    "\n",
    "\n",
    "<center><img src=\"figs/wool_6_1.png\" width=\"500\"/> \n",
    "    \n",
    "\n",
    "<p>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "**Models with Quadratics**\n",
    "\n",
    "- In the wage example, $x^*=exper^*$  is $0.298/[2(0.0061)]\\approx 24.4$\n",
    "- The return to experience becomes zero at about 24.4 years: What should we make of this?\n",
    "- There are at least three possible explanations.\n",
    "    - First, it may be that few people in the sample have more than 24 years of experience, and so the part of the curve to the right of 24 can be ignored.\n",
    "    - The cost of using a quadratic to capture diminishing effects is that the quadratic must eventually turn around.\n",
    "    - If this point is beyond all but a small percentage of the people in the sample, then this is not of much concern.\n",
    "    - But in the data set WAGE1, about 28% of the people in the sample have more than 24 years of experience; this is too high a percentage to ignore.\n",
    "- It is possible that the return to exper really becomes negative at some point, but it is hard to believe that this happens at 24 years of experience.\n",
    "- A more likely possibility is that the estimated effect of exper on wage is biased because we have controlled for no other factors, or because the functional relationship between wage and exper in equation is not entirely correct. \n",
    "- When a model has a dependent variable in logarithmic form and an explanatory variable entering as a quadratic, some care is needed in reporting the partial effects.\n",
    "- The following example also shows that the quadratic can have a U-shape, rather than a parabolic shape (inverted U-shape). "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "**Example: Effects of Pollution on Housing Prices**\n",
    "\n",
    "<blockquote> Let's modify the housing price example to include a quadratic term in _rooms_:\n",
    "    \n",
    "<br>\n",
    "\n",
    "\\begin{equation*}\n",
    "log(price)=\\beta_0+\\beta_1log(nox)+\\beta_2log(dist)+\\beta_3rooms+\\beta_4rooms^2+u\n",
    "\\end{equation*}\n",
    "\n",
    "What is the interpretation of the effect of rooms on log(price)?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "results.summary(): \n",
      "                            OLS Regression Results                            \n",
      "==============================================================================\n",
      "Dep. Variable:          np.log(price)   R-squared:                       0.603\n",
      "Model:                            OLS   Adj. R-squared:                  0.599\n",
      "Method:                 Least Squares   F-statistic:                     151.8\n",
      "Date:                Wed, 15 Sep 2021   Prob (F-statistic):           7.89e-98\n",
      "Time:                        09:54:45   Log-Likelihood:                -31.806\n",
      "No. Observations:                 506   AIC:                             75.61\n",
      "Df Residuals:                     500   BIC:                             101.0\n",
      "Df Model:                           5                                         \n",
      "Covariance Type:            nonrobust                                         \n",
      "=================================================================================\n",
      "                    coef    std err          t      P>|t|      [0.025      0.975]\n",
      "---------------------------------------------------------------------------------\n",
      "Intercept        13.3855      0.566     23.630      0.000      12.273      14.498\n",
      "np.log(nox)      -0.9017      0.115     -7.862      0.000      -1.127      -0.676\n",
      "np.log(dist)     -0.0868      0.043     -2.005      0.045      -0.172      -0.002\n",
      "rooms            -0.5451      0.165     -3.295      0.001      -0.870      -0.220\n",
      "I(rooms ** 2)     0.0623      0.013      4.862      0.000       0.037       0.087\n",
      "stratio          -0.0476      0.006     -8.129      0.000      -0.059      -0.036\n",
      "==============================================================================\n",
      "Omnibus:                       56.649   Durbin-Watson:                   0.691\n",
      "Prob(Omnibus):                  0.000   Jarque-Bera (JB):              384.168\n",
      "Skew:                          -0.100   Prob(JB):                     3.79e-84\n",
      "Kurtosis:                       7.264   Cond. No.                     2.30e+03\n",
      "==============================================================================\n",
      "\n",
      "Warnings:\n",
      "[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.\n",
      "[2] The condition number is large, 2.3e+03. This might indicate that there are\n",
      "strong multicollinearity or other numerical problems.\n",
      "\n",
      "table: \n",
      "                     b      se        t    pval\n",
      "Intercept      13.3855  0.5665  23.6295  0.0000\n",
      "np.log(nox)    -0.9017  0.1147  -7.8621  0.0000\n",
      "np.log(dist)   -0.0868  0.0433  -2.0051  0.0455\n",
      "rooms          -0.5451  0.1655  -3.2946  0.0011\n",
      "I(rooms ** 2)   0.0623  0.0128   4.8623  0.0000\n",
      "stratio        -0.0476  0.0059  -8.1293  0.0000\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import wooldridge as woo\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import statsmodels.formula.api as smf\n",
    "\n",
    "hprice2 = woo.dataWoo('hprice2')\n",
    "\n",
    "reg = smf.ols(\n",
    "    formula='np.log(price) ~ np.log(nox)+np.log(dist)+rooms+I(rooms**2)+stratio',\n",
    "    data=hprice2)\n",
    "results = reg.fit()\n",
    "\n",
    "print(f'results.summary(): \\n{results.summary()}\\n')\n",
    "\n",
    "# print regression table:\n",
    "table = pd.DataFrame({'b': round(results.params, 4),\n",
    "                      'se': round(results.bse, 4),\n",
    "                      't': round(results.tvalues, 4),\n",
    "                      'pval': round(results.pvalues, 4)})\n",
    "print(f'table: \\n{table}\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "- Initially, the effect appears to be strange: Because the coefficient on rooms is negative and the coefficient on rooms$^2$ is positive, this equation literally implies that, at low values of rooms, an additional room has a negative effect on log(price).\n",
    "- At some point, the effect becomes positive, and the quadratic shape means that the semi-elasticity of price with respect to rooms is increasing as rooms increases.\n",
    "- We obtain the turnaround value of rooms: The absolute value of the coefficient on $rooms$, 0.545, divided by twice the coefficient on $rooms^2$, 0.062, gives $rooms^*=0.545/2(0.062)=4.4$ \n",
    "- Do we really believe that starting at three rooms and increasing to four rooms actually reduces a house’s expected value?\n",
    "- Let's have a look at the data:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.01    4.5255\n",
       "0.05    5.3100\n",
       "0.10    5.5900\n",
       "0.25    5.8825\n",
       "0.50    6.2100\n",
       "0.75    6.6200\n",
       "0.90    7.1500\n",
       "0.99    8.3380\n",
       "Name: rooms, dtype: float64"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "5"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import wooldridge as woo\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "\n",
    "hprice2 = woo.dataWoo('hprice2')\n",
    "\n",
    "\n",
    "#display(hprice2.loc[hprice2['rooms']<4.4,'rooms'].describe())\n",
    "\n",
    "# calculate quantiles for room\n",
    "display(hprice2['rooms'].quantile([.01, 0.05, 0.1, .25, .5, .75, .9, .99 ]))\n",
    "\n",
    "#display a histogram for room\n",
    "plt.hist(hprice2['rooms'], bins=25)\n",
    "display((hprice2['rooms']<4.4).sum())\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "**Models with Quadratics**\n",
    "\n",
    "- only 5 of the 506 communities in the sample have houses averaging 4.4 rooms or less ($<$ 1% of the sample).\n",
    "- Very small value: we can ignore the quadratic to the left of 4.4.\n",
    "- Thus: for more representative occurences of rooms in the data the effect is increasing: for an increase from 5 to 6 rooms the price increases about .54.5+12.4(5)=7.5%, for an increase from 6 to 7 rooms, prices increase even about -54.5+12.4(6)=19.9%\n",
    "- The strong increasing effect of rooms on log(price) in this example illustrates an important lesson: one cannot simply look at the coefficient on the quadratic term—in this case, .062—and declare that it is too small to bother with, based only on its magnitude.\n",
    "- In many applications with quadratics the coefficient on the squared variable has one or more zeros after the decimal point: after all, this coefficient measures how the slope is changing as x (rooms) changes.\n",
    "- A seemingly small coefficient can have practically important consequences, as we just saw.\n",
    "- As a general rule, one must compute the partial effect and see how it varies with x to determine if the quadratic term is practically important."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "**Models with Interaction Terms**\n",
    "\n",
    "- Sometimes, it is natural for the partial effect, elasticity, or semi-elasticity of the dependent variable with respect to an explanatory variable to depend on the magnitude of yet another explanatory variable.\n",
    "- For example, in the model\n",
    "\n",
    "\\begin{equation*}\n",
    "price=\\beta_0+\\beta_1sqrft+\\beta_2bdrms+\\beta_3sqrft\\cdot bdrms+\\beta_4bthrms+u,\n",
    "\\end{equation*}\n",
    "\n",
    "the partial effect of bdrms on price (holding all other variables fixed) is\n",
    "\n",
    "\\begin{equation*}\n",
    "\\frac{\\Delta price}{\\Delta bdrms}=\\beta_2+\\beta_3sqrft.\n",
    "\\end{equation*}\n",
    "\n",
    "- If $\\beta_3>0$, then this implies that an additional bedroom yields a higher increase in housing price for larger houses.\n",
    "- In other words, there is an **interaction effect** between square footage and number of bedrooms.\n",
    "- In summarizing the effect of bdrms on price, we must evaluate the regression at interesting values of sqrft, such as the mean value, or the lower and upper quartiles in the sample.\n",
    "- Whether or not $\\beta_3$ is zero is something we can easily test.\n",
    "- The parameters on the original variables can be tricky to interpret when we include an interaction term.\n",
    "- For example, in the previous housing price equation, $\\beta_2$ is the effect of bdrms on price for a home with zero square feet, which is clearly not of much interest.\n",
    "- Instead, we must be careful to put interesting values of sqrft, such as the mean or median values in the sample, into the estimated version of housing price equation."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "**Computing Average Partial Effects**\n",
    "\n",
    "- The hallmark of models with quadratics, interactions, and other nonlinear functional forms is that the partial effects depend on the values of one or more explanatory variables.\n",
    "- For example, we just saw in the housing price example that the effect of bdrms depends on the value of sqrft.\n",
    "- The higher flexibility afforded by such a model does have a cost: it is tricky to describe the partial effects of the explanatory variables on price with a single number.\n",
    "- Often, one wants a single value to describe the relationship between the dependent variable y and each explanatory variable.\n",
    "- Popular summary measure is the **average partial effect (APE)**, also called the **average marginal effect**.\n",
    "- Idea behind the APE is simple: after computing the partial effect and plugging in the estimated parameters, we average the partial effects for each unit across the sample.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "**Computing Average Partial Effects**\n",
    "\n",
    "\n",
    "- The estimated partial effect of bdrms on price is\n",
    "\n",
    "\\begin{equation*}\n",
    "\\hat{\\beta}_2+\\hat{\\beta}_3sqft\n",
    "\\end{equation*}\n",
    "\n",
    "- We do not want to report this partial effect for each of houses in our sample, instead, we average these partial effects to obtain\n",
    "\n",
    "\n",
    "\\begin{equation*}\n",
    "APE_{price}=\\hat{\\beta}_2+\\hat{\\beta}_3\\bar{sqft}\n",
    "\\end{equation*}\n",
    "\n",
    "where $\\bar{sqft}$ is the sample average of sqft and $APE_{price}$ is the estimated APE.\n",
    "\n",
    "- The centering of explanatory variables about their sample averages before creating quadratics or interactions forces the coefficient on the levels to be the APEs.\n",
    "- However, usually we are not interested in interactions of contiuous variables but rather in interactions of a binary variable and a continuous variable or even between two binary variables. We will analyze such cases in a few minutes in detail and with data examples."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Prediction\n",
    "\n",
    "\n",
    "In models with quadratic or other nonlinear terms, the coefficients themselves are often difficult to interpret directly.\n",
    "- We have to do additional calculations to obtain the partial effect at different values of the regressors or derive the extreme points.\n",
    "- E.g, we found the number of rooms implying the minimum predicted house price to be around 4.4.\n",
    "\n",
    "For a better visual understanding of the implications of our model: often useful to calculate predictions for different values of one regressor of interest while keeping the other regressors fixed at certain values like their overall sample means.\n",
    "- By plotting the results against the regressor value, we get a very intuitive graph showing the estimated ceteris paribus effects of the regressor.\n",
    "- For instance, assume we have model \n",
    "\n",
    "\\begin{equation*}\n",
    "y=\\beta_0+\\beta_1x_1+\\beta_2x+...+\\beta_kx_k+u\n",
    "\\end{equation*}\n",
    "\n",
    "and we are interested in the expected value of $y$ given the regressors take specific values $c_1,c_2,...,c_k:$\n",
    "\n",
    "\\begin{equation*}\n",
    "\\theta_0=E(y|x_1=c_1,x_2=c_2,...,x_k=c_k)=\\beta_0+\\beta_1c_1+\\beta_2c_2+...+\\beta_kc_k\n",
    "\\end{equation*}\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    " **Prediction**\n",
    "\n",
    "    \n",
    "The natural point estimates are \n",
    "\n",
    "\\begin{equation*}\n",
    "\\hat{\\theta}_0=\\hat{\\beta}_0+\\hat{\\beta}_1c_1+\\hat{\\beta}_2c_2+...+\\hat{\\beta}_kc_k\n",
    "\\end{equation*}\n",
    "\n",
    "and can readily be obtained once the parameter estimates $\\hat{\\beta}_0,...,\\hat{\\beta}_k$  are calculated.\n",
    "- `statsmodels` provides the method `predict` for this.\n",
    "- The method `predict` automatically calculates the $\\hat{\\theta}_0$s and can be called on an object created by the `fit` method.\n",
    "- Its argument is a data frame containing the values of the regressorsv $c_1,...,c_x$ of the regressors $x_1,..., x_k$ with the same variable names as in the data frame used for estimation.\n",
    "- It can for example be specified with `pandas` as\n",
    "\n",
    "```python\n",
    "pd.DataFrame({'x':[c1], 'x2':[c2],...,'xk':[ck]}, index=['newobservation1'])\n",
    "```                                                        \n",
    "where $x_1$ through $x_k$ are the variable names and $c_1$ through $c_k$ are the values which can also be specified as lists to get predictions at several values of the regressors.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "**Prediction**\n",
    "\n",
    "- Let's check this for the housing price example\n",
    "- The number of rooms is varied between 4 and 8 and the other variables are set to their respective sample means for all predictions.\n",
    "- The regressor values and the implied predictions are shown in a table and then plotted with their confidence bands.\n",
    "- We see the minimum at a number of rooms of around 5.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "results.summary(): \n",
      "                            OLS Regression Results                            \n",
      "==============================================================================\n",
      "Dep. Variable:                  price   R-squared:                       0.681\n",
      "Model:                            OLS   Adj. R-squared:                  0.677\n",
      "Method:                 Least Squares   F-statistic:                     213.1\n",
      "Date:                Wed, 15 Sep 2021   Prob (F-statistic):          2.00e-121\n",
      "Time:                        10:46:42   Log-Likelihood:                -5047.4\n",
      "No. Observations:                 506   AIC:                         1.011e+04\n",
      "Df Residuals:                     500   BIC:                         1.013e+04\n",
      "Df Model:                           5                                         \n",
      "Covariance Type:            nonrobust                                         \n",
      "=================================================================================\n",
      "                    coef    std err          t      P>|t|      [0.025      0.975]\n",
      "---------------------------------------------------------------------------------\n",
      "Intercept      1.204e+05    1.1e+04     10.980      0.000    9.88e+04    1.42e+05\n",
      "nox           -3086.4562    324.510     -9.511      0.000   -3724.027   -2448.886\n",
      "dist           -723.5110    177.429     -4.078      0.000   -1072.109    -374.913\n",
      "rooms         -2.499e+04   3279.794     -7.620      0.000   -3.14e+04   -1.85e+04\n",
      "I(rooms ** 2)  2477.3037    253.874      9.758      0.000    1978.512    2976.095\n",
      "stratio       -1082.8905    118.400     -9.146      0.000   -1315.514    -850.267\n",
      "==============================================================================\n",
      "Omnibus:                      262.203   Durbin-Watson:                   0.848\n",
      "Prob(Omnibus):                  0.000   Jarque-Bera (JB):             3657.109\n",
      "Skew:                           1.911   Prob(JB):                         0.00\n",
      "Kurtosis:                      15.604   Cond. No.                     2.24e+03\n",
      "==============================================================================\n",
      "\n",
      "Warnings:\n",
      "[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.\n",
      "[2] The condition number is large, 2.24e+03. This might indicate that there are\n",
      "strong multicollinearity or other numerical problems.\n",
      "\n",
      "means: \n",
      "   rooms       nox      dist    stratio\n",
      "0    4.0  5.549783  3.795751  18.459289\n",
      "1    5.0  5.549783  3.795751  18.459289\n",
      "2    6.0  5.549783  3.795751  18.459289\n",
      "3    7.0  5.549783  3.795751  18.459289\n",
      "4    8.0  5.549783  3.795751  18.459289\n",
      "\n",
      " pred: \n",
      "0    20186.441146\n",
      "1    17489.067803\n",
      "2    19746.301769\n",
      "3    26958.143044\n",
      "4    39124.591629\n",
      "dtype: float64\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x1a3c6196cc0>]"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import wooldridge as woo\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import statsmodels.formula.api as smf\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "hprice2 = woo.dataWoo('hprice2')\n",
    "\n",
    "# repeating the regression from before:\n",
    "reg = smf.ols(\n",
    "    formula='price ~ nox+dist+rooms+I(rooms**2)+stratio',\n",
    "    data=hprice2)\n",
    "results = reg.fit()\n",
    "\n",
    "print(f'results.summary(): \\n{results.summary()}\\n')\n",
    "\n",
    "# predictions with rooms = 4-8, all others at the sample mean:\n",
    "nox_mean = np.mean(hprice2['nox'])\n",
    "dist_mean = np.mean(hprice2['dist'])\n",
    "stratio_mean = np.mean(hprice2['stratio'])\n",
    "means = pd.DataFrame({'rooms': np.linspace(4, 8, num=5),\n",
    "                  'nox': nox_mean,\n",
    "                  'dist': dist_mean,\n",
    "                  'stratio': stratio_mean})\n",
    "print(f'means: \\n{means}\\n')\n",
    "\n",
    "# point estimate of prediction (means):\n",
    "pred = results.predict (means)\n",
    "print (f' pred: \\n{pred}\\n' )\n",
    "\n",
    "plt.plot(means['rooms'], pred, color='black',\n",
    "        linestyle='-', label='')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "**Prediction**\n",
    "\n",
    "- The method `get_prediction` calculates not only $\\hat{\\theta}_0$ (i.e. the exact same predictions as the method `predict`), but also\n",
    "    - standard errors of the predictions (column `mean_se`),\n",
    "    - confidence intervals (columns `mean_ci_lower` and `mean_ci_upper`) and\n",
    "    - prediction intervals (columns `obs_ci_lower` and `obs_ci_upper`).\n",
    "- All you have to do is calling a second method `summary_frame` to provide the significance level.\n",
    "- Let's repeat the housing price regression and create an effects plot for the number of rooms.\n",
    "- Just to compare the results we use logs here\n",
    "- As you see, the minimum is now at 4 instead of 5."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "lpr_CI: \n",
      "        mean  mean_ci_lower  mean_ci_upper\n",
      "0   9.661702       9.499811       9.823593\n",
      "1   9.676940       9.610215       9.743665\n",
      "2   9.816700       9.787055       9.846345\n",
      "3  10.080983      10.042409      10.119557\n",
      "4  10.469788      10.383361      10.556215\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<matplotlib.legend.Legend at 0x1a3c615a5f8>"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import wooldridge as woo\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import statsmodels.formula.api as smf\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "hprice2 = woo.dataWoo('hprice2')\n",
    "\n",
    "# repeating the regression from Example 6.2:\n",
    "reg = smf.ols(\n",
    "    formula='np.log(price) ~ np.log(nox)+np.log(dist)+rooms+I(rooms**2)+stratio',\n",
    "    data=hprice2)\n",
    "results = reg.fit()\n",
    "\n",
    "#print(f'results.summary(): \\n{results.summary()}\\n')\n",
    "\n",
    "# predictions with rooms = 4-8, all others at the sample mean:\n",
    "nox_mean = np.mean(hprice2['nox'])\n",
    "dist_mean = np.mean(hprice2['dist'])\n",
    "stratio_mean = np.mean(hprice2['stratio'])\n",
    "X = pd.DataFrame({'rooms': np.linspace(4, 8, num=5),\n",
    "                  'nox': nox_mean,\n",
    "                  'dist': dist_mean,\n",
    "                  'stratio': stratio_mean})\n",
    "#print(f'X: \\n{X}\\n')\n",
    "\n",
    "# calculate 95% confidence interval:\n",
    "lpr_PICI = results.get_prediction(X).summary_frame(alpha=0.05)\n",
    "lpr_CI = lpr_PICI[['mean', 'mean_ci_lower', 'mean_ci_upper']]\n",
    "print(f'lpr_CI: \\n{lpr_CI}\\n')\n",
    "\n",
    "# plot:\n",
    "plt.plot(X['rooms'], lpr_CI['mean'], color='black',\n",
    "         linestyle='-', label='')\n",
    "plt.plot(X['rooms'], lpr_CI['mean_ci_upper'], color='lightgrey',\n",
    "         linestyle='--', label='upper CI')\n",
    "plt.plot(X['rooms'], lpr_CI['mean_ci_lower'], color='darkgrey',\n",
    "         linestyle='--', label='lower CI')\n",
    "plt.ylabel('lprice')\n",
    "plt.xlabel('rooms')\n",
    "plt.legend()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "<h3>Multiple Regression Analysis with\n",
    "Qualitative Regressors</h3>\n",
    "    \n",
    "- Many variables of interest are qualitative rather than quantitative.\n",
    "- Examples include gender or race of an individual, the industry of a firm (manufacturing, retail, and so on), and the region in the United States where a city is located (South, North, West, and so on)\n",
    "- We have briefly touched this topic already and will discuss it now in more detail."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "**Describing Qualitative Information**\n",
    "\n",
    "- Qualitative factors often come in the form of binary information:\n",
    "    - a person is female or male\n",
    "    - a person does or does not own a personal computer;\n",
    "    - a firm offers a certain kind of employee pension plan or it does not;\n",
    "    - a state administers capital punishment or it does not.\n",
    "- In all of these examples, the relevant information can be captured by defining a **binary variable** or a **zero-one variable**.\n",
    "- In econometrics, binary variables are most commonly called **dummy variables**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "**Describing Qualitative Information**\n",
    "\n",
    "- In defining a dummy variable, we must decide which event is assigned the value one and which is assigned the value zero.\n",
    "- For example, in a study of individual wage determination, we might define _female_ to be a binary variable taking on the value one for females and the value zero for males.\n",
    "- The name in this case indicates the event with the value one.\n",
    "- The same information is captured by defining _male_ to be one if the person is male and zero if the person is female.\n",
    "- Either of these is better than using _gender_ because this name does not make it clear when the dummy variable is one: does $gender=1$ correspond to male or female?\n",
    "- What we call our variables is unimportant for getting regression results, but it always helps to choose names that clarify equations and expositions.\n",
    "- Why do we use the values zero and one to describe qualitative information? In a sense, these values are arbitrary: any two different values would do.\n",
    "- The real benefit of capturing qualitative information using zero-one variables is that it leads to regression models where the parameters have very natural interpretations, as we will see now.\n",
    "- Let's check the _wage_ data and have a look at _female_, _married_ and _nonwhite_."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>wage</th>\n",
       "      <th>educ</th>\n",
       "      <th>exper</th>\n",
       "      <th>tenure</th>\n",
       "      <th>nonwhite</th>\n",
       "      <th>female</th>\n",
       "      <th>married</th>\n",
       "      <th>numdep</th>\n",
       "      <th>smsa</th>\n",
       "      <th>northcen</th>\n",
       "      <th>...</th>\n",
       "      <th>trcommpu</th>\n",
       "      <th>trade</th>\n",
       "      <th>services</th>\n",
       "      <th>profserv</th>\n",
       "      <th>profocc</th>\n",
       "      <th>clerocc</th>\n",
       "      <th>servocc</th>\n",
       "      <th>lwage</th>\n",
       "      <th>expersq</th>\n",
       "      <th>tenursq</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>3.10</td>\n",
       "      <td>11</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1.131402</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>3.24</td>\n",
       "      <td>12</td>\n",
       "      <td>22</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1.175573</td>\n",
       "      <td>484</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3.00</td>\n",
       "      <td>11</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1.098612</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>6.00</td>\n",
       "      <td>8</td>\n",
       "      <td>44</td>\n",
       "      <td>28</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1.791759</td>\n",
       "      <td>1936</td>\n",
       "      <td>784</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5.30</td>\n",
       "      <td>12</td>\n",
       "      <td>7</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1.667707</td>\n",
       "      <td>49</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 24 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   wage  educ  exper  tenure  nonwhite  female  married  numdep  smsa  \\\n",
       "0  3.10    11      2       0         0       1        0       2     1   \n",
       "1  3.24    12     22       2         0       1        1       3     1   \n",
       "2  3.00    11      2       0         0       0        0       2     0   \n",
       "3  6.00     8     44      28         0       0        1       0     1   \n",
       "4  5.30    12      7       2         0       0        1       1     0   \n",
       "\n",
       "   northcen   ...     trcommpu  trade  services  profserv  profocc  clerocc  \\\n",
       "0         0   ...            0      0         0         0        0        0   \n",
       "1         0   ...            0      0         1         0        0        0   \n",
       "2         0   ...            0      1         0         0        0        0   \n",
       "3         0   ...            0      0         0         0        0        1   \n",
       "4         0   ...            0      0         0         0        0        0   \n",
       "\n",
       "   servocc     lwage  expersq  tenursq  \n",
       "0        0  1.131402        4        0  \n",
       "1        1  1.175573      484        4  \n",
       "2        0  1.098612        4        0  \n",
       "3        0  1.791759     1936      784  \n",
       "4        0  1.667707       49        4  \n",
       "\n",
       "[5 rows x 24 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>wage</th>\n",
       "      <th>educ</th>\n",
       "      <th>exper</th>\n",
       "      <th>tenure</th>\n",
       "      <th>nonwhite</th>\n",
       "      <th>female</th>\n",
       "      <th>married</th>\n",
       "      <th>numdep</th>\n",
       "      <th>smsa</th>\n",
       "      <th>northcen</th>\n",
       "      <th>...</th>\n",
       "      <th>trcommpu</th>\n",
       "      <th>trade</th>\n",
       "      <th>services</th>\n",
       "      <th>profserv</th>\n",
       "      <th>profocc</th>\n",
       "      <th>clerocc</th>\n",
       "      <th>servocc</th>\n",
       "      <th>lwage</th>\n",
       "      <th>expersq</th>\n",
       "      <th>tenursq</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>521</th>\n",
       "      <td>15.00</td>\n",
       "      <td>16</td>\n",
       "      <td>14</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2.708050</td>\n",
       "      <td>196</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>522</th>\n",
       "      <td>2.27</td>\n",
       "      <td>10</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.819780</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>523</th>\n",
       "      <td>4.67</td>\n",
       "      <td>15</td>\n",
       "      <td>13</td>\n",
       "      <td>18</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1.541159</td>\n",
       "      <td>169</td>\n",
       "      <td>324</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>524</th>\n",
       "      <td>11.56</td>\n",
       "      <td>16</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2.447551</td>\n",
       "      <td>25</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>525</th>\n",
       "      <td>3.50</td>\n",
       "      <td>14</td>\n",
       "      <td>5</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1.252763</td>\n",
       "      <td>25</td>\n",
       "      <td>16</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 24 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      wage  educ  exper  tenure  nonwhite  female  married  numdep  smsa  \\\n",
       "521  15.00    16     14       2         0       1        1       2     0   \n",
       "522   2.27    10      2       0         0       1        0       3     0   \n",
       "523   4.67    15     13      18         0       0        1       3     0   \n",
       "524  11.56    16      5       1         0       0        1       0     0   \n",
       "525   3.50    14      5       4         1       1        0       2     0   \n",
       "\n",
       "     northcen   ...     trcommpu  trade  services  profserv  profocc  clerocc  \\\n",
       "521         0   ...            0      0         0         1        1        0   \n",
       "522         0   ...            0      1         0         0        1        0   \n",
       "523         0   ...            0      0         0         0        1        0   \n",
       "524         0   ...            0      0         0         0        0        0   \n",
       "525         0   ...            0      0         0         1        0        1   \n",
       "\n",
       "     servocc     lwage  expersq  tenursq  \n",
       "521        0  2.708050      196        4  \n",
       "522        0  0.819780        4        0  \n",
       "523        0  1.541159      169      324  \n",
       "524        0  2.447551       25        1  \n",
       "525        0  1.252763       25       16  \n",
       "\n",
       "[5 rows x 24 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>wage</th>\n",
       "      <th>educ</th>\n",
       "      <th>exper</th>\n",
       "      <th>tenure</th>\n",
       "      <th>nonwhite</th>\n",
       "      <th>female</th>\n",
       "      <th>married</th>\n",
       "      <th>numdep</th>\n",
       "      <th>smsa</th>\n",
       "      <th>northcen</th>\n",
       "      <th>...</th>\n",
       "      <th>trcommpu</th>\n",
       "      <th>trade</th>\n",
       "      <th>services</th>\n",
       "      <th>profserv</th>\n",
       "      <th>profocc</th>\n",
       "      <th>clerocc</th>\n",
       "      <th>servocc</th>\n",
       "      <th>lwage</th>\n",
       "      <th>expersq</th>\n",
       "      <th>tenursq</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>526.000000</td>\n",
       "      <td>526.000000</td>\n",
       "      <td>526.00000</td>\n",
       "      <td>526.000000</td>\n",
       "      <td>526.000000</td>\n",
       "      <td>526.000000</td>\n",
       "      <td>526.000000</td>\n",
       "      <td>526.000000</td>\n",
       "      <td>526.000000</td>\n",
       "      <td>526.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>526.000000</td>\n",
       "      <td>526.000000</td>\n",
       "      <td>526.000000</td>\n",
       "      <td>526.000000</td>\n",
       "      <td>526.000000</td>\n",
       "      <td>526.000000</td>\n",
       "      <td>526.000000</td>\n",
       "      <td>526.000000</td>\n",
       "      <td>526.000000</td>\n",
       "      <td>526.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>5.896103</td>\n",
       "      <td>12.562738</td>\n",
       "      <td>17.01711</td>\n",
       "      <td>5.104563</td>\n",
       "      <td>0.102662</td>\n",
       "      <td>0.479087</td>\n",
       "      <td>0.608365</td>\n",
       "      <td>1.043726</td>\n",
       "      <td>0.722433</td>\n",
       "      <td>0.250951</td>\n",
       "      <td>...</td>\n",
       "      <td>0.043726</td>\n",
       "      <td>0.287072</td>\n",
       "      <td>0.100760</td>\n",
       "      <td>0.258555</td>\n",
       "      <td>0.366920</td>\n",
       "      <td>0.167300</td>\n",
       "      <td>0.140684</td>\n",
       "      <td>1.623268</td>\n",
       "      <td>473.435361</td>\n",
       "      <td>78.150190</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>3.693086</td>\n",
       "      <td>2.769022</td>\n",
       "      <td>13.57216</td>\n",
       "      <td>7.224462</td>\n",
       "      <td>0.303805</td>\n",
       "      <td>0.500038</td>\n",
       "      <td>0.488580</td>\n",
       "      <td>1.261891</td>\n",
       "      <td>0.448225</td>\n",
       "      <td>0.433973</td>\n",
       "      <td>...</td>\n",
       "      <td>0.204680</td>\n",
       "      <td>0.452826</td>\n",
       "      <td>0.301298</td>\n",
       "      <td>0.438257</td>\n",
       "      <td>0.482423</td>\n",
       "      <td>0.373599</td>\n",
       "      <td>0.348027</td>\n",
       "      <td>0.531538</td>\n",
       "      <td>616.044772</td>\n",
       "      <td>199.434664</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>0.530000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.00000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-0.634878</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>3.330000</td>\n",
       "      <td>12.000000</td>\n",
       "      <td>5.00000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.202972</td>\n",
       "      <td>25.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>4.650000</td>\n",
       "      <td>12.000000</td>\n",
       "      <td>13.50000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.536867</td>\n",
       "      <td>182.500000</td>\n",
       "      <td>4.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>6.880000</td>\n",
       "      <td>14.000000</td>\n",
       "      <td>26.00000</td>\n",
       "      <td>7.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.750000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.928619</td>\n",
       "      <td>676.000000</td>\n",
       "      <td>49.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>24.980000</td>\n",
       "      <td>18.000000</td>\n",
       "      <td>51.00000</td>\n",
       "      <td>44.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>6.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>3.218076</td>\n",
       "      <td>2601.000000</td>\n",
       "      <td>1936.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>8 rows × 24 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "             wage        educ      exper      tenure    nonwhite      female  \\\n",
       "count  526.000000  526.000000  526.00000  526.000000  526.000000  526.000000   \n",
       "mean     5.896103   12.562738   17.01711    5.104563    0.102662    0.479087   \n",
       "std      3.693086    2.769022   13.57216    7.224462    0.303805    0.500038   \n",
       "min      0.530000    0.000000    1.00000    0.000000    0.000000    0.000000   \n",
       "25%      3.330000   12.000000    5.00000    0.000000    0.000000    0.000000   \n",
       "50%      4.650000   12.000000   13.50000    2.000000    0.000000    0.000000   \n",
       "75%      6.880000   14.000000   26.00000    7.000000    0.000000    1.000000   \n",
       "max     24.980000   18.000000   51.00000   44.000000    1.000000    1.000000   \n",
       "\n",
       "          married      numdep        smsa    northcen     ...       \\\n",
       "count  526.000000  526.000000  526.000000  526.000000     ...        \n",
       "mean     0.608365    1.043726    0.722433    0.250951     ...        \n",
       "std      0.488580    1.261891    0.448225    0.433973     ...        \n",
       "min      0.000000    0.000000    0.000000    0.000000     ...        \n",
       "25%      0.000000    0.000000    0.000000    0.000000     ...        \n",
       "50%      1.000000    1.000000    1.000000    0.000000     ...        \n",
       "75%      1.000000    2.000000    1.000000    0.750000     ...        \n",
       "max      1.000000    6.000000    1.000000    1.000000     ...        \n",
       "\n",
       "         trcommpu       trade    services    profserv     profocc     clerocc  \\\n",
       "count  526.000000  526.000000  526.000000  526.000000  526.000000  526.000000   \n",
       "mean     0.043726    0.287072    0.100760    0.258555    0.366920    0.167300   \n",
       "std      0.204680    0.452826    0.301298    0.438257    0.482423    0.373599   \n",
       "min      0.000000    0.000000    0.000000    0.000000    0.000000    0.000000   \n",
       "25%      0.000000    0.000000    0.000000    0.000000    0.000000    0.000000   \n",
       "50%      0.000000    0.000000    0.000000    0.000000    0.000000    0.000000   \n",
       "75%      0.000000    1.000000    0.000000    1.000000    1.000000    0.000000   \n",
       "max      1.000000    1.000000    1.000000    1.000000    1.000000    1.000000   \n",
       "\n",
       "          servocc       lwage      expersq      tenursq  \n",
       "count  526.000000  526.000000   526.000000   526.000000  \n",
       "mean     0.140684    1.623268   473.435361    78.150190  \n",
       "std      0.348027    0.531538   616.044772   199.434664  \n",
       "min      0.000000   -0.634878     1.000000     0.000000  \n",
       "25%      0.000000    1.202972    25.000000     0.000000  \n",
       "50%      0.000000    1.536867   182.500000     4.000000  \n",
       "75%      0.000000    1.928619   676.000000    49.000000  \n",
       "max      1.000000    3.218076  2601.000000  1936.000000  \n",
       "\n",
       "[8 rows x 24 columns]"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import wooldridge as woo\n",
    "import statsmodels.formula.api as smf\n",
    "import scipy.stats as stats\n",
    "\n",
    "wage1 = woo.dataWoo('wage1')\n",
    "display(wage1.head())\n",
    "display(wage1.tail())\n",
    "wage1.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "**A Single Dummy Independent Variable**\n",
    "\n",
    "- How do we incorporate binary information into regression models?\n",
    "- In the simplest case, with only a single dummy explanatory variable, we just add it as an independent variable in the equation.\n",
    "- For example, consider the following simple model of hourly wage determination:\n",
    "\n",
    "\\begin{equation*}\n",
    "wage=\\beta_0+\\delta_0female+\\beta_1educ+u\n",
    "\\end{equation*}\n",
    "\n",
    "- In this model, only two observed factors affect wage: _gender_ and _education_.\n",
    "- Because _female=1_ when the person is female, and _female=0_ when the person is male, the parameter $\\delta$ has the following interpretation: $\\delta_0$ is the difference in hourly wage between females and males, given the same amount of education (and the same error term $u$).\n",
    "- Thus, the coefficient $\\delta_0$ determines whether there is discrimination against women: if $\\delta_0<0$, then for the same level of other factors, women earn less than men on average.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "**A Single Dummy Independent Variable**\n",
    "\n",
    "- In terms of expectations, if we assume the zero conditional mean assumption $E(u|femal, educ)=0$, then \n",
    "\n",
    "\\begin{equation*}\n",
    "\\delta_0=E(wage|female=1,edu)-E(wage|female=0, educ)\n",
    "\\end{equation*}\n",
    "\n",
    "- Because $female=1$ correspnds to females and $female=0$ corresponds to males, we can write this more simply as\n",
    "\n",
    "\\begin{equation*}\n",
    "\\delta_0=E(wage|female,edu)-E(wage|male, educ)\n",
    "\\end{equation*}\n",
    "\n",
    "- The key here is that the level of education is the same in both expectations; the difference, $\\delta_0$, is due to gender only.\n",
    "- The situation can be depicted graphically as an **intercept shift** between males and females.\n",
    "- In the next figure the case $\\delta_0<0$ is shown, so that men earn a fixed amount more per hour than women.\n",
    "- The difference does not depend on the amount of education, and this explains why the wage-education profiles for women and men are parallel.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "**Graph of $wage=\\beta_0+\\delta_0female+\\beta_1educ$ for $\\delta_0<0$**\n",
    "\n",
    "<br>  \n",
    "\n",
    "\n",
    "<center><img src=\"figs/wool_7_1.png\" width=\"500\"/> \n",
    "    \n",
    "\n",
    "<p>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "But why we do not also include a dummy variable, say male, which is one for males and zero for females?\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "- This would be redundant: The intercept for males is $\\beta_0$, and the intercept for females is $\\beta_0+\\delta_0$.\n",
    "- Because there are just two groups, we only need two different intercepts.\n",
    "- This means that, in addition to $\\beta_0$, we need to use only one dummy variable; we have chosen to include the dummy variable for females.\n",
    "- Using two dummy variables would introduce perfect collinearity because _female+male=1_, which means that male is a perfect linear function of female.\n",
    "- Including dummy variables for both genders is the simplest example of the so-called **dummy variable trap**, which arises when too many dummy variables describe a given number of groups.\n",
    "- In the example we have chosen _males_ to be the **base group** or **benchmark group**, that is, the group against which comparisons are made.\n",
    "- This is why $\\beta_0$ is the intercept for males, and $\\delta_0$ is the difference in intercepts between females and males.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "- We could choose males as the base group by writing the model as\n",
    "\n",
    "\\begin{equation*}\n",
    "wage=\\alpha_0+\\gamma_0male+\\beta_1educ+u\n",
    "\\end{equation*},\n",
    "\n",
    "where the intercept for females is $\\beta_0$ and the intercept for males is $\\alpha_0+\\gamma_0$\n",
    "- In any application, it does not matter how we choose the base group, but it is important to keep track of which group is the base group."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "**Describing Qualitative Information**\n",
    "\n",
    "- The qualitative variables in the _wage_ dataset are already coded as binary variables\n",
    "- This is not always the case, sometimes they are also coded as **boolean variables** (with values `True` and `False`)\n",
    "- Sometimes there are also coded as string variables \n",
    "- However, you can easily switch back and forth between data types:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "wage        float64\n",
      "educ          int64\n",
      "exper         int64\n",
      "tenure        int64\n",
      "nonwhite      int64\n",
      "female        int64\n",
      "married       int64\n",
      "numdep        int64\n",
      "smsa          int64\n",
      "northcen      int64\n",
      "south         int64\n",
      "west          int64\n",
      "construc      int64\n",
      "ndurman       int64\n",
      "trcommpu      int64\n",
      "trade         int64\n",
      "services      int64\n",
      "profserv      int64\n",
      "profocc       int64\n",
      "clerocc       int64\n",
      "servocc       int64\n",
      "lwage       float64\n",
      "expersq       int64\n",
      "tenursq       int64\n",
      "female1        bool\n",
      "female2       int32\n",
      "female3      object\n",
      "female4      object\n",
      "female5        bool\n",
      "dtype: object\n"
     ]
    }
   ],
   "source": [
    "import wooldridge as woo\n",
    "import statsmodels.formula.api as smf\n",
    "import scipy.stats as stats\n",
    "import pandas as pd\n",
    "\n",
    "wage1 = woo.dataWoo('wage1')\n",
    "\n",
    "#transform female into boolean variable\n",
    "wage1['female1'] = wage1['female'].astype('bool') \n",
    "\n",
    "#transform female back into integer variable\n",
    "wage1['female2'] = wage1['female'].astype('int')\n",
    "\n",
    "#transform female into string variable (or object as done by pandas)\n",
    "wage1['female3'] = wage1['female1'].astype('str')\n",
    "\n",
    "#replace bolean values\n",
    "wage1['female4'] = wage1['female3']\n",
    "wage1[\"female4\"] = wage1[\"female4\"].replace(\"True\", \"female\")\n",
    "wage1[\"female4\"] = wage1[\"female4\"].replace(\"False\", \"male\")\n",
    "\n",
    "#transform string variable into boolean variable\n",
    "wage1['female5']= wage1['female4']=='female'\n",
    "\n",
    "\n",
    "#display(wage1.head())\n",
    "#display(wage1.tail())\n",
    "\n",
    "print(wage1.dtypes)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "**Describing Qualitative Information**\n",
    "\n",
    "- Instead of transforming Boolean variables into dummies, they can be directly used as regressors.\n",
    "- The coefficient is then named `varname[T.True]` indicating that `True` was treated as 1."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "results.summary(): \n",
      "                            OLS Regression Results                            \n",
      "==============================================================================\n",
      "Dep. Variable:                   wage   R-squared:                       0.259\n",
      "Model:                            OLS   Adj. R-squared:                  0.256\n",
      "Method:                 Least Squares   F-statistic:                     91.32\n",
      "Date:                Wed, 15 Sep 2021   Prob (F-statistic):           9.66e-35\n",
      "Time:                        11:18:43   Log-Likelihood:                -1354.3\n",
      "No. Observations:                 526   AIC:                             2715.\n",
      "Df Residuals:                     523   BIC:                             2727.\n",
      "Df Model:                           2                                         \n",
      "Covariance Type:            nonrobust                                         \n",
      "==============================================================================\n",
      "                 coef    std err          t      P>|t|      [0.025      0.975]\n",
      "------------------------------------------------------------------------------\n",
      "Intercept      0.6228      0.673      0.926      0.355      -0.698       1.944\n",
      "female        -2.2734      0.279     -8.147      0.000      -2.822      -1.725\n",
      "educ           0.5065      0.050     10.051      0.000       0.407       0.605\n",
      "==============================================================================\n",
      "Omnibus:                      205.985   Durbin-Watson:                   1.830\n",
      "Prob(Omnibus):                  0.000   Jarque-Bera (JB):              819.498\n",
      "Skew:                           1.772   Prob(JB):                    1.12e-178\n",
      "Kurtosis:                       7.984   Cond. No.                         63.2\n",
      "==============================================================================\n",
      "\n",
      "Warnings:\n",
      "[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.\n",
      "\n",
      "results2.summary(): \n",
      "                            OLS Regression Results                            \n",
      "==============================================================================\n",
      "Dep. Variable:                   wage   R-squared:                       0.259\n",
      "Model:                            OLS   Adj. R-squared:                  0.256\n",
      "Method:                 Least Squares   F-statistic:                     91.32\n",
      "Date:                Wed, 15 Sep 2021   Prob (F-statistic):           9.66e-35\n",
      "Time:                        11:18:43   Log-Likelihood:                -1354.3\n",
      "No. Observations:                 526   AIC:                             2715.\n",
      "Df Residuals:                     523   BIC:                             2727.\n",
      "Df Model:                           2                                         \n",
      "Covariance Type:            nonrobust                                         \n",
      "===================================================================================\n",
      "                      coef    std err          t      P>|t|      [0.025      0.975]\n",
      "-----------------------------------------------------------------------------------\n",
      "Intercept           0.6228      0.673      0.926      0.355      -0.698       1.944\n",
      "female1[T.True]    -2.2734      0.279     -8.147      0.000      -2.822      -1.725\n",
      "educ                0.5065      0.050     10.051      0.000       0.407       0.605\n",
      "==============================================================================\n",
      "Omnibus:                      205.985   Durbin-Watson:                   1.830\n",
      "Prob(Omnibus):                  0.000   Jarque-Bera (JB):              819.498\n",
      "Skew:                           1.772   Prob(JB):                    1.12e-178\n",
      "Kurtosis:                       7.984   Cond. No.                         63.2\n",
      "==============================================================================\n",
      "\n",
      "Warnings:\n",
      "[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import wooldridge as woo\n",
    "import statsmodels.formula.api as smf\n",
    "import scipy.stats as stats\n",
    "import pandas as pd\n",
    "\n",
    "wage1 = woo.dataWoo('wage1')\n",
    "\n",
    "reg = smf.ols(formula='wage ~ female + educ', data=wage1)\n",
    "results = reg.fit()\n",
    "\n",
    "print(f'results.summary(): \\n{results.summary()}\\n')\n",
    "\n",
    "#transform female into boolean variable\n",
    "wage1['female1'] = wage1['female'].astype('bool')\n",
    "\n",
    "reg = smf.ols(formula='wage ~ female1 + educ', data=wage1)\n",
    "results2 = reg.fit()\n",
    "\n",
    "print(f'results2.summary(): \\n{results2.summary()}\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x1a3c67969e8>]"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import statsmodels.api as sm\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "\n",
    "plt.scatter(wage1.educ, wage1.wage, alpha=0.3)\n",
    "plt.xlabel('educ')\n",
    "plt.ylabel('wage')\n",
    "results3 = smf.ols(formula='wage ~ educ + female', data=wage1).fit()\n",
    "plt.plot(wage1.educ, results3.params[0] + results3.params[1] * wage1.educ + results3.params[2] * 0, 'r')\n",
    "plt.plot(wage1.educ, results3.params[0] + results3.params[1] * wage1.educ + results3.params[2] * 1, 'g')\n",
    "#print(f'results3.summary(): \\n{results3.summary()}\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "**Allowing for Different Slopes**\n",
    "\n",
    "- Notice that the two lines are parallel:\n",
    "    - This is because the categorical variable affects only the intercept and not the slope (which is a function of education).\n",
    "\n",
    "- Suppose now that we wish to test whether the return to education is the same for men and women\n",
    "\n",
    "- How can we do this?\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "**Allowing for Different Slopes**\n",
    "\n",
    "- Suppose now that we wish to test whether the return to education is the same for men and women\n",
    "\n",
    "- We can then include an interaction term to explore the effect of an interaction between the two — i.e. we let the slope vary by gender.\n",
    "\n",
    "    - The `*` in the formula means that we want the interaction term AND in addition each term separately (called main- or baseline-effect).\n",
    "    - If you want to include just an interaction, use `:` instead.\n",
    "        - This is generally avoided in analysis because it is almost always the case that, if a variable is important due to an interaction, it should have an effect by itself.\n",
    "        - In the wage example for instance, it is likely that there is a constant wage differential between men and women and in addition a difference in the return to education (different slopes for return to education for men and women)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "- Consider the model\n",
    "\n",
    "\\begin{equation*}\n",
    "log(wage)=\\beta_0+\\delta_0female+\\beta_1educ+\\delta_1female \\cdot educ+u\n",
    "\\end{equation*}\n",
    "\n",
    "- To summarize what is happening here:\n",
    "\n",
    "    - If we include the category variables without interactions we have two lines, one for `female == 1` and one for `female == 0`, with all having the same slope but different intercepts.\n",
    "    - If we include the interactions, now each of the lines can have a different slope.\n",
    "    - This captures the effect that variation in income may be different for people who have a good education and people who don't.\n",
    "\n",
    "\n",
    "\n",
    "- If we plug _female_=0 into the equation, then we find that the intercept for _males_ is $\\beta_0$, and the slope on\n",
    "_education_ for _males_ is $\\beta_1$.\n",
    "\n",
    "- For females, we plug in _female_=1; thus, the intercept for females is $\\beta_0+\\delta_0$,  and the slope is $\\beta_1+\\delta_1$.\n",
    "- Therefore, $\\delta_0$ measures the difference in intercepts between women and men, and $\\delta_1$ measures the difference in the return to education between women and men.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "source": [
    "**Graphs of the wage equation with interactions of _female_ and _educ_: (a)$\\delta_0<0,\\delta_1<0$;  (b)$\\delta_0<0,\\delta_1>0$**\n",
    "\n",
    "\n",
    "<br>  \n",
    "\n",
    "\n",
    "<center><img src=\"figs/wool_7_2.png\" width=\"500\"/> \n",
    "    \n",
    "\n",
    "<p>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "**Allowing for Different Slopes**\n",
    "\n",
    "- Graph (a) shows the case where the intercept for women is below that for men, and the slope of the line is smaller for women than for men.\n",
    "- This means that women earn less than men at all levels of education, and the gap increases as educ gets larger.\n",
    "- In graph (b), the intercept for women is below that for men, but the slope on education is larger for women.\n",
    "- This means that women earn less than men at low levels of education, but the gap narrows as education increases.\n",
    "- At some point, a woman earns more than a man with the same level of education, and this amount of education is easily found once we have the estimated equation.\n",
    "- How can we estimate such a model?\n",
    "- To apply OLS, we must write the model with an interaction between female and educ:\n",
    "\n",
    "\\begin{equation*}\n",
    "log(wage)=(\\beta_0+\\delta_0female)+(\\beta_1+\\delta_1female)\\cdot educ+u\n",
    "\\end{equation*}\n",
    "\n",
    "- Basically, this allows us to test the hypothesis that average wages are identical for men and women and the hypothesis that the return to education is the same for men and women."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 180,
   "metadata": {
    "scrolled": true,
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "results_slope.summary(): \n",
      "                            OLS Regression Results                            \n",
      "==============================================================================\n",
      "Dep. Variable:                   wage   R-squared:                       0.260\n",
      "Model:                            OLS   Adj. R-squared:                  0.256\n",
      "Method:                 Least Squares   F-statistic:                     61.07\n",
      "Date:                Wed, 16 Sep 2020   Prob (F-statistic):           7.44e-34\n",
      "Time:                        00:24:02   Log-Likelihood:                -1353.9\n",
      "No. Observations:                 526   AIC:                             2716.\n",
      "Df Residuals:                     522   BIC:                             2733.\n",
      "Df Model:                           3                                         \n",
      "Covariance Type:            nonrobust                                         \n",
      "===============================================================================\n",
      "                  coef    std err          t      P>|t|      [0.025      0.975]\n",
      "-------------------------------------------------------------------------------\n",
      "Intercept       0.2005      0.844      0.238      0.812      -1.457       1.858\n",
      "female         -1.1985      1.325     -0.905      0.366      -3.802       1.405\n",
      "educ            0.5395      0.064      8.400      0.000       0.413       0.666\n",
      "female:educ    -0.0860      0.104     -0.830      0.407      -0.290       0.118\n",
      "==============================================================================\n",
      "Omnibus:                      206.193   Durbin-Watson:                   1.826\n",
      "Prob(Omnibus):                  0.000   Jarque-Bera (JB):              828.018\n",
      "Skew:                           1.769   Prob(JB):                    1.58e-180\n",
      "Kurtosis:                       8.026   Cond. No.                         152.\n",
      "==============================================================================\n",
      "\n",
      "Warnings:\n",
      "[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "count    526.000000\n",
       "mean       5.896103\n",
       "std        3.693086\n",
       "min        0.530000\n",
       "25%        3.330000\n",
       "50%        4.650000\n",
       "75%        6.880000\n",
       "max       24.980000\n",
       "Name: wage, dtype: float64"
      ]
     },
     "execution_count": 180,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import wooldridge as woo\n",
    "import statsmodels.formula.api as smf\n",
    "import scipy.stats as stats\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "wage1 = woo.dataWoo('wage1')\n",
    "\n",
    "\n",
    "reg = smf.ols(formula='wage ~ female*educ', data=wage1)\n",
    "results_slope=reg.fit()\n",
    "\n",
    "print(f'results_slope.summary(): \\n{results_slope.summary()}\\n')\n",
    "\n",
    "wage1['wage'].describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 171,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x13fb65dfb70>]"
      ]
     },
     "execution_count": 171,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import wooldridge as woo\n",
    "import statsmodels.formula.api as smf\n",
    "import scipy.stats as stats\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "plt.scatter(wage1.educ, wage1.wage, alpha=0.3)\n",
    "plt.xlabel('educ')\n",
    "plt.ylabel('wage')\n",
    "\n",
    "plt.plot(wage1.educ, results_slope.params[0] + results_slope.params[1] * 0 + results_slope.params[2] * wage1.educ + results_slope.params[3] * 0 * wage1.educ, 'r')\n",
    "plt.plot(wage1.educ, results_slope.params[0] + results_slope.params[1] * 1 + results_slope.params[2] * wage1.educ + results_slope.params[3] * 1 * wage1.educ, 'g')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "**Describing Qualitative Information**\n",
    "\n",
    "- While qualitative variables with more than two outcomes can be represented by a set of dummy variables, the more natural and convenient way to do this are categorical variables.\n",
    "- In real-world data sets, qualitative information is often not readily coded as logical or dummy variables, so we might want to create our own regressors.\n",
    "- Suppose a qualitative variable saved as the numpy array OS takes one of the three string values \"Android\", \"iOS\", \"Windows\" or \"other\".\n",
    "- We can manually define the three relevant logical variables with \"Android\" as the reference category with\n",
    "\n",
    "```python\n",
    "iOS  = OS=='iOS'\n",
    "wind = OS=='Windows'\n",
    "oth  = OS=='other'\n",
    "```\n",
    "\n",
    "\n",
    "- A more convenient and elegant way to deal with qualitative variables are categorical variables discussed next."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "**Categorical Variables**\n",
    "\n",
    "\n",
    "- We have introduced categorical variables of type `Categorical` in the _Introduction to Python_ part earlier this week.\n",
    "- They take one of a given set of outcomes which can be labeled arbitrarily.\n",
    "- This makes them the natural variable type to store qualitative information.\n",
    "- In a linear regression performed by `statsmodels` we can easily transform any variable into a categorical variable using the function `C` in the definition of the formula.\n",
    "- The function `ols` is clever enough to implicitly add _g — 1_ dummy variables if the variable has _g_ outcomes.\n",
    "- As a reference category, the first category is left out by default.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "**Categorical Variables**\n",
    "\n",
    "- Let's illustrate this using the data set `CPS1985`.\n",
    "- This data set is similar to the one used in our earlier example in that it contains wage and other data for 534 individuals.\n",
    "- The frequency tables for the two variables _gender_ and _occupation_ are shown in the output.\n",
    "- The variable _gender_ has two categories _male_ and _female_.\n",
    "- The variable _occupation_ has six categories.\n",
    "- In the output, the coefficients are labeled with a combination of the variable and category name.\n",
    "- As an example, the estimated coefficient of 0.224 for `C(gender) [T.male]` in `results` implies that men make about 22.4% more than women who are the same in terms of the other regressors.\n",
    "- Employees in technical positions earn around 1% (see coefficient of `C(occupation)[T.technical]`) less than otherwise equal management positions (who are the reference category).\n",
    "- We can choose different reference categories using a second argument of the `C` command, where we provide a new reference group `somegroup` with the command `Treatment('somegroup')`.\n",
    "- In the specification `results_newref`, we choose _male_ and _technical_.\n",
    "- When we rerun the same regression command, we see the expected results:\n",
    "    - Variables like _education_ and _experience_ get the same coefficients.\n",
    "    - The dummy variable for females gets the negative of what the males got previously.\n",
    "- Obviously, it is equivalent to say \"female log wages are lower by 0.224\" and \"male log wages are higher by 0.224\".\n",
    "- The coefficients for the occupation are now relative to _technical_.\n",
    "- From the first regression we already knew that technical positions make 1% less than managers, so it is not surprising that in the second regression we find that managers make 1% more than technical positions.\n",
    "- The other occupation coefficients are higher by 0.010085 implying the same relative comparisons as in the first specification."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "freq_gender: \n",
      "col_0   count\n",
      "gender       \n",
      "female    245\n",
      "male      289\n",
      "\n",
      "freq_occupation: \n",
      "col_0       count\n",
      "oc               \n",
      "management     55\n",
      "office         97\n",
      "sales          38\n",
      "services       83\n",
      "technical     105\n",
      "worker        156\n",
      "\n",
      "table: \n",
      "                         b      se       t    pval\n",
      "Intercept           0.9050  0.1717  5.2718  0.0000\n",
      "C(gender)[T.male]   0.2238  0.0423  5.2979  0.0000\n",
      "C(oc)[T.office]    -0.2073  0.0776 -2.6699  0.0078\n",
      "C(oc)[T.sales]     -0.3601  0.0936 -3.8455  0.0001\n",
      "C(oc)[T.services]  -0.3626  0.0818 -4.4305  0.0000\n",
      "C(oc)[T.technical] -0.0101  0.0740 -0.1363  0.8916\n",
      "C(oc)[T.worker]    -0.1525  0.0763 -1.9981  0.0462\n",
      "education           0.0759  0.0101  7.5449  0.0000\n",
      "experience          0.0119  0.0017  7.0895  0.0000\n",
      "\n",
      "table_newref: \n",
      "                                                  b      se       t    pval\n",
      "Intercept                                    1.1187  0.1765  6.3393  0.0000\n",
      "C(gender, Treatment(\"male\"))[T.female]      -0.2238  0.0423 -5.2979  0.0000\n",
      "C(oc, Treatment(\"technical\"))[T.management]  0.0101  0.0740  0.1363  0.8916\n",
      "C(oc, Treatment(\"technical\"))[T.office]     -0.1972  0.0678 -2.9082  0.0038\n",
      "C(oc, Treatment(\"technical\"))[T.sales]      -0.3500  0.0863 -4.0541  0.0001\n",
      "C(oc, Treatment(\"technical\"))[T.services]   -0.3525  0.0750 -4.7030  0.0000\n",
      "C(oc, Treatment(\"technical\"))[T.worker]     -0.1425  0.0705 -2.0218  0.0437\n",
      "education                                    0.0759  0.0101  7.5449  0.0000\n",
      "experience                                   0.0119  0.0017  7.0895  0.0000\n",
      "\n"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "**Breaking a Numeric Variable Into Categories**\n",
    "\n",
    "- Sometimes, we do not use a numeric variable directly in a regression model because the implied linear relation seems implausible or inconvenient to interpret.\n",
    "- As an alternative to working with transformations such as logs and quadratic terms, it sometimes makes sense to estimate different levels for different ranges of the variable.\n",
    "- Let's consider the example of a ranking of a law school and how it relates to the starting salary of its graduates.\n",
    "- Given a numeric variable, we need to generate a categorical variable to represent the range into which the rank of a school falls.\n",
    "- In _Python_, the command `cut` from `pandas` is very convenient for this.\n",
    "- It takes a numeric variable and a list of cut points and returns a categorical variable.\n",
    "- By default, the upper cut points are included in the corresponding range."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "**Example: Effects of Law School Rankings on Starting Salaries**\n",
    "\n",
    "- The variable _rank_ of the data set `LAWSCH85` is the rank of the law school as a number between 1 and 175.\n",
    "- We would like to compare schools in the top 10, ranks 11-25, 26-40, 41-60, and 61-100 to the reference group of ranks above 100. So, we store the cut points 0, 10, 25, 40, 60, 100, and 175 in a variable _cutpts_.\n",
    "- In the data frame _lawsch85_, we create our new variable _rc_ using the `cut` command.\n",
    "- We specify the top 10 schools as the last category.\n",
    "- It is chosen with the second argument of the `C` command.\n",
    "- The regression results imply that graduates from the top 10 schools collect a starting salary which is around 70% higher than those of the schools below rank 100.\n",
    "- In fact: this approximation is inaccurate with these large numbers and the coefficient of 0.7 actually implies a difference of exp(0.7)-1=1.013 or 101.3%.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "freq: \n",
      "col_0      count\n",
      "rc              \n",
      "(0,10]        10\n",
      "(10,25]       16\n",
      "(25,40]       13\n",
      "(40,60]       18\n",
      "(60,100]      37\n",
      "(100,175]     62\n",
      "\n",
      "table_reg: \n",
      "                                                b      se        t    pval\n",
      "Intercept                                  9.1653  0.4114  22.2770  0.0000\n",
      "C(rc, Treatment(\"(100,175]\"))[T.(0,10]]    0.6996  0.0535  13.0780  0.0000\n",
      "C(rc, Treatment(\"(100,175]\"))[T.(10,25]]   0.5935  0.0394  15.0493  0.0000\n",
      "C(rc, Treatment(\"(100,175]\"))[T.(25,40]]   0.3751  0.0341  11.0054  0.0000\n",
      "C(rc, Treatment(\"(100,175]\"))[T.(40,60]]   0.2628  0.0280   9.3991  0.0000\n",
      "C(rc, Treatment(\"(100,175]\"))[T.(60,100]]  0.1316  0.0210   6.2540  0.0000\n",
      "LSAT                                       0.0057  0.0031   1.8579  0.0655\n",
      "GPA                                        0.0137  0.0742   0.1850  0.8535\n",
      "np.log(libvol)                             0.0364  0.0260   1.3976  0.1647\n",
      "np.log(cost)                               0.0008  0.0251   0.0335  0.9734\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import wooldridge as woo\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import statsmodels.api as sm\n",
    "import statsmodels.formula.api as smf\n",
    "\n",
    "lawsch85 = woo.dataWoo('lawsch85')\n",
    "\n",
    "# define cut points for the rank:\n",
    "cutpts = [0, 10, 25, 40, 60, 100, 175]\n",
    "\n",
    "# create categorical variable containing ranges for the rank:\n",
    "lawsch85['rc'] = pd.cut(lawsch85['rank'], bins=cutpts,\n",
    "                        labels=['(0,10]', '(10,25]', '(25,40]',\n",
    "                                '(40,60]', '(60,100]', '(100,175]'])\n",
    "\n",
    "# display frequencies:\n",
    "freq = pd.crosstab(lawsch85['rc'], columns='count')\n",
    "print(f'freq: \\n{freq}\\n')\n",
    "\n",
    "# run regression:\n",
    "reg = smf.ols(formula='np.log(salary) ~ C(rc, Treatment(\"(100,175]\")) +'\n",
    "                      'LSAT + GPA + np.log(libvol) + np.log(cost)',\n",
    "              data=lawsch85)\n",
    "results = reg.fit()\n",
    "\n",
    "# print regression table:\n",
    "table_reg = pd.DataFrame({'b': round(results.params, 4),\n",
    "                          'se': round(results.bse, 4),\n",
    "                          't': round(results.tvalues, 4),\n",
    "                          'pval': round(results.pvalues, 4)})\n",
    "print(f'table_reg: \\n{table_reg}\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "**Interactions and Differences in Regression Functions Across\n",
    "Groups**\n",
    "\n",
    "- Dummy and categorical variables can be interacted just like any other variable.\n",
    "- Let's now add an interaction term between _female_ and _married_\n",
    "- This allows a marriage premium to depend on gender.\n",
    "- This model also allows us to obtain the estimated wage differential among all four groups, but here we must be careful to plug in the correct combination of zeros and ones.\n",
    "- Setting $female=0$ and $married=0$ corresponds to the group single men, which is the base group, since this eliminates $female$, $married$, and $female\\cdot married$.\n",
    "- We can find the intercept for married men by setting $female=0$ and $married=1$ for instance.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "results.summary(): \n",
      "                            OLS Regression Results                            \n",
      "==============================================================================\n",
      "Dep. Variable:           np.log(wage)   R-squared:                       0.424\n",
      "Model:                            OLS   Adj. R-squared:                  0.417\n",
      "Method:                 Least Squares   F-statistic:                     63.63\n",
      "Date:                Wed, 15 Sep 2021   Prob (F-statistic):           4.53e-59\n",
      "Time:                        14:02:08   Log-Likelihood:                -268.44\n",
      "No. Observations:                 526   AIC:                             550.9\n",
      "Df Residuals:                     519   BIC:                             580.7\n",
      "Df Model:                           6                                         \n",
      "Covariance Type:            nonrobust                                         \n",
      "==================================================================================\n",
      "                     coef    std err          t      P>|t|      [0.025      0.975]\n",
      "----------------------------------------------------------------------------------\n",
      "Intercept          0.3878      0.102      3.790      0.000       0.187       0.589\n",
      "female            -0.0967      0.057     -1.684      0.093      -0.210       0.016\n",
      "married            0.2921      0.055      5.273      0.000       0.183       0.401\n",
      "female:married    -0.3156      0.074     -4.266      0.000      -0.461      -0.170\n",
      "educ               0.0835      0.007     12.175      0.000       0.070       0.097\n",
      "exper              0.0032      0.002      1.912      0.056   -8.74e-05       0.006\n",
      "tenure             0.0157      0.003      5.370      0.000       0.010       0.021\n",
      "==============================================================================\n",
      "Omnibus:                       14.767   Durbin-Watson:                   1.774\n",
      "Prob(Omnibus):                  0.001   Jarque-Bera (JB):               29.522\n",
      "Skew:                           0.071   Prob(JB):                     3.88e-07\n",
      "Kurtosis:                       4.152   Cond. No.                         160.\n",
      "==============================================================================\n",
      "\n",
      "Warnings:\n",
      "[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import wooldridge as woo\n",
    "import statsmodels.formula.api as smf\n",
    "import scipy.stats as stats\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "wage1 = woo.dataWoo('wage1')\n",
    "\n",
    "reg = smf.ols(formula='np.log(wage) ~ female*married + educ + exper + tenure', data=wage1)\n",
    "results = reg.fit()\n",
    "\n",
    "print(f'results.summary(): \\n{results.summary()}\\n')"
   ]
  }
 ],
 "metadata": {
  "celltoolbar": "Slideshow",
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": false,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
